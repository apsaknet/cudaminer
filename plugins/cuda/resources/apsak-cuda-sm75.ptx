//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34097967
// Cuda compilation tools, release 12.4, V12.4.131
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_75
.address_size 64

	// .globl	heavy_hash
.global .align 1 .b8 rho[24] = {1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 2, 14, 27, 41, 56, 8, 25, 43, 62, 18, 39, 61, 20, 44};
.global .align 1 .b8 pi[24] = {10, 7, 11, 17, 18, 3, 5, 16, 8, 21, 24, 4, 15, 23, 19, 13, 12, 2, 20, 14, 22, 9, 6, 1};
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.const .align 4 .b8 matrix[4096];
.const .align 8 .b8 hash_header[72];
.const .align 8 .b8 target[32];
.const .align 1 .b8 powP[200] = {61, 216, 246, 161, 13, 255, 60, 17, 60, 126, 2, 183, 85, 136, 191, 41, 210, 68, 251, 14, 114, 46, 95, 30, 160, 105, 152, 245, 163, 164, 165, 27, 101, 45, 94, 135, 202, 175, 47, 123, 70, 226, 220, 41, 214, 97, 239, 74, 16, 91, 65, 173, 30, 152, 58, 24, 156, 194, 155, 120, 12, 246, 107, 119, 64, 49, 102, 136, 51, 241, 235, 248, 240, 95, 40, 67, 60, 28, 101, 46, 10, 74, 241, 64, 5, 7, 150, 15, 82, 145, 41, 91, 135, 103, 227, 68, 21, 55, 177, 37, 164, 241, 112, 236, 137, 218, 233, 130, 143, 93, 200, 230, 35, 178, 180, 133, 31, 96, 26, 178, 70, 106, 163, 100, 144, 84, 133, 52, 26, 133, 47, 122, 28, 221, 6, 15, 66, 177, 59, 86, 29, 2, 162, 193, 228, 104, 22, 69, 228, 229, 29, 186, 141, 95, 9, 5, 65, 87, 2, 209, 74, 207, 206, 155, 132, 78, 202, 137, 219, 46, 116, 168, 39, 148, 176, 72, 114, 82, 139, 231, 156, 206, 252, 177, 188, 165, 175, 130, 207, 41, 17, 93, 131, 67, 130, 111, 120, 124, 185, 2};
.const .align 1 .b8 heavyP[200] = {9, 133, 36, 178, 82, 76, 215, 58, 22, 66, 159, 47, 14, 155, 98, 121, 238, 248, 199, 22, 72, 255, 20, 122, 152, 100, 5, 128, 76, 95, 167, 17, 218, 206, 238, 68, 223, 224, 32, 231, 105, 64, 243, 20, 46, 216, 199, 114, 186, 53, 137, 147, 42, 255, 0, 193, 98, 196, 15, 37, 64, 144, 33, 94, 72, 106, 207, 13, 166, 249, 57, 128, 12, 61, 42, 121, 159, 170, 188, 160, 38, 162, 169, 208, 93, 192, 49, 244, 63, 140, 193, 84, 195, 76, 31, 211, 61, 204, 105, 167, 1, 125, 107, 108, 228, 147, 36, 86, 211, 91, 198, 46, 68, 176, 205, 153, 58, 75, 247, 78, 176, 242, 52, 84, 131, 134, 76, 119, 22, 148, 188, 54, 176, 97, 233, 7, 7, 204, 101, 119, 177, 29, 143, 126, 57, 109, 196, 186, 128, 219, 143, 234, 88, 202, 52, 123, 211, 242, 146, 185, 87, 185, 129, 132, 4, 197, 118, 199, 46, 194, 18, 81, 103, 159, 195, 71, 10, 12, 41, 181, 157, 57, 187, 146, 21, 198, 159, 47, 49, 224, 154, 84, 53, 218, 185, 16, 125, 50, 25, 22};

.visible .entry heavy_hash(
	.param .u64 heavy_hash_param_0,
	.param .u64 heavy_hash_param_1,
	.param .u64 heavy_hash_param_2,
	.param .u8 heavy_hash_param_3,
	.param .u64 heavy_hash_param_4,
	.param .u64 heavy_hash_param_5
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<4421>;
	.reg .b64 	%rd<714>;


	ld.param.u8 	%rs1, [heavy_hash_param_3];
	ld.param.u64 	%rd129, [heavy_hash_param_0];
	ld.param.u64 	%rd130, [heavy_hash_param_1];
	ld.param.u64 	%rd131, [heavy_hash_param_2];
	ld.param.u64 	%rd132, [heavy_hash_param_4];
	ld.param.u64 	%rd133, [heavy_hash_param_5];
	cvta.to.global.u64 	%rd1, %rd132;
	cvta.to.global.u64 	%rd2, %rd133;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	cvt.s64.s32 	%rd3, %r8;
	setp.ge.u64 	%p1, %rd3, %rd131;
	@%p1 bra 	$L__BB0_18;

	cvt.u32.u64 	%r9, %rd3;
	setp.ne.s32 	%p2, %r9, 0;
	@%p2 bra 	$L__BB0_3;

	mov.u64 	%rd134, 0;
	st.global.u64 	[%rd2], %rd134;

$L__BB0_3:
	setp.eq.s16 	%p3, %rs1, 0;
	@%p3 bra 	$L__BB0_5;

	shl.b64 	%rd135, %rd3, 5;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.v2.u64 	{%rd137, %rd138}, [%rd136];
	mul.lo.s64 	%rd141, %rd138, 5;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd141, 7;
	shr.b64 	%rhs, %rd141, 57;
	add.u64 	%rd142, %lhs, %rhs;
	}
	mul.lo.s64 	%rd661, %rd142, 9;
	shl.b64 	%rd143, %rd138, 17;
	ld.global.v2.u64 	{%rd144, %rd145}, [%rd136+16];
	xor.b64  	%rd148, %rd144, %rd137;
	xor.b64  	%rd149, %rd145, %rd138;
	xor.b64  	%rd150, %rd138, %rd148;
	xor.b64  	%rd151, %rd137, %rd149;
	st.global.v2.u64 	[%rd136], {%rd151, %rd150};
	xor.b64  	%rd152, %rd148, %rd143;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd149, 45;
	shr.b64 	%rhs, %rd149, 19;
	add.u64 	%rd153, %lhs, %rhs;
	}
	st.global.v2.u64 	[%rd136+16], {%rd152, %rd153};
	bra.uni 	$L__BB0_6;

$L__BB0_5:
	ld.global.u64 	%rd154, [%rd1];
	xor.b64  	%rd661, %rd154, %rd3;

$L__BB0_6:
	and.b64  	%rd171, %rd661, %rd129;
	or.b64  	%rd7, %rd171, %rd130;
	ld.const.u64 	%rd172, [hash_header];
	xor.b64  	%rd687, %rd172, 1242148031264380989;
	ld.const.u64 	%rd173, [hash_header+8];
	xor.b64  	%rd682, %rd173, 3008272977830772284;
	ld.const.u64 	%rd174, [hash_header+16];
	xor.b64  	%rd677, %rd174, 2188519011337848018;
	ld.const.u64 	%rd175, [hash_header+24];
	xor.b64  	%rd672, %rd175, 1992179434288343456;
	ld.const.u64 	%rd176, [hash_header+32];
	xor.b64  	%rd667, %rd176, 8876506674959887717;
	ld.const.u64 	%rd177, [hash_header+40];
	xor.b64  	%rd686, %rd177, 5399642050693751366;
	ld.const.u64 	%rd178, [hash_header+48];
	xor.b64  	%rd681, %rd178, 1745875063082670864;
	ld.const.u64 	%rd179, [hash_header+56];
	xor.b64  	%rd676, %rd179, 8605242046444978844;
	ld.const.u64 	%rd180, [hash_header+64];
	xor.b64  	%rd671, %rd180, -510048929142394560;
	xor.b64  	%rd666, %rd7, 3343109343542796272;
	mov.u32 	%r4419, 0;
	mov.u64 	%rd685, 1123092876221303306;
	mov.u64 	%rd684, 3784524041015224902;
	mov.u64 	%rd683, -8517909413761200310;
	mov.u64 	%rd680, 4963925045340115282;
	mov.u64 	%rd679, 1082795874807940378;
	mov.u64 	%rd678, 5237849264682708699;
	mov.u64 	%rd675, -1409360996057663723;
	mov.u64 	%rd674, -4494027153138273982;
	mov.u64 	%rd673, -5621391061570334094;
	mov.u64 	%rd670, -1817099578685924727;
	mov.u64 	%rd669, -5035616039755945756;
	mov.u64 	%rd668, 6706187291358897596;
	mov.u64 	%rd665, -5613068297060437469;
	mov.u64 	%rd664, -3386048033060200563;
	mov.u64 	%rd663, 196324915476054915;
	mov.u64 	%rd662, RC;

$L__BB0_7:
	xor.b64  	%rd181, %rd686, %rd687;
	xor.b64  	%rd182, %rd181, %rd685;
	xor.b64  	%rd183, %rd182, %rd684;
	xor.b64  	%rd184, %rd183, %rd683;
	xor.b64  	%rd185, %rd681, %rd682;
	xor.b64  	%rd186, %rd185, %rd680;
	xor.b64  	%rd187, %rd186, %rd679;
	xor.b64  	%rd188, %rd187, %rd678;
	xor.b64  	%rd189, %rd676, %rd677;
	xor.b64  	%rd190, %rd189, %rd675;
	xor.b64  	%rd191, %rd190, %rd674;
	xor.b64  	%rd192, %rd191, %rd673;
	xor.b64  	%rd193, %rd671, %rd672;
	xor.b64  	%rd194, %rd193, %rd670;
	xor.b64  	%rd195, %rd194, %rd669;
	xor.b64  	%rd196, %rd195, %rd668;
	xor.b64  	%rd197, %rd666, %rd667;
	xor.b64  	%rd198, %rd197, %rd665;
	xor.b64  	%rd199, %rd198, %rd664;
	xor.b64  	%rd200, %rd199, %rd663;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd188, 1;
	shr.b64 	%rhs, %rd188, 63;
	add.u64 	%rd201, %lhs, %rhs;
	}
	xor.b64  	%rd202, %rd200, %rd201;
	xor.b64  	%rd203, %rd202, %rd687;
	xor.b64  	%rd204, %rd686, %rd202;
	xor.b64  	%rd205, %rd685, %rd202;
	xor.b64  	%rd206, %rd684, %rd202;
	xor.b64  	%rd207, %rd683, %rd202;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd192, 1;
	shr.b64 	%rhs, %rd192, 63;
	add.u64 	%rd208, %lhs, %rhs;
	}
	xor.b64  	%rd209, %rd208, %rd184;
	xor.b64  	%rd210, %rd682, %rd209;
	xor.b64  	%rd211, %rd681, %rd209;
	xor.b64  	%rd212, %rd680, %rd209;
	xor.b64  	%rd213, %rd679, %rd209;
	xor.b64  	%rd214, %rd678, %rd209;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd196, 1;
	shr.b64 	%rhs, %rd196, 63;
	add.u64 	%rd215, %lhs, %rhs;
	}
	xor.b64  	%rd216, %rd215, %rd188;
	xor.b64  	%rd217, %rd677, %rd216;
	xor.b64  	%rd218, %rd676, %rd216;
	xor.b64  	%rd219, %rd675, %rd216;
	xor.b64  	%rd220, %rd674, %rd216;
	xor.b64  	%rd221, %rd673, %rd216;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd200, 1;
	shr.b64 	%rhs, %rd200, 63;
	add.u64 	%rd222, %lhs, %rhs;
	}
	xor.b64  	%rd223, %rd222, %rd192;
	xor.b64  	%rd224, %rd672, %rd223;
	xor.b64  	%rd225, %rd671, %rd223;
	xor.b64  	%rd226, %rd670, %rd223;
	xor.b64  	%rd227, %rd669, %rd223;
	xor.b64  	%rd228, %rd668, %rd223;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd184, 1;
	shr.b64 	%rhs, %rd184, 63;
	add.u64 	%rd229, %lhs, %rhs;
	}
	xor.b64  	%rd230, %rd196, %rd229;
	xor.b64  	%rd231, %rd667, %rd230;
	xor.b64  	%rd232, %rd666, %rd230;
	xor.b64  	%rd233, %rd665, %rd230;
	xor.b64  	%rd234, %rd664, %rd230;
	xor.b64  	%rd235, %rd663, %rd230;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd210, 1;
	shr.b64 	%rhs, %rd210, 63;
	add.u64 	%rd236, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd205, 3;
	shr.b64 	%rhs, %rd205, 61;
	add.u64 	%rd237, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd218, 6;
	shr.b64 	%rhs, %rd218, 58;
	add.u64 	%rd238, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd212, 10;
	shr.b64 	%rhs, %rd212, 54;
	add.u64 	%rd239, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd220, 15;
	shr.b64 	%rhs, %rd220, 49;
	add.u64 	%rd240, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd227, 21;
	shr.b64 	%rhs, %rd227, 43;
	add.u64 	%rd241, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd224, 28;
	shr.b64 	%rhs, %rd224, 36;
	add.u64 	%rd242, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd204, 36;
	shr.b64 	%rhs, %rd204, 28;
	add.u64 	%rd243, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd213, 45;
	shr.b64 	%rhs, %rd213, 19;
	add.u64 	%rd244, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd225, 55;
	shr.b64 	%rhs, %rd225, 9;
	add.u64 	%rd245, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd214, 2;
	shr.b64 	%rhs, %rd214, 62;
	add.u64 	%rd246, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd235, 14;
	shr.b64 	%rhs, %rd235, 50;
	add.u64 	%rd247, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd231, 27;
	shr.b64 	%rhs, %rd231, 37;
	add.u64 	%rd248, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd206, 41;
	shr.b64 	%rhs, %rd206, 23;
	add.u64 	%rd249, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd228, 56;
	shr.b64 	%rhs, %rd228, 8;
	add.u64 	%rd250, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd234, 8;
	shr.b64 	%rhs, %rd234, 56;
	add.u64 	%rd251, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd226, 25;
	shr.b64 	%rhs, %rd226, 39;
	add.u64 	%rd252, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd219, 43;
	shr.b64 	%rhs, %rd219, 21;
	add.u64 	%rd253, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd217, 62;
	shr.b64 	%rhs, %rd217, 2;
	add.u64 	%rd254, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd207, 18;
	shr.b64 	%rhs, %rd207, 46;
	add.u64 	%rd255, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd233, 39;
	shr.b64 	%rhs, %rd233, 25;
	add.u64 	%rd256, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd221, 61;
	shr.b64 	%rhs, %rd221, 3;
	add.u64 	%rd257, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd232, 20;
	shr.b64 	%rhs, %rd232, 44;
	add.u64 	%rd258, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd211, 44;
	shr.b64 	%rhs, %rd211, 20;
	add.u64 	%rd259, %lhs, %rhs;
	}
	not.b64 	%rd260, %rd259;
	and.b64  	%rd261, %rd253, %rd260;
	xor.b64  	%rd262, %rd261, %rd203;
	not.b64 	%rd263, %rd253;
	and.b64  	%rd264, %rd241, %rd263;
	xor.b64  	%rd682, %rd264, %rd259;
	not.b64 	%rd265, %rd241;
	and.b64  	%rd266, %rd247, %rd265;
	xor.b64  	%rd677, %rd266, %rd253;
	not.b64 	%rd267, %rd247;
	and.b64  	%rd268, %rd203, %rd267;
	xor.b64  	%rd672, %rd268, %rd241;
	not.b64 	%rd269, %rd203;
	and.b64  	%rd270, %rd259, %rd269;
	xor.b64  	%rd667, %rd247, %rd270;
	not.b64 	%rd271, %rd258;
	and.b64  	%rd272, %rd237, %rd271;
	xor.b64  	%rd686, %rd272, %rd242;
	not.b64 	%rd273, %rd237;
	and.b64  	%rd274, %rd244, %rd273;
	xor.b64  	%rd681, %rd274, %rd258;
	not.b64 	%rd275, %rd244;
	and.b64  	%rd276, %rd257, %rd275;
	xor.b64  	%rd676, %rd276, %rd237;
	not.b64 	%rd277, %rd257;
	and.b64  	%rd278, %rd242, %rd277;
	xor.b64  	%rd671, %rd278, %rd244;
	not.b64 	%rd279, %rd242;
	and.b64  	%rd280, %rd258, %rd279;
	xor.b64  	%rd666, %rd257, %rd280;
	not.b64 	%rd281, %rd238;
	and.b64  	%rd282, %rd252, %rd281;
	xor.b64  	%rd685, %rd282, %rd236;
	not.b64 	%rd283, %rd252;
	and.b64  	%rd284, %rd251, %rd283;
	xor.b64  	%rd680, %rd284, %rd238;
	not.b64 	%rd285, %rd251;
	and.b64  	%rd286, %rd255, %rd285;
	xor.b64  	%rd675, %rd286, %rd252;
	not.b64 	%rd287, %rd255;
	and.b64  	%rd288, %rd236, %rd287;
	xor.b64  	%rd670, %rd288, %rd251;
	not.b64 	%rd289, %rd236;
	and.b64  	%rd290, %rd238, %rd289;
	xor.b64  	%rd665, %rd255, %rd290;
	not.b64 	%rd291, %rd243;
	and.b64  	%rd292, %rd239, %rd291;
	xor.b64  	%rd684, %rd292, %rd248;
	not.b64 	%rd293, %rd239;
	and.b64  	%rd294, %rd240, %rd293;
	xor.b64  	%rd679, %rd294, %rd243;
	not.b64 	%rd295, %rd240;
	and.b64  	%rd296, %rd250, %rd295;
	xor.b64  	%rd674, %rd296, %rd239;
	not.b64 	%rd297, %rd250;
	and.b64  	%rd298, %rd248, %rd297;
	xor.b64  	%rd669, %rd298, %rd240;
	not.b64 	%rd299, %rd248;
	and.b64  	%rd300, %rd243, %rd299;
	xor.b64  	%rd664, %rd250, %rd300;
	not.b64 	%rd301, %rd245;
	and.b64  	%rd302, %rd256, %rd301;
	xor.b64  	%rd683, %rd302, %rd254;
	not.b64 	%rd303, %rd256;
	and.b64  	%rd304, %rd249, %rd303;
	xor.b64  	%rd678, %rd304, %rd245;
	not.b64 	%rd305, %rd249;
	and.b64  	%rd306, %rd246, %rd305;
	xor.b64  	%rd673, %rd306, %rd256;
	not.b64 	%rd307, %rd246;
	and.b64  	%rd308, %rd254, %rd307;
	xor.b64  	%rd668, %rd308, %rd249;
	not.b64 	%rd309, %rd254;
	and.b64  	%rd310, %rd245, %rd309;
	xor.b64  	%rd663, %rd246, %rd310;
	ld.global.nc.u64 	%rd311, [%rd662];
	xor.b64  	%rd687, %rd262, %rd311;
	add.s64 	%rd662, %rd662, 8;
	add.s32 	%r4419, %r4419, 1;
	setp.ne.s32 	%p4, %r4419, 24;
	@%p4 bra 	$L__BB0_7;

	cvt.u16.u64 	%rs2, %rd682;
	and.b16  	%rs3, %rs2, 240;
	shr.u64 	%rd334, %rd682, 8;
	cvt.u32.u64 	%r4108, %rd334;
	shr.u64 	%rd335, %rd682, 16;
	cvt.u32.u64 	%r4109, %rd335;
	shr.u64 	%rd336, %rd682, 24;
	cvt.u32.u64 	%r4110, %rd336;
	shr.u64 	%rd337, %rd682, 32;
	cvt.u32.u64 	%r4111, %rd337;
	shr.u64 	%rd338, %rd682, 40;
	cvt.u32.u64 	%r4112, %rd338;
	shr.u64 	%rd339, %rd682, 48;
	cvt.u32.u64 	%r4113, %rd339;
	shr.u64 	%rd340, %rd682, 56;
	cvt.u32.u64 	%r4114, %rd340;
	shr.u64 	%rd341, %rd677, 8;
	cvt.u32.u64 	%r4115, %rd341;
	shr.u64 	%rd342, %rd677, 16;
	cvt.u32.u64 	%r4116, %rd342;
	shr.u64 	%rd343, %rd677, 24;
	cvt.u32.u64 	%r4117, %rd343;
	shr.u64 	%rd344, %rd677, 32;
	cvt.u32.u64 	%r4118, %rd344;
	shr.u64 	%rd345, %rd677, 40;
	cvt.u32.u64 	%r4119, %rd345;
	shr.u64 	%rd346, %rd677, 48;
	cvt.u32.u64 	%r4120, %rd346;
	shr.u64 	%rd347, %rd677, 56;
	cvt.u32.u64 	%r4121, %rd347;
	shr.u64 	%rd348, %rd672, 56;
	cvt.u32.u64 	%r4122, %rd348;
	shr.u64 	%rd349, %rd672, 48;
	cvt.u32.u64 	%r4123, %rd349;
	shr.u64 	%rd350, %rd672, 40;
	cvt.u32.u64 	%r4124, %rd350;
	shr.u64 	%rd351, %rd672, 32;
	cvt.u32.u64 	%r4125, %rd351;
	shr.u64 	%rd352, %rd672, 24;
	cvt.u32.u64 	%r4126, %rd352;
	shr.u64 	%rd353, %rd672, 16;
	cvt.u32.u64 	%r4127, %rd353;
	shr.u64 	%rd354, %rd672, 8;
	cvt.u32.u64 	%r4128, %rd354;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4129, %temp}, %rd687;
	}
	mov.u32 	%r4130, 291;
	mov.u32 	%r4420, 0;
	prmt.b32 	%r4131, %r4129, %r4420, %r4130;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4132}, %rd687;
	}
	prmt.b32 	%r4133, %r4132, %r4420, %r4130;
	shr.u64 	%rd355, %rd672, 60;
	cvt.u32.u64 	%r4134, %rd355;
	shr.u64 	%rd356, %rd672, 52;
	cvt.u32.u64 	%r4135, %rd356;
	shl.b32 	%r4136, %r4122, 8;
	and.b32  	%r4137, %r4136, 3840;
	or.b32  	%r4138, %r4137, %r4134;
	shl.b32 	%r4139, %r4135, 16;
	and.b32  	%r4140, %r4139, 983040;
	or.b32  	%r4141, %r4138, %r4140;
	shl.b32 	%r4142, %r4123, 24;
	and.b32  	%r4143, %r4142, 251658240;
	or.b32  	%r4045, %r4141, %r4143;
	shr.u64 	%rd357, %rd672, 44;
	cvt.u32.u64 	%r4144, %rd357;
	and.b32  	%r4145, %r4144, 15;
	and.b32  	%r4146, %r4124, 15;
	shr.u64 	%rd358, %rd672, 36;
	cvt.u32.u64 	%r4147, %rd358;
	bfi.b32 	%r4148, %r4146, %r4145, 8, 4;
	shl.b32 	%r4149, %r4147, 16;
	and.b32  	%r4150, %r4149, 983040;
	or.b32  	%r4151, %r4148, %r4150;
	shl.b32 	%r4152, %r4125, 24;
	and.b32  	%r4153, %r4152, 251658240;
	or.b32  	%r4049, %r4151, %r4153;
	cvt.u32.u64 	%r4154, %rd672;
	shr.u32 	%r4155, %r4154, 28;
	shl.b32 	%r4156, %r4126, 8;
	and.b32  	%r4157, %r4156, 3840;
	or.b32  	%r4158, %r4155, %r4157;
	shr.u32 	%r4159, %r4154, 4;
	and.b32  	%r4160, %r4159, 983040;
	or.b32  	%r4161, %r4158, %r4160;
	shl.b32 	%r4162, %r4127, 24;
	and.b32  	%r4163, %r4162, 251658240;
	or.b32  	%r4053, %r4161, %r4163;
	shr.u32 	%r4164, %r4154, 12;
	and.b32  	%r4165, %r4164, 15;
	and.b32  	%r4166, %r4128, 15;
	cvt.u16.u64 	%rs4, %rd672;
	and.b16  	%rs5, %rs4, 240;
	shr.u16 	%rs6, %rs5, 4;
	bfi.b32 	%r4167, %r4166, %r4165, 8, 4;
	cvt.u32.u16 	%r4168, %rs6;
	prmt.b32 	%r4169, %r4168, %r4167, 28756;
	shl.b32 	%r4170, %r4154, 24;
	and.b32  	%r4171, %r4170, 251658240;
	or.b32  	%r4057, %r4169, %r4171;
	shr.u64 	%rd359, %rd677, 60;
	cvt.u32.u64 	%r4172, %rd359;
	shr.u64 	%rd360, %rd677, 52;
	cvt.u32.u64 	%r4173, %rd360;
	shl.b32 	%r4174, %r4121, 8;
	and.b32  	%r4175, %r4174, 3840;
	or.b32  	%r4176, %r4175, %r4172;
	shl.b32 	%r4177, %r4173, 16;
	and.b32  	%r4178, %r4177, 983040;
	or.b32  	%r4179, %r4176, %r4178;
	shl.b32 	%r4180, %r4120, 24;
	and.b32  	%r4181, %r4180, 251658240;
	or.b32  	%r4061, %r4179, %r4181;
	shr.u64 	%rd361, %rd677, 44;
	cvt.u32.u64 	%r4182, %rd361;
	and.b32  	%r4183, %r4182, 15;
	and.b32  	%r4184, %r4119, 15;
	shr.u64 	%rd362, %rd677, 36;
	cvt.u32.u64 	%r4185, %rd362;
	bfi.b32 	%r4186, %r4184, %r4183, 8, 4;
	shl.b32 	%r4187, %r4185, 16;
	and.b32  	%r4188, %r4187, 983040;
	or.b32  	%r4189, %r4186, %r4188;
	shl.b32 	%r4190, %r4118, 24;
	and.b32  	%r4191, %r4190, 251658240;
	or.b32  	%r4065, %r4189, %r4191;
	cvt.u32.u64 	%r4192, %rd677;
	shr.u32 	%r4193, %r4192, 28;
	shl.b32 	%r4194, %r4117, 8;
	and.b32  	%r4195, %r4194, 3840;
	or.b32  	%r4196, %r4193, %r4195;
	shr.u32 	%r4197, %r4192, 4;
	and.b32  	%r4198, %r4197, 983040;
	or.b32  	%r4199, %r4196, %r4198;
	shl.b32 	%r4200, %r4116, 24;
	and.b32  	%r4201, %r4200, 251658240;
	or.b32  	%r4069, %r4199, %r4201;
	shr.u32 	%r4202, %r4192, 12;
	and.b32  	%r4203, %r4202, 15;
	and.b32  	%r4204, %r4115, 15;
	cvt.u16.u64 	%rs7, %rd677;
	and.b16  	%rs8, %rs7, 240;
	shr.u16 	%rs9, %rs8, 4;
	bfi.b32 	%r4205, %r4204, %r4203, 8, 4;
	cvt.u32.u16 	%r4206, %rs9;
	prmt.b32 	%r4207, %r4206, %r4205, 28756;
	shl.b32 	%r4208, %r4192, 24;
	and.b32  	%r4209, %r4208, 251658240;
	or.b32  	%r4073, %r4207, %r4209;
	shr.u64 	%rd363, %rd682, 60;
	cvt.u32.u64 	%r4210, %rd363;
	shr.u64 	%rd364, %rd682, 52;
	cvt.u32.u64 	%r4211, %rd364;
	shl.b32 	%r4212, %r4114, 8;
	and.b32  	%r4213, %r4212, 3840;
	or.b32  	%r4214, %r4213, %r4210;
	shl.b32 	%r4215, %r4211, 16;
	and.b32  	%r4216, %r4215, 983040;
	or.b32  	%r4217, %r4214, %r4216;
	shl.b32 	%r4218, %r4113, 24;
	and.b32  	%r4219, %r4218, 251658240;
	or.b32  	%r4077, %r4217, %r4219;
	shr.u64 	%rd365, %rd682, 44;
	cvt.u32.u64 	%r4220, %rd365;
	and.b32  	%r4221, %r4220, 15;
	and.b32  	%r4222, %r4112, 15;
	shr.u64 	%rd366, %rd682, 36;
	cvt.u32.u64 	%r4223, %rd366;
	bfi.b32 	%r4224, %r4222, %r4221, 8, 4;
	shl.b32 	%r4225, %r4223, 16;
	and.b32  	%r4226, %r4225, 983040;
	or.b32  	%r4227, %r4224, %r4226;
	shl.b32 	%r4228, %r4111, 24;
	and.b32  	%r4229, %r4228, 251658240;
	or.b32  	%r4081, %r4227, %r4229;
	cvt.u32.u64 	%r4230, %rd682;
	shr.u32 	%r4231, %r4230, 28;
	shl.b32 	%r4232, %r4110, 8;
	and.b32  	%r4233, %r4232, 3840;
	or.b32  	%r4234, %r4231, %r4233;
	shr.u32 	%r4235, %r4230, 4;
	and.b32  	%r4236, %r4235, 983040;
	or.b32  	%r4237, %r4234, %r4236;
	shl.b32 	%r4238, %r4109, 24;
	and.b32  	%r4239, %r4238, 251658240;
	or.b32  	%r4085, %r4237, %r4239;
	shr.u32 	%r4240, %r4230, 12;
	and.b32  	%r4241, %r4240, 15;
	and.b32  	%r4242, %r4108, 15;
	shr.u16 	%rs10, %rs3, 4;
	bfi.b32 	%r4243, %r4242, %r4241, 8, 4;
	cvt.u32.u16 	%r4244, %rs10;
	prmt.b32 	%r4245, %r4244, %r4243, 28756;
	shl.b32 	%r4246, %r4230, 24;
	and.b32  	%r4247, %r4246, 251658240;
	or.b32  	%r4089, %r4245, %r4247;
	mov.b64 	%rd367, {%r4133, %r4131};
	cvt.u16.u64 	%rs11, %rd367;
	and.b16  	%rs12, %rs11, 240;
	shr.u16 	%rs13, %rs12, 4;
	shr.u64 	%rd368, %rd367, 8;
	cvt.u32.u64 	%r4248, %rd368;
	cvt.u32.u64 	%r4249, %rd367;
	shr.u32 	%r4250, %r4249, 12;
	cvt.u32.u16 	%r4251, %rs13;
	and.b32  	%r4252, %r4249, 15;
	prmt.b32 	%r4253, %r4252, %r4251, 30212;
	shl.b32 	%r4254, %r4249, 4;
	and.b32  	%r4255, %r4254, 983040;
	or.b32  	%r4256, %r4253, %r4255;
	shl.b32 	%r4257, %r4248, 24;
	and.b32  	%r4258, %r4257, 251658240;
	or.b32  	%r4093, %r4256, %r4258;
	shr.u64 	%rd369, %rd367, 16;
	cvt.u32.u64 	%r4259, %rd369;
	shr.u32 	%r4260, %r4249, 20;
	and.b32  	%r4261, %r4260, 15;
	and.b32  	%r4262, %r4259, 15;
	shr.u64 	%rd370, %rd367, 24;
	cvt.u32.u64 	%r4263, %rd370;
	bfi.b32 	%r4264, %r4262, %r4261, 8, 4;
	and.b32  	%r4265, %r4250, 983040;
	or.b32  	%r4266, %r4264, %r4265;
	shl.b32 	%r4267, %r4263, 24;
	and.b32  	%r4268, %r4267, 251658240;
	or.b32  	%r4097, %r4266, %r4268;
	shr.u64 	%rd371, %rd367, 32;
	cvt.u32.u64 	%r4269, %rd371;
	shr.u64 	%rd372, %rd367, 36;
	cvt.u32.u64 	%r4270, %rd372;
	and.b32  	%r4271, %r4270, 15;
	and.b32  	%r4272, %r4269, 15;
	shr.u64 	%rd373, %rd367, 40;
	cvt.u32.u64 	%r4273, %rd373;
	shr.u64 	%rd374, %rd367, 44;
	cvt.u32.u64 	%r4274, %rd374;
	bfi.b32 	%r4275, %r4272, %r4271, 8, 4;
	shl.b32 	%r4276, %r4274, 16;
	and.b32  	%r4277, %r4276, 983040;
	or.b32  	%r4278, %r4275, %r4277;
	shl.b32 	%r4279, %r4273, 24;
	and.b32  	%r4280, %r4279, 251658240;
	or.b32  	%r4101, %r4278, %r4280;
	shr.u64 	%rd375, %rd367, 48;
	cvt.u32.u64 	%r4281, %rd375;
	shr.u64 	%rd376, %rd367, 52;
	cvt.u32.u64 	%r4282, %rd376;
	and.b32  	%r4283, %r4282, 15;
	and.b32  	%r4284, %r4281, 15;
	shr.u64 	%rd377, %rd367, 56;
	cvt.u32.u64 	%r4285, %rd377;
	bfi.b32 	%r4286, %r4284, %r4283, 8, 4;
	and.b32  	%r4287, %r4274, 983040;
	or.b32  	%r4288, %r4286, %r4287;
	shl.b32 	%r4289, %r4285, 24;
	and.b32  	%r4290, %r4289, 251658240;
	or.b32  	%r4105, %r4288, %r4290;
	ld.const.u32 	%r12, [matrix];
	// begin inline asm
	dp4a.u32.u32 %r11, %r12, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r16, [matrix+4];
	// begin inline asm
	dp4a.u32.u32 %r15, %r16, %r4049, %r11;
	// end inline asm
	ld.const.u32 	%r20, [matrix+8];
	// begin inline asm
	dp4a.u32.u32 %r19, %r20, %r4053, %r15;
	// end inline asm
	ld.const.u32 	%r24, [matrix+12];
	// begin inline asm
	dp4a.u32.u32 %r23, %r24, %r4057, %r19;
	// end inline asm
	ld.const.u32 	%r28, [matrix+16];
	// begin inline asm
	dp4a.u32.u32 %r27, %r28, %r4061, %r23;
	// end inline asm
	ld.const.u32 	%r32, [matrix+20];
	// begin inline asm
	dp4a.u32.u32 %r31, %r32, %r4065, %r27;
	// end inline asm
	ld.const.u32 	%r36, [matrix+24];
	// begin inline asm
	dp4a.u32.u32 %r35, %r36, %r4069, %r31;
	// end inline asm
	ld.const.u32 	%r40, [matrix+28];
	// begin inline asm
	dp4a.u32.u32 %r39, %r40, %r4073, %r35;
	// end inline asm
	ld.const.u32 	%r44, [matrix+32];
	// begin inline asm
	dp4a.u32.u32 %r43, %r44, %r4077, %r39;
	// end inline asm
	ld.const.u32 	%r48, [matrix+36];
	// begin inline asm
	dp4a.u32.u32 %r47, %r48, %r4081, %r43;
	// end inline asm
	ld.const.u32 	%r52, [matrix+40];
	// begin inline asm
	dp4a.u32.u32 %r51, %r52, %r4085, %r47;
	// end inline asm
	ld.const.u32 	%r56, [matrix+44];
	// begin inline asm
	dp4a.u32.u32 %r55, %r56, %r4089, %r51;
	// end inline asm
	ld.const.u32 	%r60, [matrix+48];
	// begin inline asm
	dp4a.u32.u32 %r59, %r60, %r4093, %r55;
	// end inline asm
	ld.const.u32 	%r64, [matrix+52];
	// begin inline asm
	dp4a.u32.u32 %r63, %r64, %r4097, %r59;
	// end inline asm
	ld.const.u32 	%r68, [matrix+56];
	// begin inline asm
	dp4a.u32.u32 %r67, %r68, %r4101, %r63;
	// end inline asm
	ld.const.u32 	%r72, [matrix+60];
	// begin inline asm
	dp4a.u32.u32 %r71, %r72, %r4105, %r67;
	// end inline asm
	ld.const.u32 	%r76, [matrix+64];
	// begin inline asm
	dp4a.u32.u32 %r75, %r76, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r80, [matrix+68];
	// begin inline asm
	dp4a.u32.u32 %r79, %r80, %r4049, %r75;
	// end inline asm
	ld.const.u32 	%r84, [matrix+72];
	// begin inline asm
	dp4a.u32.u32 %r83, %r84, %r4053, %r79;
	// end inline asm
	ld.const.u32 	%r88, [matrix+76];
	// begin inline asm
	dp4a.u32.u32 %r87, %r88, %r4057, %r83;
	// end inline asm
	ld.const.u32 	%r92, [matrix+80];
	// begin inline asm
	dp4a.u32.u32 %r91, %r92, %r4061, %r87;
	// end inline asm
	ld.const.u32 	%r96, [matrix+84];
	// begin inline asm
	dp4a.u32.u32 %r95, %r96, %r4065, %r91;
	// end inline asm
	ld.const.u32 	%r100, [matrix+88];
	// begin inline asm
	dp4a.u32.u32 %r99, %r100, %r4069, %r95;
	// end inline asm
	ld.const.u32 	%r104, [matrix+92];
	// begin inline asm
	dp4a.u32.u32 %r103, %r104, %r4073, %r99;
	// end inline asm
	ld.const.u32 	%r108, [matrix+96];
	// begin inline asm
	dp4a.u32.u32 %r107, %r108, %r4077, %r103;
	// end inline asm
	ld.const.u32 	%r112, [matrix+100];
	// begin inline asm
	dp4a.u32.u32 %r111, %r112, %r4081, %r107;
	// end inline asm
	ld.const.u32 	%r116, [matrix+104];
	// begin inline asm
	dp4a.u32.u32 %r115, %r116, %r4085, %r111;
	// end inline asm
	ld.const.u32 	%r120, [matrix+108];
	// begin inline asm
	dp4a.u32.u32 %r119, %r120, %r4089, %r115;
	// end inline asm
	ld.const.u32 	%r124, [matrix+112];
	// begin inline asm
	dp4a.u32.u32 %r123, %r124, %r4093, %r119;
	// end inline asm
	ld.const.u32 	%r128, [matrix+116];
	// begin inline asm
	dp4a.u32.u32 %r127, %r128, %r4097, %r123;
	// end inline asm
	ld.const.u32 	%r132, [matrix+120];
	// begin inline asm
	dp4a.u32.u32 %r131, %r132, %r4101, %r127;
	// end inline asm
	ld.const.u32 	%r136, [matrix+124];
	// begin inline asm
	dp4a.u32.u32 %r135, %r136, %r4105, %r131;
	// end inline asm
	shr.u32 	%r4291, %r71, 6;
	and.b32  	%r4292, %r4291, 240;
	shr.u32 	%r4293, %r135, 10;
	or.b32  	%r4294, %r4293, %r4292;
	cvt.u64.u32 	%rd378, %r4294;
	ld.const.u32 	%r140, [matrix+128];
	// begin inline asm
	dp4a.u32.u32 %r139, %r140, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r144, [matrix+132];
	// begin inline asm
	dp4a.u32.u32 %r143, %r144, %r4049, %r139;
	// end inline asm
	ld.const.u32 	%r148, [matrix+136];
	// begin inline asm
	dp4a.u32.u32 %r147, %r148, %r4053, %r143;
	// end inline asm
	ld.const.u32 	%r152, [matrix+140];
	// begin inline asm
	dp4a.u32.u32 %r151, %r152, %r4057, %r147;
	// end inline asm
	ld.const.u32 	%r156, [matrix+144];
	// begin inline asm
	dp4a.u32.u32 %r155, %r156, %r4061, %r151;
	// end inline asm
	ld.const.u32 	%r160, [matrix+148];
	// begin inline asm
	dp4a.u32.u32 %r159, %r160, %r4065, %r155;
	// end inline asm
	ld.const.u32 	%r164, [matrix+152];
	// begin inline asm
	dp4a.u32.u32 %r163, %r164, %r4069, %r159;
	// end inline asm
	ld.const.u32 	%r168, [matrix+156];
	// begin inline asm
	dp4a.u32.u32 %r167, %r168, %r4073, %r163;
	// end inline asm
	ld.const.u32 	%r172, [matrix+160];
	// begin inline asm
	dp4a.u32.u32 %r171, %r172, %r4077, %r167;
	// end inline asm
	ld.const.u32 	%r176, [matrix+164];
	// begin inline asm
	dp4a.u32.u32 %r175, %r176, %r4081, %r171;
	// end inline asm
	ld.const.u32 	%r180, [matrix+168];
	// begin inline asm
	dp4a.u32.u32 %r179, %r180, %r4085, %r175;
	// end inline asm
	ld.const.u32 	%r184, [matrix+172];
	// begin inline asm
	dp4a.u32.u32 %r183, %r184, %r4089, %r179;
	// end inline asm
	ld.const.u32 	%r188, [matrix+176];
	// begin inline asm
	dp4a.u32.u32 %r187, %r188, %r4093, %r183;
	// end inline asm
	ld.const.u32 	%r192, [matrix+180];
	// begin inline asm
	dp4a.u32.u32 %r191, %r192, %r4097, %r187;
	// end inline asm
	ld.const.u32 	%r196, [matrix+184];
	// begin inline asm
	dp4a.u32.u32 %r195, %r196, %r4101, %r191;
	// end inline asm
	ld.const.u32 	%r200, [matrix+188];
	// begin inline asm
	dp4a.u32.u32 %r199, %r200, %r4105, %r195;
	// end inline asm
	ld.const.u32 	%r204, [matrix+192];
	// begin inline asm
	dp4a.u32.u32 %r203, %r204, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r208, [matrix+196];
	// begin inline asm
	dp4a.u32.u32 %r207, %r208, %r4049, %r203;
	// end inline asm
	ld.const.u32 	%r212, [matrix+200];
	// begin inline asm
	dp4a.u32.u32 %r211, %r212, %r4053, %r207;
	// end inline asm
	ld.const.u32 	%r216, [matrix+204];
	// begin inline asm
	dp4a.u32.u32 %r215, %r216, %r4057, %r211;
	// end inline asm
	ld.const.u32 	%r220, [matrix+208];
	// begin inline asm
	dp4a.u32.u32 %r219, %r220, %r4061, %r215;
	// end inline asm
	ld.const.u32 	%r224, [matrix+212];
	// begin inline asm
	dp4a.u32.u32 %r223, %r224, %r4065, %r219;
	// end inline asm
	ld.const.u32 	%r228, [matrix+216];
	// begin inline asm
	dp4a.u32.u32 %r227, %r228, %r4069, %r223;
	// end inline asm
	ld.const.u32 	%r232, [matrix+220];
	// begin inline asm
	dp4a.u32.u32 %r231, %r232, %r4073, %r227;
	// end inline asm
	ld.const.u32 	%r236, [matrix+224];
	// begin inline asm
	dp4a.u32.u32 %r235, %r236, %r4077, %r231;
	// end inline asm
	ld.const.u32 	%r240, [matrix+228];
	// begin inline asm
	dp4a.u32.u32 %r239, %r240, %r4081, %r235;
	// end inline asm
	ld.const.u32 	%r244, [matrix+232];
	// begin inline asm
	dp4a.u32.u32 %r243, %r244, %r4085, %r239;
	// end inline asm
	ld.const.u32 	%r248, [matrix+236];
	// begin inline asm
	dp4a.u32.u32 %r247, %r248, %r4089, %r243;
	// end inline asm
	ld.const.u32 	%r252, [matrix+240];
	// begin inline asm
	dp4a.u32.u32 %r251, %r252, %r4093, %r247;
	// end inline asm
	ld.const.u32 	%r256, [matrix+244];
	// begin inline asm
	dp4a.u32.u32 %r255, %r256, %r4097, %r251;
	// end inline asm
	ld.const.u32 	%r260, [matrix+248];
	// begin inline asm
	dp4a.u32.u32 %r259, %r260, %r4101, %r255;
	// end inline asm
	ld.const.u32 	%r264, [matrix+252];
	// begin inline asm
	dp4a.u32.u32 %r263, %r264, %r4105, %r259;
	// end inline asm
	shr.u32 	%r4295, %r199, 6;
	and.b32  	%r4296, %r4295, 240;
	shr.u32 	%r4297, %r263, 10;
	or.b32  	%r4298, %r4297, %r4296;
	cvt.u64.u32 	%rd379, %r4298;
	xor.b64  	%rd380, %rd349, %rd379;
	ld.const.u32 	%r268, [matrix+256];
	// begin inline asm
	dp4a.u32.u32 %r267, %r268, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r272, [matrix+260];
	// begin inline asm
	dp4a.u32.u32 %r271, %r272, %r4049, %r267;
	// end inline asm
	ld.const.u32 	%r276, [matrix+264];
	// begin inline asm
	dp4a.u32.u32 %r275, %r276, %r4053, %r271;
	// end inline asm
	ld.const.u32 	%r280, [matrix+268];
	// begin inline asm
	dp4a.u32.u32 %r279, %r280, %r4057, %r275;
	// end inline asm
	ld.const.u32 	%r284, [matrix+272];
	// begin inline asm
	dp4a.u32.u32 %r283, %r284, %r4061, %r279;
	// end inline asm
	ld.const.u32 	%r288, [matrix+276];
	// begin inline asm
	dp4a.u32.u32 %r287, %r288, %r4065, %r283;
	// end inline asm
	ld.const.u32 	%r292, [matrix+280];
	// begin inline asm
	dp4a.u32.u32 %r291, %r292, %r4069, %r287;
	// end inline asm
	ld.const.u32 	%r296, [matrix+284];
	// begin inline asm
	dp4a.u32.u32 %r295, %r296, %r4073, %r291;
	// end inline asm
	ld.const.u32 	%r300, [matrix+288];
	// begin inline asm
	dp4a.u32.u32 %r299, %r300, %r4077, %r295;
	// end inline asm
	ld.const.u32 	%r304, [matrix+292];
	// begin inline asm
	dp4a.u32.u32 %r303, %r304, %r4081, %r299;
	// end inline asm
	ld.const.u32 	%r308, [matrix+296];
	// begin inline asm
	dp4a.u32.u32 %r307, %r308, %r4085, %r303;
	// end inline asm
	ld.const.u32 	%r312, [matrix+300];
	// begin inline asm
	dp4a.u32.u32 %r311, %r312, %r4089, %r307;
	// end inline asm
	ld.const.u32 	%r316, [matrix+304];
	// begin inline asm
	dp4a.u32.u32 %r315, %r316, %r4093, %r311;
	// end inline asm
	ld.const.u32 	%r320, [matrix+308];
	// begin inline asm
	dp4a.u32.u32 %r319, %r320, %r4097, %r315;
	// end inline asm
	ld.const.u32 	%r324, [matrix+312];
	// begin inline asm
	dp4a.u32.u32 %r323, %r324, %r4101, %r319;
	// end inline asm
	ld.const.u32 	%r328, [matrix+316];
	// begin inline asm
	dp4a.u32.u32 %r327, %r328, %r4105, %r323;
	// end inline asm
	ld.const.u32 	%r332, [matrix+320];
	// begin inline asm
	dp4a.u32.u32 %r331, %r332, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r336, [matrix+324];
	// begin inline asm
	dp4a.u32.u32 %r335, %r336, %r4049, %r331;
	// end inline asm
	ld.const.u32 	%r340, [matrix+328];
	// begin inline asm
	dp4a.u32.u32 %r339, %r340, %r4053, %r335;
	// end inline asm
	ld.const.u32 	%r344, [matrix+332];
	// begin inline asm
	dp4a.u32.u32 %r343, %r344, %r4057, %r339;
	// end inline asm
	ld.const.u32 	%r348, [matrix+336];
	// begin inline asm
	dp4a.u32.u32 %r347, %r348, %r4061, %r343;
	// end inline asm
	ld.const.u32 	%r352, [matrix+340];
	// begin inline asm
	dp4a.u32.u32 %r351, %r352, %r4065, %r347;
	// end inline asm
	ld.const.u32 	%r356, [matrix+344];
	// begin inline asm
	dp4a.u32.u32 %r355, %r356, %r4069, %r351;
	// end inline asm
	ld.const.u32 	%r360, [matrix+348];
	// begin inline asm
	dp4a.u32.u32 %r359, %r360, %r4073, %r355;
	// end inline asm
	ld.const.u32 	%r364, [matrix+352];
	// begin inline asm
	dp4a.u32.u32 %r363, %r364, %r4077, %r359;
	// end inline asm
	ld.const.u32 	%r368, [matrix+356];
	// begin inline asm
	dp4a.u32.u32 %r367, %r368, %r4081, %r363;
	// end inline asm
	ld.const.u32 	%r372, [matrix+360];
	// begin inline asm
	dp4a.u32.u32 %r371, %r372, %r4085, %r367;
	// end inline asm
	ld.const.u32 	%r376, [matrix+364];
	// begin inline asm
	dp4a.u32.u32 %r375, %r376, %r4089, %r371;
	// end inline asm
	ld.const.u32 	%r380, [matrix+368];
	// begin inline asm
	dp4a.u32.u32 %r379, %r380, %r4093, %r375;
	// end inline asm
	ld.const.u32 	%r384, [matrix+372];
	// begin inline asm
	dp4a.u32.u32 %r383, %r384, %r4097, %r379;
	// end inline asm
	ld.const.u32 	%r388, [matrix+376];
	// begin inline asm
	dp4a.u32.u32 %r387, %r388, %r4101, %r383;
	// end inline asm
	ld.const.u32 	%r392, [matrix+380];
	// begin inline asm
	dp4a.u32.u32 %r391, %r392, %r4105, %r387;
	// end inline asm
	shr.u32 	%r4299, %r327, 6;
	and.b32  	%r4300, %r4299, 240;
	shr.u32 	%r4301, %r391, 10;
	or.b32  	%r4302, %r4301, %r4300;
	cvt.u64.u32 	%rd381, %r4302;
	xor.b64  	%rd382, %rd350, %rd381;
	ld.const.u32 	%r396, [matrix+384];
	// begin inline asm
	dp4a.u32.u32 %r395, %r396, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r400, [matrix+388];
	// begin inline asm
	dp4a.u32.u32 %r399, %r400, %r4049, %r395;
	// end inline asm
	ld.const.u32 	%r404, [matrix+392];
	// begin inline asm
	dp4a.u32.u32 %r403, %r404, %r4053, %r399;
	// end inline asm
	ld.const.u32 	%r408, [matrix+396];
	// begin inline asm
	dp4a.u32.u32 %r407, %r408, %r4057, %r403;
	// end inline asm
	ld.const.u32 	%r412, [matrix+400];
	// begin inline asm
	dp4a.u32.u32 %r411, %r412, %r4061, %r407;
	// end inline asm
	ld.const.u32 	%r416, [matrix+404];
	// begin inline asm
	dp4a.u32.u32 %r415, %r416, %r4065, %r411;
	// end inline asm
	ld.const.u32 	%r420, [matrix+408];
	// begin inline asm
	dp4a.u32.u32 %r419, %r420, %r4069, %r415;
	// end inline asm
	ld.const.u32 	%r424, [matrix+412];
	// begin inline asm
	dp4a.u32.u32 %r423, %r424, %r4073, %r419;
	// end inline asm
	ld.const.u32 	%r428, [matrix+416];
	// begin inline asm
	dp4a.u32.u32 %r427, %r428, %r4077, %r423;
	// end inline asm
	ld.const.u32 	%r432, [matrix+420];
	// begin inline asm
	dp4a.u32.u32 %r431, %r432, %r4081, %r427;
	// end inline asm
	ld.const.u32 	%r436, [matrix+424];
	// begin inline asm
	dp4a.u32.u32 %r435, %r436, %r4085, %r431;
	// end inline asm
	ld.const.u32 	%r440, [matrix+428];
	// begin inline asm
	dp4a.u32.u32 %r439, %r440, %r4089, %r435;
	// end inline asm
	ld.const.u32 	%r444, [matrix+432];
	// begin inline asm
	dp4a.u32.u32 %r443, %r444, %r4093, %r439;
	// end inline asm
	ld.const.u32 	%r448, [matrix+436];
	// begin inline asm
	dp4a.u32.u32 %r447, %r448, %r4097, %r443;
	// end inline asm
	ld.const.u32 	%r452, [matrix+440];
	// begin inline asm
	dp4a.u32.u32 %r451, %r452, %r4101, %r447;
	// end inline asm
	ld.const.u32 	%r456, [matrix+444];
	// begin inline asm
	dp4a.u32.u32 %r455, %r456, %r4105, %r451;
	// end inline asm
	ld.const.u32 	%r460, [matrix+448];
	// begin inline asm
	dp4a.u32.u32 %r459, %r460, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r464, [matrix+452];
	// begin inline asm
	dp4a.u32.u32 %r463, %r464, %r4049, %r459;
	// end inline asm
	ld.const.u32 	%r468, [matrix+456];
	// begin inline asm
	dp4a.u32.u32 %r467, %r468, %r4053, %r463;
	// end inline asm
	ld.const.u32 	%r472, [matrix+460];
	// begin inline asm
	dp4a.u32.u32 %r471, %r472, %r4057, %r467;
	// end inline asm
	ld.const.u32 	%r476, [matrix+464];
	// begin inline asm
	dp4a.u32.u32 %r475, %r476, %r4061, %r471;
	// end inline asm
	ld.const.u32 	%r480, [matrix+468];
	// begin inline asm
	dp4a.u32.u32 %r479, %r480, %r4065, %r475;
	// end inline asm
	ld.const.u32 	%r484, [matrix+472];
	// begin inline asm
	dp4a.u32.u32 %r483, %r484, %r4069, %r479;
	// end inline asm
	ld.const.u32 	%r488, [matrix+476];
	// begin inline asm
	dp4a.u32.u32 %r487, %r488, %r4073, %r483;
	// end inline asm
	ld.const.u32 	%r492, [matrix+480];
	// begin inline asm
	dp4a.u32.u32 %r491, %r492, %r4077, %r487;
	// end inline asm
	ld.const.u32 	%r496, [matrix+484];
	// begin inline asm
	dp4a.u32.u32 %r495, %r496, %r4081, %r491;
	// end inline asm
	ld.const.u32 	%r500, [matrix+488];
	// begin inline asm
	dp4a.u32.u32 %r499, %r500, %r4085, %r495;
	// end inline asm
	ld.const.u32 	%r504, [matrix+492];
	// begin inline asm
	dp4a.u32.u32 %r503, %r504, %r4089, %r499;
	// end inline asm
	ld.const.u32 	%r508, [matrix+496];
	// begin inline asm
	dp4a.u32.u32 %r507, %r508, %r4093, %r503;
	// end inline asm
	ld.const.u32 	%r512, [matrix+500];
	// begin inline asm
	dp4a.u32.u32 %r511, %r512, %r4097, %r507;
	// end inline asm
	ld.const.u32 	%r516, [matrix+504];
	// begin inline asm
	dp4a.u32.u32 %r515, %r516, %r4101, %r511;
	// end inline asm
	ld.const.u32 	%r520, [matrix+508];
	// begin inline asm
	dp4a.u32.u32 %r519, %r520, %r4105, %r515;
	// end inline asm
	shr.u32 	%r4303, %r455, 6;
	and.b32  	%r4304, %r4303, 240;
	shr.u32 	%r4305, %r519, 10;
	or.b32  	%r4306, %r4305, %r4304;
	cvt.u64.u32 	%rd383, %r4306;
	xor.b64  	%rd384, %rd351, %rd383;
	ld.const.u32 	%r524, [matrix+512];
	// begin inline asm
	dp4a.u32.u32 %r523, %r524, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r528, [matrix+516];
	// begin inline asm
	dp4a.u32.u32 %r527, %r528, %r4049, %r523;
	// end inline asm
	ld.const.u32 	%r532, [matrix+520];
	// begin inline asm
	dp4a.u32.u32 %r531, %r532, %r4053, %r527;
	// end inline asm
	ld.const.u32 	%r536, [matrix+524];
	// begin inline asm
	dp4a.u32.u32 %r535, %r536, %r4057, %r531;
	// end inline asm
	ld.const.u32 	%r540, [matrix+528];
	// begin inline asm
	dp4a.u32.u32 %r539, %r540, %r4061, %r535;
	// end inline asm
	ld.const.u32 	%r544, [matrix+532];
	// begin inline asm
	dp4a.u32.u32 %r543, %r544, %r4065, %r539;
	// end inline asm
	ld.const.u32 	%r548, [matrix+536];
	// begin inline asm
	dp4a.u32.u32 %r547, %r548, %r4069, %r543;
	// end inline asm
	ld.const.u32 	%r552, [matrix+540];
	// begin inline asm
	dp4a.u32.u32 %r551, %r552, %r4073, %r547;
	// end inline asm
	ld.const.u32 	%r556, [matrix+544];
	// begin inline asm
	dp4a.u32.u32 %r555, %r556, %r4077, %r551;
	// end inline asm
	ld.const.u32 	%r560, [matrix+548];
	// begin inline asm
	dp4a.u32.u32 %r559, %r560, %r4081, %r555;
	// end inline asm
	ld.const.u32 	%r564, [matrix+552];
	// begin inline asm
	dp4a.u32.u32 %r563, %r564, %r4085, %r559;
	// end inline asm
	ld.const.u32 	%r568, [matrix+556];
	// begin inline asm
	dp4a.u32.u32 %r567, %r568, %r4089, %r563;
	// end inline asm
	ld.const.u32 	%r572, [matrix+560];
	// begin inline asm
	dp4a.u32.u32 %r571, %r572, %r4093, %r567;
	// end inline asm
	ld.const.u32 	%r576, [matrix+564];
	// begin inline asm
	dp4a.u32.u32 %r575, %r576, %r4097, %r571;
	// end inline asm
	ld.const.u32 	%r580, [matrix+568];
	// begin inline asm
	dp4a.u32.u32 %r579, %r580, %r4101, %r575;
	// end inline asm
	ld.const.u32 	%r584, [matrix+572];
	// begin inline asm
	dp4a.u32.u32 %r583, %r584, %r4105, %r579;
	// end inline asm
	ld.const.u32 	%r588, [matrix+576];
	// begin inline asm
	dp4a.u32.u32 %r587, %r588, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r592, [matrix+580];
	// begin inline asm
	dp4a.u32.u32 %r591, %r592, %r4049, %r587;
	// end inline asm
	ld.const.u32 	%r596, [matrix+584];
	// begin inline asm
	dp4a.u32.u32 %r595, %r596, %r4053, %r591;
	// end inline asm
	ld.const.u32 	%r600, [matrix+588];
	// begin inline asm
	dp4a.u32.u32 %r599, %r600, %r4057, %r595;
	// end inline asm
	ld.const.u32 	%r604, [matrix+592];
	// begin inline asm
	dp4a.u32.u32 %r603, %r604, %r4061, %r599;
	// end inline asm
	ld.const.u32 	%r608, [matrix+596];
	// begin inline asm
	dp4a.u32.u32 %r607, %r608, %r4065, %r603;
	// end inline asm
	ld.const.u32 	%r612, [matrix+600];
	// begin inline asm
	dp4a.u32.u32 %r611, %r612, %r4069, %r607;
	// end inline asm
	ld.const.u32 	%r616, [matrix+604];
	// begin inline asm
	dp4a.u32.u32 %r615, %r616, %r4073, %r611;
	// end inline asm
	ld.const.u32 	%r620, [matrix+608];
	// begin inline asm
	dp4a.u32.u32 %r619, %r620, %r4077, %r615;
	// end inline asm
	ld.const.u32 	%r624, [matrix+612];
	// begin inline asm
	dp4a.u32.u32 %r623, %r624, %r4081, %r619;
	// end inline asm
	ld.const.u32 	%r628, [matrix+616];
	// begin inline asm
	dp4a.u32.u32 %r627, %r628, %r4085, %r623;
	// end inline asm
	ld.const.u32 	%r632, [matrix+620];
	// begin inline asm
	dp4a.u32.u32 %r631, %r632, %r4089, %r627;
	// end inline asm
	ld.const.u32 	%r636, [matrix+624];
	// begin inline asm
	dp4a.u32.u32 %r635, %r636, %r4093, %r631;
	// end inline asm
	ld.const.u32 	%r640, [matrix+628];
	// begin inline asm
	dp4a.u32.u32 %r639, %r640, %r4097, %r635;
	// end inline asm
	ld.const.u32 	%r644, [matrix+632];
	// begin inline asm
	dp4a.u32.u32 %r643, %r644, %r4101, %r639;
	// end inline asm
	ld.const.u32 	%r648, [matrix+636];
	// begin inline asm
	dp4a.u32.u32 %r647, %r648, %r4105, %r643;
	// end inline asm
	shr.u32 	%r4307, %r583, 6;
	and.b32  	%r4308, %r4307, 240;
	shr.u32 	%r4309, %r647, 10;
	or.b32  	%r4310, %r4309, %r4308;
	cvt.u64.u32 	%rd385, %r4310;
	xor.b64  	%rd386, %rd352, %rd385;
	ld.const.u32 	%r652, [matrix+640];
	// begin inline asm
	dp4a.u32.u32 %r651, %r652, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r656, [matrix+644];
	// begin inline asm
	dp4a.u32.u32 %r655, %r656, %r4049, %r651;
	// end inline asm
	ld.const.u32 	%r660, [matrix+648];
	// begin inline asm
	dp4a.u32.u32 %r659, %r660, %r4053, %r655;
	// end inline asm
	ld.const.u32 	%r664, [matrix+652];
	// begin inline asm
	dp4a.u32.u32 %r663, %r664, %r4057, %r659;
	// end inline asm
	ld.const.u32 	%r668, [matrix+656];
	// begin inline asm
	dp4a.u32.u32 %r667, %r668, %r4061, %r663;
	// end inline asm
	ld.const.u32 	%r672, [matrix+660];
	// begin inline asm
	dp4a.u32.u32 %r671, %r672, %r4065, %r667;
	// end inline asm
	ld.const.u32 	%r676, [matrix+664];
	// begin inline asm
	dp4a.u32.u32 %r675, %r676, %r4069, %r671;
	// end inline asm
	ld.const.u32 	%r680, [matrix+668];
	// begin inline asm
	dp4a.u32.u32 %r679, %r680, %r4073, %r675;
	// end inline asm
	ld.const.u32 	%r684, [matrix+672];
	// begin inline asm
	dp4a.u32.u32 %r683, %r684, %r4077, %r679;
	// end inline asm
	ld.const.u32 	%r688, [matrix+676];
	// begin inline asm
	dp4a.u32.u32 %r687, %r688, %r4081, %r683;
	// end inline asm
	ld.const.u32 	%r692, [matrix+680];
	// begin inline asm
	dp4a.u32.u32 %r691, %r692, %r4085, %r687;
	// end inline asm
	ld.const.u32 	%r696, [matrix+684];
	// begin inline asm
	dp4a.u32.u32 %r695, %r696, %r4089, %r691;
	// end inline asm
	ld.const.u32 	%r700, [matrix+688];
	// begin inline asm
	dp4a.u32.u32 %r699, %r700, %r4093, %r695;
	// end inline asm
	ld.const.u32 	%r704, [matrix+692];
	// begin inline asm
	dp4a.u32.u32 %r703, %r704, %r4097, %r699;
	// end inline asm
	ld.const.u32 	%r708, [matrix+696];
	// begin inline asm
	dp4a.u32.u32 %r707, %r708, %r4101, %r703;
	// end inline asm
	ld.const.u32 	%r712, [matrix+700];
	// begin inline asm
	dp4a.u32.u32 %r711, %r712, %r4105, %r707;
	// end inline asm
	ld.const.u32 	%r716, [matrix+704];
	// begin inline asm
	dp4a.u32.u32 %r715, %r716, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r720, [matrix+708];
	// begin inline asm
	dp4a.u32.u32 %r719, %r720, %r4049, %r715;
	// end inline asm
	ld.const.u32 	%r724, [matrix+712];
	// begin inline asm
	dp4a.u32.u32 %r723, %r724, %r4053, %r719;
	// end inline asm
	ld.const.u32 	%r728, [matrix+716];
	// begin inline asm
	dp4a.u32.u32 %r727, %r728, %r4057, %r723;
	// end inline asm
	ld.const.u32 	%r732, [matrix+720];
	// begin inline asm
	dp4a.u32.u32 %r731, %r732, %r4061, %r727;
	// end inline asm
	ld.const.u32 	%r736, [matrix+724];
	// begin inline asm
	dp4a.u32.u32 %r735, %r736, %r4065, %r731;
	// end inline asm
	ld.const.u32 	%r740, [matrix+728];
	// begin inline asm
	dp4a.u32.u32 %r739, %r740, %r4069, %r735;
	// end inline asm
	ld.const.u32 	%r744, [matrix+732];
	// begin inline asm
	dp4a.u32.u32 %r743, %r744, %r4073, %r739;
	// end inline asm
	ld.const.u32 	%r748, [matrix+736];
	// begin inline asm
	dp4a.u32.u32 %r747, %r748, %r4077, %r743;
	// end inline asm
	ld.const.u32 	%r752, [matrix+740];
	// begin inline asm
	dp4a.u32.u32 %r751, %r752, %r4081, %r747;
	// end inline asm
	ld.const.u32 	%r756, [matrix+744];
	// begin inline asm
	dp4a.u32.u32 %r755, %r756, %r4085, %r751;
	// end inline asm
	ld.const.u32 	%r760, [matrix+748];
	// begin inline asm
	dp4a.u32.u32 %r759, %r760, %r4089, %r755;
	// end inline asm
	ld.const.u32 	%r764, [matrix+752];
	// begin inline asm
	dp4a.u32.u32 %r763, %r764, %r4093, %r759;
	// end inline asm
	ld.const.u32 	%r768, [matrix+756];
	// begin inline asm
	dp4a.u32.u32 %r767, %r768, %r4097, %r763;
	// end inline asm
	ld.const.u32 	%r772, [matrix+760];
	// begin inline asm
	dp4a.u32.u32 %r771, %r772, %r4101, %r767;
	// end inline asm
	ld.const.u32 	%r776, [matrix+764];
	// begin inline asm
	dp4a.u32.u32 %r775, %r776, %r4105, %r771;
	// end inline asm
	shr.u32 	%r4311, %r711, 6;
	and.b32  	%r4312, %r4311, 240;
	shr.u32 	%r4313, %r775, 10;
	or.b32  	%r4314, %r4313, %r4312;
	cvt.u64.u32 	%rd387, %r4314;
	xor.b64  	%rd388, %rd353, %rd387;
	ld.const.u32 	%r780, [matrix+768];
	// begin inline asm
	dp4a.u32.u32 %r779, %r780, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r784, [matrix+772];
	// begin inline asm
	dp4a.u32.u32 %r783, %r784, %r4049, %r779;
	// end inline asm
	ld.const.u32 	%r788, [matrix+776];
	// begin inline asm
	dp4a.u32.u32 %r787, %r788, %r4053, %r783;
	// end inline asm
	ld.const.u32 	%r792, [matrix+780];
	// begin inline asm
	dp4a.u32.u32 %r791, %r792, %r4057, %r787;
	// end inline asm
	ld.const.u32 	%r796, [matrix+784];
	// begin inline asm
	dp4a.u32.u32 %r795, %r796, %r4061, %r791;
	// end inline asm
	ld.const.u32 	%r800, [matrix+788];
	// begin inline asm
	dp4a.u32.u32 %r799, %r800, %r4065, %r795;
	// end inline asm
	ld.const.u32 	%r804, [matrix+792];
	// begin inline asm
	dp4a.u32.u32 %r803, %r804, %r4069, %r799;
	// end inline asm
	ld.const.u32 	%r808, [matrix+796];
	// begin inline asm
	dp4a.u32.u32 %r807, %r808, %r4073, %r803;
	// end inline asm
	ld.const.u32 	%r812, [matrix+800];
	// begin inline asm
	dp4a.u32.u32 %r811, %r812, %r4077, %r807;
	// end inline asm
	ld.const.u32 	%r816, [matrix+804];
	// begin inline asm
	dp4a.u32.u32 %r815, %r816, %r4081, %r811;
	// end inline asm
	ld.const.u32 	%r820, [matrix+808];
	// begin inline asm
	dp4a.u32.u32 %r819, %r820, %r4085, %r815;
	// end inline asm
	ld.const.u32 	%r824, [matrix+812];
	// begin inline asm
	dp4a.u32.u32 %r823, %r824, %r4089, %r819;
	// end inline asm
	ld.const.u32 	%r828, [matrix+816];
	// begin inline asm
	dp4a.u32.u32 %r827, %r828, %r4093, %r823;
	// end inline asm
	ld.const.u32 	%r832, [matrix+820];
	// begin inline asm
	dp4a.u32.u32 %r831, %r832, %r4097, %r827;
	// end inline asm
	ld.const.u32 	%r836, [matrix+824];
	// begin inline asm
	dp4a.u32.u32 %r835, %r836, %r4101, %r831;
	// end inline asm
	ld.const.u32 	%r840, [matrix+828];
	// begin inline asm
	dp4a.u32.u32 %r839, %r840, %r4105, %r835;
	// end inline asm
	ld.const.u32 	%r844, [matrix+832];
	// begin inline asm
	dp4a.u32.u32 %r843, %r844, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r848, [matrix+836];
	// begin inline asm
	dp4a.u32.u32 %r847, %r848, %r4049, %r843;
	// end inline asm
	ld.const.u32 	%r852, [matrix+840];
	// begin inline asm
	dp4a.u32.u32 %r851, %r852, %r4053, %r847;
	// end inline asm
	ld.const.u32 	%r856, [matrix+844];
	// begin inline asm
	dp4a.u32.u32 %r855, %r856, %r4057, %r851;
	// end inline asm
	ld.const.u32 	%r860, [matrix+848];
	// begin inline asm
	dp4a.u32.u32 %r859, %r860, %r4061, %r855;
	// end inline asm
	ld.const.u32 	%r864, [matrix+852];
	// begin inline asm
	dp4a.u32.u32 %r863, %r864, %r4065, %r859;
	// end inline asm
	ld.const.u32 	%r868, [matrix+856];
	// begin inline asm
	dp4a.u32.u32 %r867, %r868, %r4069, %r863;
	// end inline asm
	ld.const.u32 	%r872, [matrix+860];
	// begin inline asm
	dp4a.u32.u32 %r871, %r872, %r4073, %r867;
	// end inline asm
	ld.const.u32 	%r876, [matrix+864];
	// begin inline asm
	dp4a.u32.u32 %r875, %r876, %r4077, %r871;
	// end inline asm
	ld.const.u32 	%r880, [matrix+868];
	// begin inline asm
	dp4a.u32.u32 %r879, %r880, %r4081, %r875;
	// end inline asm
	ld.const.u32 	%r884, [matrix+872];
	// begin inline asm
	dp4a.u32.u32 %r883, %r884, %r4085, %r879;
	// end inline asm
	ld.const.u32 	%r888, [matrix+876];
	// begin inline asm
	dp4a.u32.u32 %r887, %r888, %r4089, %r883;
	// end inline asm
	ld.const.u32 	%r892, [matrix+880];
	// begin inline asm
	dp4a.u32.u32 %r891, %r892, %r4093, %r887;
	// end inline asm
	ld.const.u32 	%r896, [matrix+884];
	// begin inline asm
	dp4a.u32.u32 %r895, %r896, %r4097, %r891;
	// end inline asm
	ld.const.u32 	%r900, [matrix+888];
	// begin inline asm
	dp4a.u32.u32 %r899, %r900, %r4101, %r895;
	// end inline asm
	ld.const.u32 	%r904, [matrix+892];
	// begin inline asm
	dp4a.u32.u32 %r903, %r904, %r4105, %r899;
	// end inline asm
	shr.u32 	%r4315, %r839, 6;
	and.b32  	%r4316, %r4315, 240;
	shr.u32 	%r4317, %r903, 10;
	or.b32  	%r4318, %r4317, %r4316;
	cvt.u64.u32 	%rd389, %r4318;
	xor.b64  	%rd390, %rd354, %rd389;
	ld.const.u32 	%r908, [matrix+896];
	// begin inline asm
	dp4a.u32.u32 %r907, %r908, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r912, [matrix+900];
	// begin inline asm
	dp4a.u32.u32 %r911, %r912, %r4049, %r907;
	// end inline asm
	ld.const.u32 	%r916, [matrix+904];
	// begin inline asm
	dp4a.u32.u32 %r915, %r916, %r4053, %r911;
	// end inline asm
	ld.const.u32 	%r920, [matrix+908];
	// begin inline asm
	dp4a.u32.u32 %r919, %r920, %r4057, %r915;
	// end inline asm
	ld.const.u32 	%r924, [matrix+912];
	// begin inline asm
	dp4a.u32.u32 %r923, %r924, %r4061, %r919;
	// end inline asm
	ld.const.u32 	%r928, [matrix+916];
	// begin inline asm
	dp4a.u32.u32 %r927, %r928, %r4065, %r923;
	// end inline asm
	ld.const.u32 	%r932, [matrix+920];
	// begin inline asm
	dp4a.u32.u32 %r931, %r932, %r4069, %r927;
	// end inline asm
	ld.const.u32 	%r936, [matrix+924];
	// begin inline asm
	dp4a.u32.u32 %r935, %r936, %r4073, %r931;
	// end inline asm
	ld.const.u32 	%r940, [matrix+928];
	// begin inline asm
	dp4a.u32.u32 %r939, %r940, %r4077, %r935;
	// end inline asm
	ld.const.u32 	%r944, [matrix+932];
	// begin inline asm
	dp4a.u32.u32 %r943, %r944, %r4081, %r939;
	// end inline asm
	ld.const.u32 	%r948, [matrix+936];
	// begin inline asm
	dp4a.u32.u32 %r947, %r948, %r4085, %r943;
	// end inline asm
	ld.const.u32 	%r952, [matrix+940];
	// begin inline asm
	dp4a.u32.u32 %r951, %r952, %r4089, %r947;
	// end inline asm
	ld.const.u32 	%r956, [matrix+944];
	// begin inline asm
	dp4a.u32.u32 %r955, %r956, %r4093, %r951;
	// end inline asm
	ld.const.u32 	%r960, [matrix+948];
	// begin inline asm
	dp4a.u32.u32 %r959, %r960, %r4097, %r955;
	// end inline asm
	ld.const.u32 	%r964, [matrix+952];
	// begin inline asm
	dp4a.u32.u32 %r963, %r964, %r4101, %r959;
	// end inline asm
	ld.const.u32 	%r968, [matrix+956];
	// begin inline asm
	dp4a.u32.u32 %r967, %r968, %r4105, %r963;
	// end inline asm
	ld.const.u32 	%r972, [matrix+960];
	// begin inline asm
	dp4a.u32.u32 %r971, %r972, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r976, [matrix+964];
	// begin inline asm
	dp4a.u32.u32 %r975, %r976, %r4049, %r971;
	// end inline asm
	ld.const.u32 	%r980, [matrix+968];
	// begin inline asm
	dp4a.u32.u32 %r979, %r980, %r4053, %r975;
	// end inline asm
	ld.const.u32 	%r984, [matrix+972];
	// begin inline asm
	dp4a.u32.u32 %r983, %r984, %r4057, %r979;
	// end inline asm
	ld.const.u32 	%r988, [matrix+976];
	// begin inline asm
	dp4a.u32.u32 %r987, %r988, %r4061, %r983;
	// end inline asm
	ld.const.u32 	%r992, [matrix+980];
	// begin inline asm
	dp4a.u32.u32 %r991, %r992, %r4065, %r987;
	// end inline asm
	ld.const.u32 	%r996, [matrix+984];
	// begin inline asm
	dp4a.u32.u32 %r995, %r996, %r4069, %r991;
	// end inline asm
	ld.const.u32 	%r1000, [matrix+988];
	// begin inline asm
	dp4a.u32.u32 %r999, %r1000, %r4073, %r995;
	// end inline asm
	ld.const.u32 	%r1004, [matrix+992];
	// begin inline asm
	dp4a.u32.u32 %r1003, %r1004, %r4077, %r999;
	// end inline asm
	ld.const.u32 	%r1008, [matrix+996];
	// begin inline asm
	dp4a.u32.u32 %r1007, %r1008, %r4081, %r1003;
	// end inline asm
	ld.const.u32 	%r1012, [matrix+1000];
	// begin inline asm
	dp4a.u32.u32 %r1011, %r1012, %r4085, %r1007;
	// end inline asm
	ld.const.u32 	%r1016, [matrix+1004];
	// begin inline asm
	dp4a.u32.u32 %r1015, %r1016, %r4089, %r1011;
	// end inline asm
	ld.const.u32 	%r1020, [matrix+1008];
	// begin inline asm
	dp4a.u32.u32 %r1019, %r1020, %r4093, %r1015;
	// end inline asm
	ld.const.u32 	%r1024, [matrix+1012];
	// begin inline asm
	dp4a.u32.u32 %r1023, %r1024, %r4097, %r1019;
	// end inline asm
	ld.const.u32 	%r1028, [matrix+1016];
	// begin inline asm
	dp4a.u32.u32 %r1027, %r1028, %r4101, %r1023;
	// end inline asm
	ld.const.u32 	%r1032, [matrix+1020];
	// begin inline asm
	dp4a.u32.u32 %r1031, %r1032, %r4105, %r1027;
	// end inline asm
	shr.u32 	%r4319, %r967, 6;
	and.b32  	%r4320, %r4319, 240;
	shr.u32 	%r4321, %r1031, 10;
	or.b32  	%r4322, %r4321, %r4320;
	cvt.u64.u32 	%rd391, %r4322;
	xor.b64  	%rd392, %rd672, %rd391;
	ld.const.u32 	%r1036, [matrix+1024];
	// begin inline asm
	dp4a.u32.u32 %r1035, %r1036, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1040, [matrix+1028];
	// begin inline asm
	dp4a.u32.u32 %r1039, %r1040, %r4049, %r1035;
	// end inline asm
	ld.const.u32 	%r1044, [matrix+1032];
	// begin inline asm
	dp4a.u32.u32 %r1043, %r1044, %r4053, %r1039;
	// end inline asm
	ld.const.u32 	%r1048, [matrix+1036];
	// begin inline asm
	dp4a.u32.u32 %r1047, %r1048, %r4057, %r1043;
	// end inline asm
	ld.const.u32 	%r1052, [matrix+1040];
	// begin inline asm
	dp4a.u32.u32 %r1051, %r1052, %r4061, %r1047;
	// end inline asm
	ld.const.u32 	%r1056, [matrix+1044];
	// begin inline asm
	dp4a.u32.u32 %r1055, %r1056, %r4065, %r1051;
	// end inline asm
	ld.const.u32 	%r1060, [matrix+1048];
	// begin inline asm
	dp4a.u32.u32 %r1059, %r1060, %r4069, %r1055;
	// end inline asm
	ld.const.u32 	%r1064, [matrix+1052];
	// begin inline asm
	dp4a.u32.u32 %r1063, %r1064, %r4073, %r1059;
	// end inline asm
	ld.const.u32 	%r1068, [matrix+1056];
	// begin inline asm
	dp4a.u32.u32 %r1067, %r1068, %r4077, %r1063;
	// end inline asm
	ld.const.u32 	%r1072, [matrix+1060];
	// begin inline asm
	dp4a.u32.u32 %r1071, %r1072, %r4081, %r1067;
	// end inline asm
	ld.const.u32 	%r1076, [matrix+1064];
	// begin inline asm
	dp4a.u32.u32 %r1075, %r1076, %r4085, %r1071;
	// end inline asm
	ld.const.u32 	%r1080, [matrix+1068];
	// begin inline asm
	dp4a.u32.u32 %r1079, %r1080, %r4089, %r1075;
	// end inline asm
	ld.const.u32 	%r1084, [matrix+1072];
	// begin inline asm
	dp4a.u32.u32 %r1083, %r1084, %r4093, %r1079;
	// end inline asm
	ld.const.u32 	%r1088, [matrix+1076];
	// begin inline asm
	dp4a.u32.u32 %r1087, %r1088, %r4097, %r1083;
	// end inline asm
	ld.const.u32 	%r1092, [matrix+1080];
	// begin inline asm
	dp4a.u32.u32 %r1091, %r1092, %r4101, %r1087;
	// end inline asm
	ld.const.u32 	%r1096, [matrix+1084];
	// begin inline asm
	dp4a.u32.u32 %r1095, %r1096, %r4105, %r1091;
	// end inline asm
	ld.const.u32 	%r1100, [matrix+1088];
	// begin inline asm
	dp4a.u32.u32 %r1099, %r1100, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1104, [matrix+1092];
	// begin inline asm
	dp4a.u32.u32 %r1103, %r1104, %r4049, %r1099;
	// end inline asm
	ld.const.u32 	%r1108, [matrix+1096];
	// begin inline asm
	dp4a.u32.u32 %r1107, %r1108, %r4053, %r1103;
	// end inline asm
	ld.const.u32 	%r1112, [matrix+1100];
	// begin inline asm
	dp4a.u32.u32 %r1111, %r1112, %r4057, %r1107;
	// end inline asm
	ld.const.u32 	%r1116, [matrix+1104];
	// begin inline asm
	dp4a.u32.u32 %r1115, %r1116, %r4061, %r1111;
	// end inline asm
	ld.const.u32 	%r1120, [matrix+1108];
	// begin inline asm
	dp4a.u32.u32 %r1119, %r1120, %r4065, %r1115;
	// end inline asm
	ld.const.u32 	%r1124, [matrix+1112];
	// begin inline asm
	dp4a.u32.u32 %r1123, %r1124, %r4069, %r1119;
	// end inline asm
	ld.const.u32 	%r1128, [matrix+1116];
	// begin inline asm
	dp4a.u32.u32 %r1127, %r1128, %r4073, %r1123;
	// end inline asm
	ld.const.u32 	%r1132, [matrix+1120];
	// begin inline asm
	dp4a.u32.u32 %r1131, %r1132, %r4077, %r1127;
	// end inline asm
	ld.const.u32 	%r1136, [matrix+1124];
	// begin inline asm
	dp4a.u32.u32 %r1135, %r1136, %r4081, %r1131;
	// end inline asm
	ld.const.u32 	%r1140, [matrix+1128];
	// begin inline asm
	dp4a.u32.u32 %r1139, %r1140, %r4085, %r1135;
	// end inline asm
	ld.const.u32 	%r1144, [matrix+1132];
	// begin inline asm
	dp4a.u32.u32 %r1143, %r1144, %r4089, %r1139;
	// end inline asm
	ld.const.u32 	%r1148, [matrix+1136];
	// begin inline asm
	dp4a.u32.u32 %r1147, %r1148, %r4093, %r1143;
	// end inline asm
	ld.const.u32 	%r1152, [matrix+1140];
	// begin inline asm
	dp4a.u32.u32 %r1151, %r1152, %r4097, %r1147;
	// end inline asm
	ld.const.u32 	%r1156, [matrix+1144];
	// begin inline asm
	dp4a.u32.u32 %r1155, %r1156, %r4101, %r1151;
	// end inline asm
	ld.const.u32 	%r1160, [matrix+1148];
	// begin inline asm
	dp4a.u32.u32 %r1159, %r1160, %r4105, %r1155;
	// end inline asm
	shr.u32 	%r4323, %r1095, 6;
	and.b32  	%r4324, %r4323, 240;
	shr.u32 	%r4325, %r1159, 10;
	or.b32  	%r4326, %r4325, %r4324;
	cvt.u64.u32 	%rd393, %r4326;
	ld.const.u32 	%r1164, [matrix+1152];
	// begin inline asm
	dp4a.u32.u32 %r1163, %r1164, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1168, [matrix+1156];
	// begin inline asm
	dp4a.u32.u32 %r1167, %r1168, %r4049, %r1163;
	// end inline asm
	ld.const.u32 	%r1172, [matrix+1160];
	// begin inline asm
	dp4a.u32.u32 %r1171, %r1172, %r4053, %r1167;
	// end inline asm
	ld.const.u32 	%r1176, [matrix+1164];
	// begin inline asm
	dp4a.u32.u32 %r1175, %r1176, %r4057, %r1171;
	// end inline asm
	ld.const.u32 	%r1180, [matrix+1168];
	// begin inline asm
	dp4a.u32.u32 %r1179, %r1180, %r4061, %r1175;
	// end inline asm
	ld.const.u32 	%r1184, [matrix+1172];
	// begin inline asm
	dp4a.u32.u32 %r1183, %r1184, %r4065, %r1179;
	// end inline asm
	ld.const.u32 	%r1188, [matrix+1176];
	// begin inline asm
	dp4a.u32.u32 %r1187, %r1188, %r4069, %r1183;
	// end inline asm
	ld.const.u32 	%r1192, [matrix+1180];
	// begin inline asm
	dp4a.u32.u32 %r1191, %r1192, %r4073, %r1187;
	// end inline asm
	ld.const.u32 	%r1196, [matrix+1184];
	// begin inline asm
	dp4a.u32.u32 %r1195, %r1196, %r4077, %r1191;
	// end inline asm
	ld.const.u32 	%r1200, [matrix+1188];
	// begin inline asm
	dp4a.u32.u32 %r1199, %r1200, %r4081, %r1195;
	// end inline asm
	ld.const.u32 	%r1204, [matrix+1192];
	// begin inline asm
	dp4a.u32.u32 %r1203, %r1204, %r4085, %r1199;
	// end inline asm
	ld.const.u32 	%r1208, [matrix+1196];
	// begin inline asm
	dp4a.u32.u32 %r1207, %r1208, %r4089, %r1203;
	// end inline asm
	ld.const.u32 	%r1212, [matrix+1200];
	// begin inline asm
	dp4a.u32.u32 %r1211, %r1212, %r4093, %r1207;
	// end inline asm
	ld.const.u32 	%r1216, [matrix+1204];
	// begin inline asm
	dp4a.u32.u32 %r1215, %r1216, %r4097, %r1211;
	// end inline asm
	ld.const.u32 	%r1220, [matrix+1208];
	// begin inline asm
	dp4a.u32.u32 %r1219, %r1220, %r4101, %r1215;
	// end inline asm
	ld.const.u32 	%r1224, [matrix+1212];
	// begin inline asm
	dp4a.u32.u32 %r1223, %r1224, %r4105, %r1219;
	// end inline asm
	ld.const.u32 	%r1228, [matrix+1216];
	// begin inline asm
	dp4a.u32.u32 %r1227, %r1228, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1232, [matrix+1220];
	// begin inline asm
	dp4a.u32.u32 %r1231, %r1232, %r4049, %r1227;
	// end inline asm
	ld.const.u32 	%r1236, [matrix+1224];
	// begin inline asm
	dp4a.u32.u32 %r1235, %r1236, %r4053, %r1231;
	// end inline asm
	ld.const.u32 	%r1240, [matrix+1228];
	// begin inline asm
	dp4a.u32.u32 %r1239, %r1240, %r4057, %r1235;
	// end inline asm
	ld.const.u32 	%r1244, [matrix+1232];
	// begin inline asm
	dp4a.u32.u32 %r1243, %r1244, %r4061, %r1239;
	// end inline asm
	ld.const.u32 	%r1248, [matrix+1236];
	// begin inline asm
	dp4a.u32.u32 %r1247, %r1248, %r4065, %r1243;
	// end inline asm
	ld.const.u32 	%r1252, [matrix+1240];
	// begin inline asm
	dp4a.u32.u32 %r1251, %r1252, %r4069, %r1247;
	// end inline asm
	ld.const.u32 	%r1256, [matrix+1244];
	// begin inline asm
	dp4a.u32.u32 %r1255, %r1256, %r4073, %r1251;
	// end inline asm
	ld.const.u32 	%r1260, [matrix+1248];
	// begin inline asm
	dp4a.u32.u32 %r1259, %r1260, %r4077, %r1255;
	// end inline asm
	ld.const.u32 	%r1264, [matrix+1252];
	// begin inline asm
	dp4a.u32.u32 %r1263, %r1264, %r4081, %r1259;
	// end inline asm
	ld.const.u32 	%r1268, [matrix+1256];
	// begin inline asm
	dp4a.u32.u32 %r1267, %r1268, %r4085, %r1263;
	// end inline asm
	ld.const.u32 	%r1272, [matrix+1260];
	// begin inline asm
	dp4a.u32.u32 %r1271, %r1272, %r4089, %r1267;
	// end inline asm
	ld.const.u32 	%r1276, [matrix+1264];
	// begin inline asm
	dp4a.u32.u32 %r1275, %r1276, %r4093, %r1271;
	// end inline asm
	ld.const.u32 	%r1280, [matrix+1268];
	// begin inline asm
	dp4a.u32.u32 %r1279, %r1280, %r4097, %r1275;
	// end inline asm
	ld.const.u32 	%r1284, [matrix+1272];
	// begin inline asm
	dp4a.u32.u32 %r1283, %r1284, %r4101, %r1279;
	// end inline asm
	ld.const.u32 	%r1288, [matrix+1276];
	// begin inline asm
	dp4a.u32.u32 %r1287, %r1288, %r4105, %r1283;
	// end inline asm
	shr.u32 	%r4327, %r1223, 6;
	and.b32  	%r4328, %r4327, 240;
	shr.u32 	%r4329, %r1287, 10;
	or.b32  	%r4330, %r4329, %r4328;
	cvt.u64.u32 	%rd394, %r4330;
	xor.b64  	%rd395, %rd346, %rd394;
	ld.const.u32 	%r1292, [matrix+1280];
	// begin inline asm
	dp4a.u32.u32 %r1291, %r1292, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1296, [matrix+1284];
	// begin inline asm
	dp4a.u32.u32 %r1295, %r1296, %r4049, %r1291;
	// end inline asm
	ld.const.u32 	%r1300, [matrix+1288];
	// begin inline asm
	dp4a.u32.u32 %r1299, %r1300, %r4053, %r1295;
	// end inline asm
	ld.const.u32 	%r1304, [matrix+1292];
	// begin inline asm
	dp4a.u32.u32 %r1303, %r1304, %r4057, %r1299;
	// end inline asm
	ld.const.u32 	%r1308, [matrix+1296];
	// begin inline asm
	dp4a.u32.u32 %r1307, %r1308, %r4061, %r1303;
	// end inline asm
	ld.const.u32 	%r1312, [matrix+1300];
	// begin inline asm
	dp4a.u32.u32 %r1311, %r1312, %r4065, %r1307;
	// end inline asm
	ld.const.u32 	%r1316, [matrix+1304];
	// begin inline asm
	dp4a.u32.u32 %r1315, %r1316, %r4069, %r1311;
	// end inline asm
	ld.const.u32 	%r1320, [matrix+1308];
	// begin inline asm
	dp4a.u32.u32 %r1319, %r1320, %r4073, %r1315;
	// end inline asm
	ld.const.u32 	%r1324, [matrix+1312];
	// begin inline asm
	dp4a.u32.u32 %r1323, %r1324, %r4077, %r1319;
	// end inline asm
	ld.const.u32 	%r1328, [matrix+1316];
	// begin inline asm
	dp4a.u32.u32 %r1327, %r1328, %r4081, %r1323;
	// end inline asm
	ld.const.u32 	%r1332, [matrix+1320];
	// begin inline asm
	dp4a.u32.u32 %r1331, %r1332, %r4085, %r1327;
	// end inline asm
	ld.const.u32 	%r1336, [matrix+1324];
	// begin inline asm
	dp4a.u32.u32 %r1335, %r1336, %r4089, %r1331;
	// end inline asm
	ld.const.u32 	%r1340, [matrix+1328];
	// begin inline asm
	dp4a.u32.u32 %r1339, %r1340, %r4093, %r1335;
	// end inline asm
	ld.const.u32 	%r1344, [matrix+1332];
	// begin inline asm
	dp4a.u32.u32 %r1343, %r1344, %r4097, %r1339;
	// end inline asm
	ld.const.u32 	%r1348, [matrix+1336];
	// begin inline asm
	dp4a.u32.u32 %r1347, %r1348, %r4101, %r1343;
	// end inline asm
	ld.const.u32 	%r1352, [matrix+1340];
	// begin inline asm
	dp4a.u32.u32 %r1351, %r1352, %r4105, %r1347;
	// end inline asm
	ld.const.u32 	%r1356, [matrix+1344];
	// begin inline asm
	dp4a.u32.u32 %r1355, %r1356, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1360, [matrix+1348];
	// begin inline asm
	dp4a.u32.u32 %r1359, %r1360, %r4049, %r1355;
	// end inline asm
	ld.const.u32 	%r1364, [matrix+1352];
	// begin inline asm
	dp4a.u32.u32 %r1363, %r1364, %r4053, %r1359;
	// end inline asm
	ld.const.u32 	%r1368, [matrix+1356];
	// begin inline asm
	dp4a.u32.u32 %r1367, %r1368, %r4057, %r1363;
	// end inline asm
	ld.const.u32 	%r1372, [matrix+1360];
	// begin inline asm
	dp4a.u32.u32 %r1371, %r1372, %r4061, %r1367;
	// end inline asm
	ld.const.u32 	%r1376, [matrix+1364];
	// begin inline asm
	dp4a.u32.u32 %r1375, %r1376, %r4065, %r1371;
	// end inline asm
	ld.const.u32 	%r1380, [matrix+1368];
	// begin inline asm
	dp4a.u32.u32 %r1379, %r1380, %r4069, %r1375;
	// end inline asm
	ld.const.u32 	%r1384, [matrix+1372];
	// begin inline asm
	dp4a.u32.u32 %r1383, %r1384, %r4073, %r1379;
	// end inline asm
	ld.const.u32 	%r1388, [matrix+1376];
	// begin inline asm
	dp4a.u32.u32 %r1387, %r1388, %r4077, %r1383;
	// end inline asm
	ld.const.u32 	%r1392, [matrix+1380];
	// begin inline asm
	dp4a.u32.u32 %r1391, %r1392, %r4081, %r1387;
	// end inline asm
	ld.const.u32 	%r1396, [matrix+1384];
	// begin inline asm
	dp4a.u32.u32 %r1395, %r1396, %r4085, %r1391;
	// end inline asm
	ld.const.u32 	%r1400, [matrix+1388];
	// begin inline asm
	dp4a.u32.u32 %r1399, %r1400, %r4089, %r1395;
	// end inline asm
	ld.const.u32 	%r1404, [matrix+1392];
	// begin inline asm
	dp4a.u32.u32 %r1403, %r1404, %r4093, %r1399;
	// end inline asm
	ld.const.u32 	%r1408, [matrix+1396];
	// begin inline asm
	dp4a.u32.u32 %r1407, %r1408, %r4097, %r1403;
	// end inline asm
	ld.const.u32 	%r1412, [matrix+1400];
	// begin inline asm
	dp4a.u32.u32 %r1411, %r1412, %r4101, %r1407;
	// end inline asm
	ld.const.u32 	%r1416, [matrix+1404];
	// begin inline asm
	dp4a.u32.u32 %r1415, %r1416, %r4105, %r1411;
	// end inline asm
	shr.u32 	%r4331, %r1351, 6;
	and.b32  	%r4332, %r4331, 240;
	shr.u32 	%r4333, %r1415, 10;
	or.b32  	%r4334, %r4333, %r4332;
	cvt.u64.u32 	%rd396, %r4334;
	xor.b64  	%rd397, %rd345, %rd396;
	ld.const.u32 	%r1420, [matrix+1408];
	// begin inline asm
	dp4a.u32.u32 %r1419, %r1420, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1424, [matrix+1412];
	// begin inline asm
	dp4a.u32.u32 %r1423, %r1424, %r4049, %r1419;
	// end inline asm
	ld.const.u32 	%r1428, [matrix+1416];
	// begin inline asm
	dp4a.u32.u32 %r1427, %r1428, %r4053, %r1423;
	// end inline asm
	ld.const.u32 	%r1432, [matrix+1420];
	// begin inline asm
	dp4a.u32.u32 %r1431, %r1432, %r4057, %r1427;
	// end inline asm
	ld.const.u32 	%r1436, [matrix+1424];
	// begin inline asm
	dp4a.u32.u32 %r1435, %r1436, %r4061, %r1431;
	// end inline asm
	ld.const.u32 	%r1440, [matrix+1428];
	// begin inline asm
	dp4a.u32.u32 %r1439, %r1440, %r4065, %r1435;
	// end inline asm
	ld.const.u32 	%r1444, [matrix+1432];
	// begin inline asm
	dp4a.u32.u32 %r1443, %r1444, %r4069, %r1439;
	// end inline asm
	ld.const.u32 	%r1448, [matrix+1436];
	// begin inline asm
	dp4a.u32.u32 %r1447, %r1448, %r4073, %r1443;
	// end inline asm
	ld.const.u32 	%r1452, [matrix+1440];
	// begin inline asm
	dp4a.u32.u32 %r1451, %r1452, %r4077, %r1447;
	// end inline asm
	ld.const.u32 	%r1456, [matrix+1444];
	// begin inline asm
	dp4a.u32.u32 %r1455, %r1456, %r4081, %r1451;
	// end inline asm
	ld.const.u32 	%r1460, [matrix+1448];
	// begin inline asm
	dp4a.u32.u32 %r1459, %r1460, %r4085, %r1455;
	// end inline asm
	ld.const.u32 	%r1464, [matrix+1452];
	// begin inline asm
	dp4a.u32.u32 %r1463, %r1464, %r4089, %r1459;
	// end inline asm
	ld.const.u32 	%r1468, [matrix+1456];
	// begin inline asm
	dp4a.u32.u32 %r1467, %r1468, %r4093, %r1463;
	// end inline asm
	ld.const.u32 	%r1472, [matrix+1460];
	// begin inline asm
	dp4a.u32.u32 %r1471, %r1472, %r4097, %r1467;
	// end inline asm
	ld.const.u32 	%r1476, [matrix+1464];
	// begin inline asm
	dp4a.u32.u32 %r1475, %r1476, %r4101, %r1471;
	// end inline asm
	ld.const.u32 	%r1480, [matrix+1468];
	// begin inline asm
	dp4a.u32.u32 %r1479, %r1480, %r4105, %r1475;
	// end inline asm
	ld.const.u32 	%r1484, [matrix+1472];
	// begin inline asm
	dp4a.u32.u32 %r1483, %r1484, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1488, [matrix+1476];
	// begin inline asm
	dp4a.u32.u32 %r1487, %r1488, %r4049, %r1483;
	// end inline asm
	ld.const.u32 	%r1492, [matrix+1480];
	// begin inline asm
	dp4a.u32.u32 %r1491, %r1492, %r4053, %r1487;
	// end inline asm
	ld.const.u32 	%r1496, [matrix+1484];
	// begin inline asm
	dp4a.u32.u32 %r1495, %r1496, %r4057, %r1491;
	// end inline asm
	ld.const.u32 	%r1500, [matrix+1488];
	// begin inline asm
	dp4a.u32.u32 %r1499, %r1500, %r4061, %r1495;
	// end inline asm
	ld.const.u32 	%r1504, [matrix+1492];
	// begin inline asm
	dp4a.u32.u32 %r1503, %r1504, %r4065, %r1499;
	// end inline asm
	ld.const.u32 	%r1508, [matrix+1496];
	// begin inline asm
	dp4a.u32.u32 %r1507, %r1508, %r4069, %r1503;
	// end inline asm
	ld.const.u32 	%r1512, [matrix+1500];
	// begin inline asm
	dp4a.u32.u32 %r1511, %r1512, %r4073, %r1507;
	// end inline asm
	ld.const.u32 	%r1516, [matrix+1504];
	// begin inline asm
	dp4a.u32.u32 %r1515, %r1516, %r4077, %r1511;
	// end inline asm
	ld.const.u32 	%r1520, [matrix+1508];
	// begin inline asm
	dp4a.u32.u32 %r1519, %r1520, %r4081, %r1515;
	// end inline asm
	ld.const.u32 	%r1524, [matrix+1512];
	// begin inline asm
	dp4a.u32.u32 %r1523, %r1524, %r4085, %r1519;
	// end inline asm
	ld.const.u32 	%r1528, [matrix+1516];
	// begin inline asm
	dp4a.u32.u32 %r1527, %r1528, %r4089, %r1523;
	// end inline asm
	ld.const.u32 	%r1532, [matrix+1520];
	// begin inline asm
	dp4a.u32.u32 %r1531, %r1532, %r4093, %r1527;
	// end inline asm
	ld.const.u32 	%r1536, [matrix+1524];
	// begin inline asm
	dp4a.u32.u32 %r1535, %r1536, %r4097, %r1531;
	// end inline asm
	ld.const.u32 	%r1540, [matrix+1528];
	// begin inline asm
	dp4a.u32.u32 %r1539, %r1540, %r4101, %r1535;
	// end inline asm
	ld.const.u32 	%r1544, [matrix+1532];
	// begin inline asm
	dp4a.u32.u32 %r1543, %r1544, %r4105, %r1539;
	// end inline asm
	shr.u32 	%r4335, %r1479, 6;
	and.b32  	%r4336, %r4335, 240;
	shr.u32 	%r4337, %r1543, 10;
	or.b32  	%r4338, %r4337, %r4336;
	cvt.u64.u32 	%rd398, %r4338;
	xor.b64  	%rd399, %rd344, %rd398;
	ld.const.u32 	%r1548, [matrix+1536];
	// begin inline asm
	dp4a.u32.u32 %r1547, %r1548, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1552, [matrix+1540];
	// begin inline asm
	dp4a.u32.u32 %r1551, %r1552, %r4049, %r1547;
	// end inline asm
	ld.const.u32 	%r1556, [matrix+1544];
	// begin inline asm
	dp4a.u32.u32 %r1555, %r1556, %r4053, %r1551;
	// end inline asm
	ld.const.u32 	%r1560, [matrix+1548];
	// begin inline asm
	dp4a.u32.u32 %r1559, %r1560, %r4057, %r1555;
	// end inline asm
	ld.const.u32 	%r1564, [matrix+1552];
	// begin inline asm
	dp4a.u32.u32 %r1563, %r1564, %r4061, %r1559;
	// end inline asm
	ld.const.u32 	%r1568, [matrix+1556];
	// begin inline asm
	dp4a.u32.u32 %r1567, %r1568, %r4065, %r1563;
	// end inline asm
	ld.const.u32 	%r1572, [matrix+1560];
	// begin inline asm
	dp4a.u32.u32 %r1571, %r1572, %r4069, %r1567;
	// end inline asm
	ld.const.u32 	%r1576, [matrix+1564];
	// begin inline asm
	dp4a.u32.u32 %r1575, %r1576, %r4073, %r1571;
	// end inline asm
	ld.const.u32 	%r1580, [matrix+1568];
	// begin inline asm
	dp4a.u32.u32 %r1579, %r1580, %r4077, %r1575;
	// end inline asm
	ld.const.u32 	%r1584, [matrix+1572];
	// begin inline asm
	dp4a.u32.u32 %r1583, %r1584, %r4081, %r1579;
	// end inline asm
	ld.const.u32 	%r1588, [matrix+1576];
	// begin inline asm
	dp4a.u32.u32 %r1587, %r1588, %r4085, %r1583;
	// end inline asm
	ld.const.u32 	%r1592, [matrix+1580];
	// begin inline asm
	dp4a.u32.u32 %r1591, %r1592, %r4089, %r1587;
	// end inline asm
	ld.const.u32 	%r1596, [matrix+1584];
	// begin inline asm
	dp4a.u32.u32 %r1595, %r1596, %r4093, %r1591;
	// end inline asm
	ld.const.u32 	%r1600, [matrix+1588];
	// begin inline asm
	dp4a.u32.u32 %r1599, %r1600, %r4097, %r1595;
	// end inline asm
	ld.const.u32 	%r1604, [matrix+1592];
	// begin inline asm
	dp4a.u32.u32 %r1603, %r1604, %r4101, %r1599;
	// end inline asm
	ld.const.u32 	%r1608, [matrix+1596];
	// begin inline asm
	dp4a.u32.u32 %r1607, %r1608, %r4105, %r1603;
	// end inline asm
	ld.const.u32 	%r1612, [matrix+1600];
	// begin inline asm
	dp4a.u32.u32 %r1611, %r1612, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1616, [matrix+1604];
	// begin inline asm
	dp4a.u32.u32 %r1615, %r1616, %r4049, %r1611;
	// end inline asm
	ld.const.u32 	%r1620, [matrix+1608];
	// begin inline asm
	dp4a.u32.u32 %r1619, %r1620, %r4053, %r1615;
	// end inline asm
	ld.const.u32 	%r1624, [matrix+1612];
	// begin inline asm
	dp4a.u32.u32 %r1623, %r1624, %r4057, %r1619;
	// end inline asm
	ld.const.u32 	%r1628, [matrix+1616];
	// begin inline asm
	dp4a.u32.u32 %r1627, %r1628, %r4061, %r1623;
	// end inline asm
	ld.const.u32 	%r1632, [matrix+1620];
	// begin inline asm
	dp4a.u32.u32 %r1631, %r1632, %r4065, %r1627;
	// end inline asm
	ld.const.u32 	%r1636, [matrix+1624];
	// begin inline asm
	dp4a.u32.u32 %r1635, %r1636, %r4069, %r1631;
	// end inline asm
	ld.const.u32 	%r1640, [matrix+1628];
	// begin inline asm
	dp4a.u32.u32 %r1639, %r1640, %r4073, %r1635;
	// end inline asm
	ld.const.u32 	%r1644, [matrix+1632];
	// begin inline asm
	dp4a.u32.u32 %r1643, %r1644, %r4077, %r1639;
	// end inline asm
	ld.const.u32 	%r1648, [matrix+1636];
	// begin inline asm
	dp4a.u32.u32 %r1647, %r1648, %r4081, %r1643;
	// end inline asm
	ld.const.u32 	%r1652, [matrix+1640];
	// begin inline asm
	dp4a.u32.u32 %r1651, %r1652, %r4085, %r1647;
	// end inline asm
	ld.const.u32 	%r1656, [matrix+1644];
	// begin inline asm
	dp4a.u32.u32 %r1655, %r1656, %r4089, %r1651;
	// end inline asm
	ld.const.u32 	%r1660, [matrix+1648];
	// begin inline asm
	dp4a.u32.u32 %r1659, %r1660, %r4093, %r1655;
	// end inline asm
	ld.const.u32 	%r1664, [matrix+1652];
	// begin inline asm
	dp4a.u32.u32 %r1663, %r1664, %r4097, %r1659;
	// end inline asm
	ld.const.u32 	%r1668, [matrix+1656];
	// begin inline asm
	dp4a.u32.u32 %r1667, %r1668, %r4101, %r1663;
	// end inline asm
	ld.const.u32 	%r1672, [matrix+1660];
	// begin inline asm
	dp4a.u32.u32 %r1671, %r1672, %r4105, %r1667;
	// end inline asm
	shr.u32 	%r4339, %r1607, 6;
	and.b32  	%r4340, %r4339, 240;
	shr.u32 	%r4341, %r1671, 10;
	or.b32  	%r4342, %r4341, %r4340;
	cvt.u64.u32 	%rd400, %r4342;
	xor.b64  	%rd401, %rd343, %rd400;
	ld.const.u32 	%r1676, [matrix+1664];
	// begin inline asm
	dp4a.u32.u32 %r1675, %r1676, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1680, [matrix+1668];
	// begin inline asm
	dp4a.u32.u32 %r1679, %r1680, %r4049, %r1675;
	// end inline asm
	ld.const.u32 	%r1684, [matrix+1672];
	// begin inline asm
	dp4a.u32.u32 %r1683, %r1684, %r4053, %r1679;
	// end inline asm
	ld.const.u32 	%r1688, [matrix+1676];
	// begin inline asm
	dp4a.u32.u32 %r1687, %r1688, %r4057, %r1683;
	// end inline asm
	ld.const.u32 	%r1692, [matrix+1680];
	// begin inline asm
	dp4a.u32.u32 %r1691, %r1692, %r4061, %r1687;
	// end inline asm
	ld.const.u32 	%r1696, [matrix+1684];
	// begin inline asm
	dp4a.u32.u32 %r1695, %r1696, %r4065, %r1691;
	// end inline asm
	ld.const.u32 	%r1700, [matrix+1688];
	// begin inline asm
	dp4a.u32.u32 %r1699, %r1700, %r4069, %r1695;
	// end inline asm
	ld.const.u32 	%r1704, [matrix+1692];
	// begin inline asm
	dp4a.u32.u32 %r1703, %r1704, %r4073, %r1699;
	// end inline asm
	ld.const.u32 	%r1708, [matrix+1696];
	// begin inline asm
	dp4a.u32.u32 %r1707, %r1708, %r4077, %r1703;
	// end inline asm
	ld.const.u32 	%r1712, [matrix+1700];
	// begin inline asm
	dp4a.u32.u32 %r1711, %r1712, %r4081, %r1707;
	// end inline asm
	ld.const.u32 	%r1716, [matrix+1704];
	// begin inline asm
	dp4a.u32.u32 %r1715, %r1716, %r4085, %r1711;
	// end inline asm
	ld.const.u32 	%r1720, [matrix+1708];
	// begin inline asm
	dp4a.u32.u32 %r1719, %r1720, %r4089, %r1715;
	// end inline asm
	ld.const.u32 	%r1724, [matrix+1712];
	// begin inline asm
	dp4a.u32.u32 %r1723, %r1724, %r4093, %r1719;
	// end inline asm
	ld.const.u32 	%r1728, [matrix+1716];
	// begin inline asm
	dp4a.u32.u32 %r1727, %r1728, %r4097, %r1723;
	// end inline asm
	ld.const.u32 	%r1732, [matrix+1720];
	// begin inline asm
	dp4a.u32.u32 %r1731, %r1732, %r4101, %r1727;
	// end inline asm
	ld.const.u32 	%r1736, [matrix+1724];
	// begin inline asm
	dp4a.u32.u32 %r1735, %r1736, %r4105, %r1731;
	// end inline asm
	ld.const.u32 	%r1740, [matrix+1728];
	// begin inline asm
	dp4a.u32.u32 %r1739, %r1740, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1744, [matrix+1732];
	// begin inline asm
	dp4a.u32.u32 %r1743, %r1744, %r4049, %r1739;
	// end inline asm
	ld.const.u32 	%r1748, [matrix+1736];
	// begin inline asm
	dp4a.u32.u32 %r1747, %r1748, %r4053, %r1743;
	// end inline asm
	ld.const.u32 	%r1752, [matrix+1740];
	// begin inline asm
	dp4a.u32.u32 %r1751, %r1752, %r4057, %r1747;
	// end inline asm
	ld.const.u32 	%r1756, [matrix+1744];
	// begin inline asm
	dp4a.u32.u32 %r1755, %r1756, %r4061, %r1751;
	// end inline asm
	ld.const.u32 	%r1760, [matrix+1748];
	// begin inline asm
	dp4a.u32.u32 %r1759, %r1760, %r4065, %r1755;
	// end inline asm
	ld.const.u32 	%r1764, [matrix+1752];
	// begin inline asm
	dp4a.u32.u32 %r1763, %r1764, %r4069, %r1759;
	// end inline asm
	ld.const.u32 	%r1768, [matrix+1756];
	// begin inline asm
	dp4a.u32.u32 %r1767, %r1768, %r4073, %r1763;
	// end inline asm
	ld.const.u32 	%r1772, [matrix+1760];
	// begin inline asm
	dp4a.u32.u32 %r1771, %r1772, %r4077, %r1767;
	// end inline asm
	ld.const.u32 	%r1776, [matrix+1764];
	// begin inline asm
	dp4a.u32.u32 %r1775, %r1776, %r4081, %r1771;
	// end inline asm
	ld.const.u32 	%r1780, [matrix+1768];
	// begin inline asm
	dp4a.u32.u32 %r1779, %r1780, %r4085, %r1775;
	// end inline asm
	ld.const.u32 	%r1784, [matrix+1772];
	// begin inline asm
	dp4a.u32.u32 %r1783, %r1784, %r4089, %r1779;
	// end inline asm
	ld.const.u32 	%r1788, [matrix+1776];
	// begin inline asm
	dp4a.u32.u32 %r1787, %r1788, %r4093, %r1783;
	// end inline asm
	ld.const.u32 	%r1792, [matrix+1780];
	// begin inline asm
	dp4a.u32.u32 %r1791, %r1792, %r4097, %r1787;
	// end inline asm
	ld.const.u32 	%r1796, [matrix+1784];
	// begin inline asm
	dp4a.u32.u32 %r1795, %r1796, %r4101, %r1791;
	// end inline asm
	ld.const.u32 	%r1800, [matrix+1788];
	// begin inline asm
	dp4a.u32.u32 %r1799, %r1800, %r4105, %r1795;
	// end inline asm
	shr.u32 	%r4343, %r1735, 6;
	and.b32  	%r4344, %r4343, 240;
	shr.u32 	%r4345, %r1799, 10;
	or.b32  	%r4346, %r4345, %r4344;
	cvt.u64.u32 	%rd402, %r4346;
	xor.b64  	%rd403, %rd342, %rd402;
	ld.const.u32 	%r1804, [matrix+1792];
	// begin inline asm
	dp4a.u32.u32 %r1803, %r1804, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1808, [matrix+1796];
	// begin inline asm
	dp4a.u32.u32 %r1807, %r1808, %r4049, %r1803;
	// end inline asm
	ld.const.u32 	%r1812, [matrix+1800];
	// begin inline asm
	dp4a.u32.u32 %r1811, %r1812, %r4053, %r1807;
	// end inline asm
	ld.const.u32 	%r1816, [matrix+1804];
	// begin inline asm
	dp4a.u32.u32 %r1815, %r1816, %r4057, %r1811;
	// end inline asm
	ld.const.u32 	%r1820, [matrix+1808];
	// begin inline asm
	dp4a.u32.u32 %r1819, %r1820, %r4061, %r1815;
	// end inline asm
	ld.const.u32 	%r1824, [matrix+1812];
	// begin inline asm
	dp4a.u32.u32 %r1823, %r1824, %r4065, %r1819;
	// end inline asm
	ld.const.u32 	%r1828, [matrix+1816];
	// begin inline asm
	dp4a.u32.u32 %r1827, %r1828, %r4069, %r1823;
	// end inline asm
	ld.const.u32 	%r1832, [matrix+1820];
	// begin inline asm
	dp4a.u32.u32 %r1831, %r1832, %r4073, %r1827;
	// end inline asm
	ld.const.u32 	%r1836, [matrix+1824];
	// begin inline asm
	dp4a.u32.u32 %r1835, %r1836, %r4077, %r1831;
	// end inline asm
	ld.const.u32 	%r1840, [matrix+1828];
	// begin inline asm
	dp4a.u32.u32 %r1839, %r1840, %r4081, %r1835;
	// end inline asm
	ld.const.u32 	%r1844, [matrix+1832];
	// begin inline asm
	dp4a.u32.u32 %r1843, %r1844, %r4085, %r1839;
	// end inline asm
	ld.const.u32 	%r1848, [matrix+1836];
	// begin inline asm
	dp4a.u32.u32 %r1847, %r1848, %r4089, %r1843;
	// end inline asm
	ld.const.u32 	%r1852, [matrix+1840];
	// begin inline asm
	dp4a.u32.u32 %r1851, %r1852, %r4093, %r1847;
	// end inline asm
	ld.const.u32 	%r1856, [matrix+1844];
	// begin inline asm
	dp4a.u32.u32 %r1855, %r1856, %r4097, %r1851;
	// end inline asm
	ld.const.u32 	%r1860, [matrix+1848];
	// begin inline asm
	dp4a.u32.u32 %r1859, %r1860, %r4101, %r1855;
	// end inline asm
	ld.const.u32 	%r1864, [matrix+1852];
	// begin inline asm
	dp4a.u32.u32 %r1863, %r1864, %r4105, %r1859;
	// end inline asm
	ld.const.u32 	%r1868, [matrix+1856];
	// begin inline asm
	dp4a.u32.u32 %r1867, %r1868, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1872, [matrix+1860];
	// begin inline asm
	dp4a.u32.u32 %r1871, %r1872, %r4049, %r1867;
	// end inline asm
	ld.const.u32 	%r1876, [matrix+1864];
	// begin inline asm
	dp4a.u32.u32 %r1875, %r1876, %r4053, %r1871;
	// end inline asm
	ld.const.u32 	%r1880, [matrix+1868];
	// begin inline asm
	dp4a.u32.u32 %r1879, %r1880, %r4057, %r1875;
	// end inline asm
	ld.const.u32 	%r1884, [matrix+1872];
	// begin inline asm
	dp4a.u32.u32 %r1883, %r1884, %r4061, %r1879;
	// end inline asm
	ld.const.u32 	%r1888, [matrix+1876];
	// begin inline asm
	dp4a.u32.u32 %r1887, %r1888, %r4065, %r1883;
	// end inline asm
	ld.const.u32 	%r1892, [matrix+1880];
	// begin inline asm
	dp4a.u32.u32 %r1891, %r1892, %r4069, %r1887;
	// end inline asm
	ld.const.u32 	%r1896, [matrix+1884];
	// begin inline asm
	dp4a.u32.u32 %r1895, %r1896, %r4073, %r1891;
	// end inline asm
	ld.const.u32 	%r1900, [matrix+1888];
	// begin inline asm
	dp4a.u32.u32 %r1899, %r1900, %r4077, %r1895;
	// end inline asm
	ld.const.u32 	%r1904, [matrix+1892];
	// begin inline asm
	dp4a.u32.u32 %r1903, %r1904, %r4081, %r1899;
	// end inline asm
	ld.const.u32 	%r1908, [matrix+1896];
	// begin inline asm
	dp4a.u32.u32 %r1907, %r1908, %r4085, %r1903;
	// end inline asm
	ld.const.u32 	%r1912, [matrix+1900];
	// begin inline asm
	dp4a.u32.u32 %r1911, %r1912, %r4089, %r1907;
	// end inline asm
	ld.const.u32 	%r1916, [matrix+1904];
	// begin inline asm
	dp4a.u32.u32 %r1915, %r1916, %r4093, %r1911;
	// end inline asm
	ld.const.u32 	%r1920, [matrix+1908];
	// begin inline asm
	dp4a.u32.u32 %r1919, %r1920, %r4097, %r1915;
	// end inline asm
	ld.const.u32 	%r1924, [matrix+1912];
	// begin inline asm
	dp4a.u32.u32 %r1923, %r1924, %r4101, %r1919;
	// end inline asm
	ld.const.u32 	%r1928, [matrix+1916];
	// begin inline asm
	dp4a.u32.u32 %r1927, %r1928, %r4105, %r1923;
	// end inline asm
	shr.u32 	%r4347, %r1863, 6;
	and.b32  	%r4348, %r4347, 240;
	shr.u32 	%r4349, %r1927, 10;
	or.b32  	%r4350, %r4349, %r4348;
	cvt.u64.u32 	%rd404, %r4350;
	xor.b64  	%rd405, %rd341, %rd404;
	ld.const.u32 	%r1932, [matrix+1920];
	// begin inline asm
	dp4a.u32.u32 %r1931, %r1932, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r1936, [matrix+1924];
	// begin inline asm
	dp4a.u32.u32 %r1935, %r1936, %r4049, %r1931;
	// end inline asm
	ld.const.u32 	%r1940, [matrix+1928];
	// begin inline asm
	dp4a.u32.u32 %r1939, %r1940, %r4053, %r1935;
	// end inline asm
	ld.const.u32 	%r1944, [matrix+1932];
	// begin inline asm
	dp4a.u32.u32 %r1943, %r1944, %r4057, %r1939;
	// end inline asm
	ld.const.u32 	%r1948, [matrix+1936];
	// begin inline asm
	dp4a.u32.u32 %r1947, %r1948, %r4061, %r1943;
	// end inline asm
	ld.const.u32 	%r1952, [matrix+1940];
	// begin inline asm
	dp4a.u32.u32 %r1951, %r1952, %r4065, %r1947;
	// end inline asm
	ld.const.u32 	%r1956, [matrix+1944];
	// begin inline asm
	dp4a.u32.u32 %r1955, %r1956, %r4069, %r1951;
	// end inline asm
	ld.const.u32 	%r1960, [matrix+1948];
	// begin inline asm
	dp4a.u32.u32 %r1959, %r1960, %r4073, %r1955;
	// end inline asm
	ld.const.u32 	%r1964, [matrix+1952];
	// begin inline asm
	dp4a.u32.u32 %r1963, %r1964, %r4077, %r1959;
	// end inline asm
	ld.const.u32 	%r1968, [matrix+1956];
	// begin inline asm
	dp4a.u32.u32 %r1967, %r1968, %r4081, %r1963;
	// end inline asm
	ld.const.u32 	%r1972, [matrix+1960];
	// begin inline asm
	dp4a.u32.u32 %r1971, %r1972, %r4085, %r1967;
	// end inline asm
	ld.const.u32 	%r1976, [matrix+1964];
	// begin inline asm
	dp4a.u32.u32 %r1975, %r1976, %r4089, %r1971;
	// end inline asm
	ld.const.u32 	%r1980, [matrix+1968];
	// begin inline asm
	dp4a.u32.u32 %r1979, %r1980, %r4093, %r1975;
	// end inline asm
	ld.const.u32 	%r1984, [matrix+1972];
	// begin inline asm
	dp4a.u32.u32 %r1983, %r1984, %r4097, %r1979;
	// end inline asm
	ld.const.u32 	%r1988, [matrix+1976];
	// begin inline asm
	dp4a.u32.u32 %r1987, %r1988, %r4101, %r1983;
	// end inline asm
	ld.const.u32 	%r1992, [matrix+1980];
	// begin inline asm
	dp4a.u32.u32 %r1991, %r1992, %r4105, %r1987;
	// end inline asm
	ld.const.u32 	%r1996, [matrix+1984];
	// begin inline asm
	dp4a.u32.u32 %r1995, %r1996, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2000, [matrix+1988];
	// begin inline asm
	dp4a.u32.u32 %r1999, %r2000, %r4049, %r1995;
	// end inline asm
	ld.const.u32 	%r2004, [matrix+1992];
	// begin inline asm
	dp4a.u32.u32 %r2003, %r2004, %r4053, %r1999;
	// end inline asm
	ld.const.u32 	%r2008, [matrix+1996];
	// begin inline asm
	dp4a.u32.u32 %r2007, %r2008, %r4057, %r2003;
	// end inline asm
	ld.const.u32 	%r2012, [matrix+2000];
	// begin inline asm
	dp4a.u32.u32 %r2011, %r2012, %r4061, %r2007;
	// end inline asm
	ld.const.u32 	%r2016, [matrix+2004];
	// begin inline asm
	dp4a.u32.u32 %r2015, %r2016, %r4065, %r2011;
	// end inline asm
	ld.const.u32 	%r2020, [matrix+2008];
	// begin inline asm
	dp4a.u32.u32 %r2019, %r2020, %r4069, %r2015;
	// end inline asm
	ld.const.u32 	%r2024, [matrix+2012];
	// begin inline asm
	dp4a.u32.u32 %r2023, %r2024, %r4073, %r2019;
	// end inline asm
	ld.const.u32 	%r2028, [matrix+2016];
	// begin inline asm
	dp4a.u32.u32 %r2027, %r2028, %r4077, %r2023;
	// end inline asm
	ld.const.u32 	%r2032, [matrix+2020];
	// begin inline asm
	dp4a.u32.u32 %r2031, %r2032, %r4081, %r2027;
	// end inline asm
	ld.const.u32 	%r2036, [matrix+2024];
	// begin inline asm
	dp4a.u32.u32 %r2035, %r2036, %r4085, %r2031;
	// end inline asm
	ld.const.u32 	%r2040, [matrix+2028];
	// begin inline asm
	dp4a.u32.u32 %r2039, %r2040, %r4089, %r2035;
	// end inline asm
	ld.const.u32 	%r2044, [matrix+2032];
	// begin inline asm
	dp4a.u32.u32 %r2043, %r2044, %r4093, %r2039;
	// end inline asm
	ld.const.u32 	%r2048, [matrix+2036];
	// begin inline asm
	dp4a.u32.u32 %r2047, %r2048, %r4097, %r2043;
	// end inline asm
	ld.const.u32 	%r2052, [matrix+2040];
	// begin inline asm
	dp4a.u32.u32 %r2051, %r2052, %r4101, %r2047;
	// end inline asm
	ld.const.u32 	%r2056, [matrix+2044];
	// begin inline asm
	dp4a.u32.u32 %r2055, %r2056, %r4105, %r2051;
	// end inline asm
	shr.u32 	%r4351, %r1991, 6;
	and.b32  	%r4352, %r4351, 240;
	shr.u32 	%r4353, %r2055, 10;
	or.b32  	%r4354, %r4353, %r4352;
	cvt.u64.u32 	%rd406, %r4354;
	xor.b64  	%rd407, %rd677, %rd406;
	ld.const.u32 	%r2060, [matrix+2048];
	// begin inline asm
	dp4a.u32.u32 %r2059, %r2060, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2064, [matrix+2052];
	// begin inline asm
	dp4a.u32.u32 %r2063, %r2064, %r4049, %r2059;
	// end inline asm
	ld.const.u32 	%r2068, [matrix+2056];
	// begin inline asm
	dp4a.u32.u32 %r2067, %r2068, %r4053, %r2063;
	// end inline asm
	ld.const.u32 	%r2072, [matrix+2060];
	// begin inline asm
	dp4a.u32.u32 %r2071, %r2072, %r4057, %r2067;
	// end inline asm
	ld.const.u32 	%r2076, [matrix+2064];
	// begin inline asm
	dp4a.u32.u32 %r2075, %r2076, %r4061, %r2071;
	// end inline asm
	ld.const.u32 	%r2080, [matrix+2068];
	// begin inline asm
	dp4a.u32.u32 %r2079, %r2080, %r4065, %r2075;
	// end inline asm
	ld.const.u32 	%r2084, [matrix+2072];
	// begin inline asm
	dp4a.u32.u32 %r2083, %r2084, %r4069, %r2079;
	// end inline asm
	ld.const.u32 	%r2088, [matrix+2076];
	// begin inline asm
	dp4a.u32.u32 %r2087, %r2088, %r4073, %r2083;
	// end inline asm
	ld.const.u32 	%r2092, [matrix+2080];
	// begin inline asm
	dp4a.u32.u32 %r2091, %r2092, %r4077, %r2087;
	// end inline asm
	ld.const.u32 	%r2096, [matrix+2084];
	// begin inline asm
	dp4a.u32.u32 %r2095, %r2096, %r4081, %r2091;
	// end inline asm
	ld.const.u32 	%r2100, [matrix+2088];
	// begin inline asm
	dp4a.u32.u32 %r2099, %r2100, %r4085, %r2095;
	// end inline asm
	ld.const.u32 	%r2104, [matrix+2092];
	// begin inline asm
	dp4a.u32.u32 %r2103, %r2104, %r4089, %r2099;
	// end inline asm
	ld.const.u32 	%r2108, [matrix+2096];
	// begin inline asm
	dp4a.u32.u32 %r2107, %r2108, %r4093, %r2103;
	// end inline asm
	ld.const.u32 	%r2112, [matrix+2100];
	// begin inline asm
	dp4a.u32.u32 %r2111, %r2112, %r4097, %r2107;
	// end inline asm
	ld.const.u32 	%r2116, [matrix+2104];
	// begin inline asm
	dp4a.u32.u32 %r2115, %r2116, %r4101, %r2111;
	// end inline asm
	ld.const.u32 	%r2120, [matrix+2108];
	// begin inline asm
	dp4a.u32.u32 %r2119, %r2120, %r4105, %r2115;
	// end inline asm
	ld.const.u32 	%r2124, [matrix+2112];
	// begin inline asm
	dp4a.u32.u32 %r2123, %r2124, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2128, [matrix+2116];
	// begin inline asm
	dp4a.u32.u32 %r2127, %r2128, %r4049, %r2123;
	// end inline asm
	ld.const.u32 	%r2132, [matrix+2120];
	// begin inline asm
	dp4a.u32.u32 %r2131, %r2132, %r4053, %r2127;
	// end inline asm
	ld.const.u32 	%r2136, [matrix+2124];
	// begin inline asm
	dp4a.u32.u32 %r2135, %r2136, %r4057, %r2131;
	// end inline asm
	ld.const.u32 	%r2140, [matrix+2128];
	// begin inline asm
	dp4a.u32.u32 %r2139, %r2140, %r4061, %r2135;
	// end inline asm
	ld.const.u32 	%r2144, [matrix+2132];
	// begin inline asm
	dp4a.u32.u32 %r2143, %r2144, %r4065, %r2139;
	// end inline asm
	ld.const.u32 	%r2148, [matrix+2136];
	// begin inline asm
	dp4a.u32.u32 %r2147, %r2148, %r4069, %r2143;
	// end inline asm
	ld.const.u32 	%r2152, [matrix+2140];
	// begin inline asm
	dp4a.u32.u32 %r2151, %r2152, %r4073, %r2147;
	// end inline asm
	ld.const.u32 	%r2156, [matrix+2144];
	// begin inline asm
	dp4a.u32.u32 %r2155, %r2156, %r4077, %r2151;
	// end inline asm
	ld.const.u32 	%r2160, [matrix+2148];
	// begin inline asm
	dp4a.u32.u32 %r2159, %r2160, %r4081, %r2155;
	// end inline asm
	ld.const.u32 	%r2164, [matrix+2152];
	// begin inline asm
	dp4a.u32.u32 %r2163, %r2164, %r4085, %r2159;
	// end inline asm
	ld.const.u32 	%r2168, [matrix+2156];
	// begin inline asm
	dp4a.u32.u32 %r2167, %r2168, %r4089, %r2163;
	// end inline asm
	ld.const.u32 	%r2172, [matrix+2160];
	// begin inline asm
	dp4a.u32.u32 %r2171, %r2172, %r4093, %r2167;
	// end inline asm
	ld.const.u32 	%r2176, [matrix+2164];
	// begin inline asm
	dp4a.u32.u32 %r2175, %r2176, %r4097, %r2171;
	// end inline asm
	ld.const.u32 	%r2180, [matrix+2168];
	// begin inline asm
	dp4a.u32.u32 %r2179, %r2180, %r4101, %r2175;
	// end inline asm
	ld.const.u32 	%r2184, [matrix+2172];
	// begin inline asm
	dp4a.u32.u32 %r2183, %r2184, %r4105, %r2179;
	// end inline asm
	shr.u32 	%r4355, %r2119, 6;
	and.b32  	%r4356, %r4355, 240;
	shr.u32 	%r4357, %r2183, 10;
	or.b32  	%r4358, %r4357, %r4356;
	cvt.u64.u32 	%rd408, %r4358;
	ld.const.u32 	%r2188, [matrix+2176];
	// begin inline asm
	dp4a.u32.u32 %r2187, %r2188, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2192, [matrix+2180];
	// begin inline asm
	dp4a.u32.u32 %r2191, %r2192, %r4049, %r2187;
	// end inline asm
	ld.const.u32 	%r2196, [matrix+2184];
	// begin inline asm
	dp4a.u32.u32 %r2195, %r2196, %r4053, %r2191;
	// end inline asm
	ld.const.u32 	%r2200, [matrix+2188];
	// begin inline asm
	dp4a.u32.u32 %r2199, %r2200, %r4057, %r2195;
	// end inline asm
	ld.const.u32 	%r2204, [matrix+2192];
	// begin inline asm
	dp4a.u32.u32 %r2203, %r2204, %r4061, %r2199;
	// end inline asm
	ld.const.u32 	%r2208, [matrix+2196];
	// begin inline asm
	dp4a.u32.u32 %r2207, %r2208, %r4065, %r2203;
	// end inline asm
	ld.const.u32 	%r2212, [matrix+2200];
	// begin inline asm
	dp4a.u32.u32 %r2211, %r2212, %r4069, %r2207;
	// end inline asm
	ld.const.u32 	%r2216, [matrix+2204];
	// begin inline asm
	dp4a.u32.u32 %r2215, %r2216, %r4073, %r2211;
	// end inline asm
	ld.const.u32 	%r2220, [matrix+2208];
	// begin inline asm
	dp4a.u32.u32 %r2219, %r2220, %r4077, %r2215;
	// end inline asm
	ld.const.u32 	%r2224, [matrix+2212];
	// begin inline asm
	dp4a.u32.u32 %r2223, %r2224, %r4081, %r2219;
	// end inline asm
	ld.const.u32 	%r2228, [matrix+2216];
	// begin inline asm
	dp4a.u32.u32 %r2227, %r2228, %r4085, %r2223;
	// end inline asm
	ld.const.u32 	%r2232, [matrix+2220];
	// begin inline asm
	dp4a.u32.u32 %r2231, %r2232, %r4089, %r2227;
	// end inline asm
	ld.const.u32 	%r2236, [matrix+2224];
	// begin inline asm
	dp4a.u32.u32 %r2235, %r2236, %r4093, %r2231;
	// end inline asm
	ld.const.u32 	%r2240, [matrix+2228];
	// begin inline asm
	dp4a.u32.u32 %r2239, %r2240, %r4097, %r2235;
	// end inline asm
	ld.const.u32 	%r2244, [matrix+2232];
	// begin inline asm
	dp4a.u32.u32 %r2243, %r2244, %r4101, %r2239;
	// end inline asm
	ld.const.u32 	%r2248, [matrix+2236];
	// begin inline asm
	dp4a.u32.u32 %r2247, %r2248, %r4105, %r2243;
	// end inline asm
	ld.const.u32 	%r2252, [matrix+2240];
	// begin inline asm
	dp4a.u32.u32 %r2251, %r2252, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2256, [matrix+2244];
	// begin inline asm
	dp4a.u32.u32 %r2255, %r2256, %r4049, %r2251;
	// end inline asm
	ld.const.u32 	%r2260, [matrix+2248];
	// begin inline asm
	dp4a.u32.u32 %r2259, %r2260, %r4053, %r2255;
	// end inline asm
	ld.const.u32 	%r2264, [matrix+2252];
	// begin inline asm
	dp4a.u32.u32 %r2263, %r2264, %r4057, %r2259;
	// end inline asm
	ld.const.u32 	%r2268, [matrix+2256];
	// begin inline asm
	dp4a.u32.u32 %r2267, %r2268, %r4061, %r2263;
	// end inline asm
	ld.const.u32 	%r2272, [matrix+2260];
	// begin inline asm
	dp4a.u32.u32 %r2271, %r2272, %r4065, %r2267;
	// end inline asm
	ld.const.u32 	%r2276, [matrix+2264];
	// begin inline asm
	dp4a.u32.u32 %r2275, %r2276, %r4069, %r2271;
	// end inline asm
	ld.const.u32 	%r2280, [matrix+2268];
	// begin inline asm
	dp4a.u32.u32 %r2279, %r2280, %r4073, %r2275;
	// end inline asm
	ld.const.u32 	%r2284, [matrix+2272];
	// begin inline asm
	dp4a.u32.u32 %r2283, %r2284, %r4077, %r2279;
	// end inline asm
	ld.const.u32 	%r2288, [matrix+2276];
	// begin inline asm
	dp4a.u32.u32 %r2287, %r2288, %r4081, %r2283;
	// end inline asm
	ld.const.u32 	%r2292, [matrix+2280];
	// begin inline asm
	dp4a.u32.u32 %r2291, %r2292, %r4085, %r2287;
	// end inline asm
	ld.const.u32 	%r2296, [matrix+2284];
	// begin inline asm
	dp4a.u32.u32 %r2295, %r2296, %r4089, %r2291;
	// end inline asm
	ld.const.u32 	%r2300, [matrix+2288];
	// begin inline asm
	dp4a.u32.u32 %r2299, %r2300, %r4093, %r2295;
	// end inline asm
	ld.const.u32 	%r2304, [matrix+2292];
	// begin inline asm
	dp4a.u32.u32 %r2303, %r2304, %r4097, %r2299;
	// end inline asm
	ld.const.u32 	%r2308, [matrix+2296];
	// begin inline asm
	dp4a.u32.u32 %r2307, %r2308, %r4101, %r2303;
	// end inline asm
	ld.const.u32 	%r2312, [matrix+2300];
	// begin inline asm
	dp4a.u32.u32 %r2311, %r2312, %r4105, %r2307;
	// end inline asm
	shr.u32 	%r4359, %r2247, 6;
	and.b32  	%r4360, %r4359, 240;
	shr.u32 	%r4361, %r2311, 10;
	or.b32  	%r4362, %r4361, %r4360;
	cvt.u64.u32 	%rd409, %r4362;
	xor.b64  	%rd410, %rd339, %rd409;
	ld.const.u32 	%r2316, [matrix+2304];
	// begin inline asm
	dp4a.u32.u32 %r2315, %r2316, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2320, [matrix+2308];
	// begin inline asm
	dp4a.u32.u32 %r2319, %r2320, %r4049, %r2315;
	// end inline asm
	ld.const.u32 	%r2324, [matrix+2312];
	// begin inline asm
	dp4a.u32.u32 %r2323, %r2324, %r4053, %r2319;
	// end inline asm
	ld.const.u32 	%r2328, [matrix+2316];
	// begin inline asm
	dp4a.u32.u32 %r2327, %r2328, %r4057, %r2323;
	// end inline asm
	ld.const.u32 	%r2332, [matrix+2320];
	// begin inline asm
	dp4a.u32.u32 %r2331, %r2332, %r4061, %r2327;
	// end inline asm
	ld.const.u32 	%r2336, [matrix+2324];
	// begin inline asm
	dp4a.u32.u32 %r2335, %r2336, %r4065, %r2331;
	// end inline asm
	ld.const.u32 	%r2340, [matrix+2328];
	// begin inline asm
	dp4a.u32.u32 %r2339, %r2340, %r4069, %r2335;
	// end inline asm
	ld.const.u32 	%r2344, [matrix+2332];
	// begin inline asm
	dp4a.u32.u32 %r2343, %r2344, %r4073, %r2339;
	// end inline asm
	ld.const.u32 	%r2348, [matrix+2336];
	// begin inline asm
	dp4a.u32.u32 %r2347, %r2348, %r4077, %r2343;
	// end inline asm
	ld.const.u32 	%r2352, [matrix+2340];
	// begin inline asm
	dp4a.u32.u32 %r2351, %r2352, %r4081, %r2347;
	// end inline asm
	ld.const.u32 	%r2356, [matrix+2344];
	// begin inline asm
	dp4a.u32.u32 %r2355, %r2356, %r4085, %r2351;
	// end inline asm
	ld.const.u32 	%r2360, [matrix+2348];
	// begin inline asm
	dp4a.u32.u32 %r2359, %r2360, %r4089, %r2355;
	// end inline asm
	ld.const.u32 	%r2364, [matrix+2352];
	// begin inline asm
	dp4a.u32.u32 %r2363, %r2364, %r4093, %r2359;
	// end inline asm
	ld.const.u32 	%r2368, [matrix+2356];
	// begin inline asm
	dp4a.u32.u32 %r2367, %r2368, %r4097, %r2363;
	// end inline asm
	ld.const.u32 	%r2372, [matrix+2360];
	// begin inline asm
	dp4a.u32.u32 %r2371, %r2372, %r4101, %r2367;
	// end inline asm
	ld.const.u32 	%r2376, [matrix+2364];
	// begin inline asm
	dp4a.u32.u32 %r2375, %r2376, %r4105, %r2371;
	// end inline asm
	ld.const.u32 	%r2380, [matrix+2368];
	// begin inline asm
	dp4a.u32.u32 %r2379, %r2380, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2384, [matrix+2372];
	// begin inline asm
	dp4a.u32.u32 %r2383, %r2384, %r4049, %r2379;
	// end inline asm
	ld.const.u32 	%r2388, [matrix+2376];
	// begin inline asm
	dp4a.u32.u32 %r2387, %r2388, %r4053, %r2383;
	// end inline asm
	ld.const.u32 	%r2392, [matrix+2380];
	// begin inline asm
	dp4a.u32.u32 %r2391, %r2392, %r4057, %r2387;
	// end inline asm
	ld.const.u32 	%r2396, [matrix+2384];
	// begin inline asm
	dp4a.u32.u32 %r2395, %r2396, %r4061, %r2391;
	// end inline asm
	ld.const.u32 	%r2400, [matrix+2388];
	// begin inline asm
	dp4a.u32.u32 %r2399, %r2400, %r4065, %r2395;
	// end inline asm
	ld.const.u32 	%r2404, [matrix+2392];
	// begin inline asm
	dp4a.u32.u32 %r2403, %r2404, %r4069, %r2399;
	// end inline asm
	ld.const.u32 	%r2408, [matrix+2396];
	// begin inline asm
	dp4a.u32.u32 %r2407, %r2408, %r4073, %r2403;
	// end inline asm
	ld.const.u32 	%r2412, [matrix+2400];
	// begin inline asm
	dp4a.u32.u32 %r2411, %r2412, %r4077, %r2407;
	// end inline asm
	ld.const.u32 	%r2416, [matrix+2404];
	// begin inline asm
	dp4a.u32.u32 %r2415, %r2416, %r4081, %r2411;
	// end inline asm
	ld.const.u32 	%r2420, [matrix+2408];
	// begin inline asm
	dp4a.u32.u32 %r2419, %r2420, %r4085, %r2415;
	// end inline asm
	ld.const.u32 	%r2424, [matrix+2412];
	// begin inline asm
	dp4a.u32.u32 %r2423, %r2424, %r4089, %r2419;
	// end inline asm
	ld.const.u32 	%r2428, [matrix+2416];
	// begin inline asm
	dp4a.u32.u32 %r2427, %r2428, %r4093, %r2423;
	// end inline asm
	ld.const.u32 	%r2432, [matrix+2420];
	// begin inline asm
	dp4a.u32.u32 %r2431, %r2432, %r4097, %r2427;
	// end inline asm
	ld.const.u32 	%r2436, [matrix+2424];
	// begin inline asm
	dp4a.u32.u32 %r2435, %r2436, %r4101, %r2431;
	// end inline asm
	ld.const.u32 	%r2440, [matrix+2428];
	// begin inline asm
	dp4a.u32.u32 %r2439, %r2440, %r4105, %r2435;
	// end inline asm
	shr.u32 	%r4363, %r2375, 6;
	and.b32  	%r4364, %r4363, 240;
	shr.u32 	%r4365, %r2439, 10;
	or.b32  	%r4366, %r4365, %r4364;
	cvt.u64.u32 	%rd411, %r4366;
	xor.b64  	%rd412, %rd338, %rd411;
	ld.const.u32 	%r2444, [matrix+2432];
	// begin inline asm
	dp4a.u32.u32 %r2443, %r2444, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2448, [matrix+2436];
	// begin inline asm
	dp4a.u32.u32 %r2447, %r2448, %r4049, %r2443;
	// end inline asm
	ld.const.u32 	%r2452, [matrix+2440];
	// begin inline asm
	dp4a.u32.u32 %r2451, %r2452, %r4053, %r2447;
	// end inline asm
	ld.const.u32 	%r2456, [matrix+2444];
	// begin inline asm
	dp4a.u32.u32 %r2455, %r2456, %r4057, %r2451;
	// end inline asm
	ld.const.u32 	%r2460, [matrix+2448];
	// begin inline asm
	dp4a.u32.u32 %r2459, %r2460, %r4061, %r2455;
	// end inline asm
	ld.const.u32 	%r2464, [matrix+2452];
	// begin inline asm
	dp4a.u32.u32 %r2463, %r2464, %r4065, %r2459;
	// end inline asm
	ld.const.u32 	%r2468, [matrix+2456];
	// begin inline asm
	dp4a.u32.u32 %r2467, %r2468, %r4069, %r2463;
	// end inline asm
	ld.const.u32 	%r2472, [matrix+2460];
	// begin inline asm
	dp4a.u32.u32 %r2471, %r2472, %r4073, %r2467;
	// end inline asm
	ld.const.u32 	%r2476, [matrix+2464];
	// begin inline asm
	dp4a.u32.u32 %r2475, %r2476, %r4077, %r2471;
	// end inline asm
	ld.const.u32 	%r2480, [matrix+2468];
	// begin inline asm
	dp4a.u32.u32 %r2479, %r2480, %r4081, %r2475;
	// end inline asm
	ld.const.u32 	%r2484, [matrix+2472];
	// begin inline asm
	dp4a.u32.u32 %r2483, %r2484, %r4085, %r2479;
	// end inline asm
	ld.const.u32 	%r2488, [matrix+2476];
	// begin inline asm
	dp4a.u32.u32 %r2487, %r2488, %r4089, %r2483;
	// end inline asm
	ld.const.u32 	%r2492, [matrix+2480];
	// begin inline asm
	dp4a.u32.u32 %r2491, %r2492, %r4093, %r2487;
	// end inline asm
	ld.const.u32 	%r2496, [matrix+2484];
	// begin inline asm
	dp4a.u32.u32 %r2495, %r2496, %r4097, %r2491;
	// end inline asm
	ld.const.u32 	%r2500, [matrix+2488];
	// begin inline asm
	dp4a.u32.u32 %r2499, %r2500, %r4101, %r2495;
	// end inline asm
	ld.const.u32 	%r2504, [matrix+2492];
	// begin inline asm
	dp4a.u32.u32 %r2503, %r2504, %r4105, %r2499;
	// end inline asm
	ld.const.u32 	%r2508, [matrix+2496];
	// begin inline asm
	dp4a.u32.u32 %r2507, %r2508, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2512, [matrix+2500];
	// begin inline asm
	dp4a.u32.u32 %r2511, %r2512, %r4049, %r2507;
	// end inline asm
	ld.const.u32 	%r2516, [matrix+2504];
	// begin inline asm
	dp4a.u32.u32 %r2515, %r2516, %r4053, %r2511;
	// end inline asm
	ld.const.u32 	%r2520, [matrix+2508];
	// begin inline asm
	dp4a.u32.u32 %r2519, %r2520, %r4057, %r2515;
	// end inline asm
	ld.const.u32 	%r2524, [matrix+2512];
	// begin inline asm
	dp4a.u32.u32 %r2523, %r2524, %r4061, %r2519;
	// end inline asm
	ld.const.u32 	%r2528, [matrix+2516];
	// begin inline asm
	dp4a.u32.u32 %r2527, %r2528, %r4065, %r2523;
	// end inline asm
	ld.const.u32 	%r2532, [matrix+2520];
	// begin inline asm
	dp4a.u32.u32 %r2531, %r2532, %r4069, %r2527;
	// end inline asm
	ld.const.u32 	%r2536, [matrix+2524];
	// begin inline asm
	dp4a.u32.u32 %r2535, %r2536, %r4073, %r2531;
	// end inline asm
	ld.const.u32 	%r2540, [matrix+2528];
	// begin inline asm
	dp4a.u32.u32 %r2539, %r2540, %r4077, %r2535;
	// end inline asm
	ld.const.u32 	%r2544, [matrix+2532];
	// begin inline asm
	dp4a.u32.u32 %r2543, %r2544, %r4081, %r2539;
	// end inline asm
	ld.const.u32 	%r2548, [matrix+2536];
	// begin inline asm
	dp4a.u32.u32 %r2547, %r2548, %r4085, %r2543;
	// end inline asm
	ld.const.u32 	%r2552, [matrix+2540];
	// begin inline asm
	dp4a.u32.u32 %r2551, %r2552, %r4089, %r2547;
	// end inline asm
	ld.const.u32 	%r2556, [matrix+2544];
	// begin inline asm
	dp4a.u32.u32 %r2555, %r2556, %r4093, %r2551;
	// end inline asm
	ld.const.u32 	%r2560, [matrix+2548];
	// begin inline asm
	dp4a.u32.u32 %r2559, %r2560, %r4097, %r2555;
	// end inline asm
	ld.const.u32 	%r2564, [matrix+2552];
	// begin inline asm
	dp4a.u32.u32 %r2563, %r2564, %r4101, %r2559;
	// end inline asm
	ld.const.u32 	%r2568, [matrix+2556];
	// begin inline asm
	dp4a.u32.u32 %r2567, %r2568, %r4105, %r2563;
	// end inline asm
	shr.u32 	%r4367, %r2503, 6;
	and.b32  	%r4368, %r4367, 240;
	shr.u32 	%r4369, %r2567, 10;
	or.b32  	%r4370, %r4369, %r4368;
	cvt.u64.u32 	%rd413, %r4370;
	xor.b64  	%rd414, %rd337, %rd413;
	ld.const.u32 	%r2572, [matrix+2560];
	// begin inline asm
	dp4a.u32.u32 %r2571, %r2572, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2576, [matrix+2564];
	// begin inline asm
	dp4a.u32.u32 %r2575, %r2576, %r4049, %r2571;
	// end inline asm
	ld.const.u32 	%r2580, [matrix+2568];
	// begin inline asm
	dp4a.u32.u32 %r2579, %r2580, %r4053, %r2575;
	// end inline asm
	ld.const.u32 	%r2584, [matrix+2572];
	// begin inline asm
	dp4a.u32.u32 %r2583, %r2584, %r4057, %r2579;
	// end inline asm
	ld.const.u32 	%r2588, [matrix+2576];
	// begin inline asm
	dp4a.u32.u32 %r2587, %r2588, %r4061, %r2583;
	// end inline asm
	ld.const.u32 	%r2592, [matrix+2580];
	// begin inline asm
	dp4a.u32.u32 %r2591, %r2592, %r4065, %r2587;
	// end inline asm
	ld.const.u32 	%r2596, [matrix+2584];
	// begin inline asm
	dp4a.u32.u32 %r2595, %r2596, %r4069, %r2591;
	// end inline asm
	ld.const.u32 	%r2600, [matrix+2588];
	// begin inline asm
	dp4a.u32.u32 %r2599, %r2600, %r4073, %r2595;
	// end inline asm
	ld.const.u32 	%r2604, [matrix+2592];
	// begin inline asm
	dp4a.u32.u32 %r2603, %r2604, %r4077, %r2599;
	// end inline asm
	ld.const.u32 	%r2608, [matrix+2596];
	// begin inline asm
	dp4a.u32.u32 %r2607, %r2608, %r4081, %r2603;
	// end inline asm
	ld.const.u32 	%r2612, [matrix+2600];
	// begin inline asm
	dp4a.u32.u32 %r2611, %r2612, %r4085, %r2607;
	// end inline asm
	ld.const.u32 	%r2616, [matrix+2604];
	// begin inline asm
	dp4a.u32.u32 %r2615, %r2616, %r4089, %r2611;
	// end inline asm
	ld.const.u32 	%r2620, [matrix+2608];
	// begin inline asm
	dp4a.u32.u32 %r2619, %r2620, %r4093, %r2615;
	// end inline asm
	ld.const.u32 	%r2624, [matrix+2612];
	// begin inline asm
	dp4a.u32.u32 %r2623, %r2624, %r4097, %r2619;
	// end inline asm
	ld.const.u32 	%r2628, [matrix+2616];
	// begin inline asm
	dp4a.u32.u32 %r2627, %r2628, %r4101, %r2623;
	// end inline asm
	ld.const.u32 	%r2632, [matrix+2620];
	// begin inline asm
	dp4a.u32.u32 %r2631, %r2632, %r4105, %r2627;
	// end inline asm
	ld.const.u32 	%r2636, [matrix+2624];
	// begin inline asm
	dp4a.u32.u32 %r2635, %r2636, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2640, [matrix+2628];
	// begin inline asm
	dp4a.u32.u32 %r2639, %r2640, %r4049, %r2635;
	// end inline asm
	ld.const.u32 	%r2644, [matrix+2632];
	// begin inline asm
	dp4a.u32.u32 %r2643, %r2644, %r4053, %r2639;
	// end inline asm
	ld.const.u32 	%r2648, [matrix+2636];
	// begin inline asm
	dp4a.u32.u32 %r2647, %r2648, %r4057, %r2643;
	// end inline asm
	ld.const.u32 	%r2652, [matrix+2640];
	// begin inline asm
	dp4a.u32.u32 %r2651, %r2652, %r4061, %r2647;
	// end inline asm
	ld.const.u32 	%r2656, [matrix+2644];
	// begin inline asm
	dp4a.u32.u32 %r2655, %r2656, %r4065, %r2651;
	// end inline asm
	ld.const.u32 	%r2660, [matrix+2648];
	// begin inline asm
	dp4a.u32.u32 %r2659, %r2660, %r4069, %r2655;
	// end inline asm
	ld.const.u32 	%r2664, [matrix+2652];
	// begin inline asm
	dp4a.u32.u32 %r2663, %r2664, %r4073, %r2659;
	// end inline asm
	ld.const.u32 	%r2668, [matrix+2656];
	// begin inline asm
	dp4a.u32.u32 %r2667, %r2668, %r4077, %r2663;
	// end inline asm
	ld.const.u32 	%r2672, [matrix+2660];
	// begin inline asm
	dp4a.u32.u32 %r2671, %r2672, %r4081, %r2667;
	// end inline asm
	ld.const.u32 	%r2676, [matrix+2664];
	// begin inline asm
	dp4a.u32.u32 %r2675, %r2676, %r4085, %r2671;
	// end inline asm
	ld.const.u32 	%r2680, [matrix+2668];
	// begin inline asm
	dp4a.u32.u32 %r2679, %r2680, %r4089, %r2675;
	// end inline asm
	ld.const.u32 	%r2684, [matrix+2672];
	// begin inline asm
	dp4a.u32.u32 %r2683, %r2684, %r4093, %r2679;
	// end inline asm
	ld.const.u32 	%r2688, [matrix+2676];
	// begin inline asm
	dp4a.u32.u32 %r2687, %r2688, %r4097, %r2683;
	// end inline asm
	ld.const.u32 	%r2692, [matrix+2680];
	// begin inline asm
	dp4a.u32.u32 %r2691, %r2692, %r4101, %r2687;
	// end inline asm
	ld.const.u32 	%r2696, [matrix+2684];
	// begin inline asm
	dp4a.u32.u32 %r2695, %r2696, %r4105, %r2691;
	// end inline asm
	shr.u32 	%r4371, %r2631, 6;
	and.b32  	%r4372, %r4371, 240;
	shr.u32 	%r4373, %r2695, 10;
	or.b32  	%r4374, %r4373, %r4372;
	cvt.u64.u32 	%rd415, %r4374;
	xor.b64  	%rd416, %rd336, %rd415;
	ld.const.u32 	%r2700, [matrix+2688];
	// begin inline asm
	dp4a.u32.u32 %r2699, %r2700, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2704, [matrix+2692];
	// begin inline asm
	dp4a.u32.u32 %r2703, %r2704, %r4049, %r2699;
	// end inline asm
	ld.const.u32 	%r2708, [matrix+2696];
	// begin inline asm
	dp4a.u32.u32 %r2707, %r2708, %r4053, %r2703;
	// end inline asm
	ld.const.u32 	%r2712, [matrix+2700];
	// begin inline asm
	dp4a.u32.u32 %r2711, %r2712, %r4057, %r2707;
	// end inline asm
	ld.const.u32 	%r2716, [matrix+2704];
	// begin inline asm
	dp4a.u32.u32 %r2715, %r2716, %r4061, %r2711;
	// end inline asm
	ld.const.u32 	%r2720, [matrix+2708];
	// begin inline asm
	dp4a.u32.u32 %r2719, %r2720, %r4065, %r2715;
	// end inline asm
	ld.const.u32 	%r2724, [matrix+2712];
	// begin inline asm
	dp4a.u32.u32 %r2723, %r2724, %r4069, %r2719;
	// end inline asm
	ld.const.u32 	%r2728, [matrix+2716];
	// begin inline asm
	dp4a.u32.u32 %r2727, %r2728, %r4073, %r2723;
	// end inline asm
	ld.const.u32 	%r2732, [matrix+2720];
	// begin inline asm
	dp4a.u32.u32 %r2731, %r2732, %r4077, %r2727;
	// end inline asm
	ld.const.u32 	%r2736, [matrix+2724];
	// begin inline asm
	dp4a.u32.u32 %r2735, %r2736, %r4081, %r2731;
	// end inline asm
	ld.const.u32 	%r2740, [matrix+2728];
	// begin inline asm
	dp4a.u32.u32 %r2739, %r2740, %r4085, %r2735;
	// end inline asm
	ld.const.u32 	%r2744, [matrix+2732];
	// begin inline asm
	dp4a.u32.u32 %r2743, %r2744, %r4089, %r2739;
	// end inline asm
	ld.const.u32 	%r2748, [matrix+2736];
	// begin inline asm
	dp4a.u32.u32 %r2747, %r2748, %r4093, %r2743;
	// end inline asm
	ld.const.u32 	%r2752, [matrix+2740];
	// begin inline asm
	dp4a.u32.u32 %r2751, %r2752, %r4097, %r2747;
	// end inline asm
	ld.const.u32 	%r2756, [matrix+2744];
	// begin inline asm
	dp4a.u32.u32 %r2755, %r2756, %r4101, %r2751;
	// end inline asm
	ld.const.u32 	%r2760, [matrix+2748];
	// begin inline asm
	dp4a.u32.u32 %r2759, %r2760, %r4105, %r2755;
	// end inline asm
	ld.const.u32 	%r2764, [matrix+2752];
	// begin inline asm
	dp4a.u32.u32 %r2763, %r2764, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2768, [matrix+2756];
	// begin inline asm
	dp4a.u32.u32 %r2767, %r2768, %r4049, %r2763;
	// end inline asm
	ld.const.u32 	%r2772, [matrix+2760];
	// begin inline asm
	dp4a.u32.u32 %r2771, %r2772, %r4053, %r2767;
	// end inline asm
	ld.const.u32 	%r2776, [matrix+2764];
	// begin inline asm
	dp4a.u32.u32 %r2775, %r2776, %r4057, %r2771;
	// end inline asm
	ld.const.u32 	%r2780, [matrix+2768];
	// begin inline asm
	dp4a.u32.u32 %r2779, %r2780, %r4061, %r2775;
	// end inline asm
	ld.const.u32 	%r2784, [matrix+2772];
	// begin inline asm
	dp4a.u32.u32 %r2783, %r2784, %r4065, %r2779;
	// end inline asm
	ld.const.u32 	%r2788, [matrix+2776];
	// begin inline asm
	dp4a.u32.u32 %r2787, %r2788, %r4069, %r2783;
	// end inline asm
	ld.const.u32 	%r2792, [matrix+2780];
	// begin inline asm
	dp4a.u32.u32 %r2791, %r2792, %r4073, %r2787;
	// end inline asm
	ld.const.u32 	%r2796, [matrix+2784];
	// begin inline asm
	dp4a.u32.u32 %r2795, %r2796, %r4077, %r2791;
	// end inline asm
	ld.const.u32 	%r2800, [matrix+2788];
	// begin inline asm
	dp4a.u32.u32 %r2799, %r2800, %r4081, %r2795;
	// end inline asm
	ld.const.u32 	%r2804, [matrix+2792];
	// begin inline asm
	dp4a.u32.u32 %r2803, %r2804, %r4085, %r2799;
	// end inline asm
	ld.const.u32 	%r2808, [matrix+2796];
	// begin inline asm
	dp4a.u32.u32 %r2807, %r2808, %r4089, %r2803;
	// end inline asm
	ld.const.u32 	%r2812, [matrix+2800];
	// begin inline asm
	dp4a.u32.u32 %r2811, %r2812, %r4093, %r2807;
	// end inline asm
	ld.const.u32 	%r2816, [matrix+2804];
	// begin inline asm
	dp4a.u32.u32 %r2815, %r2816, %r4097, %r2811;
	// end inline asm
	ld.const.u32 	%r2820, [matrix+2808];
	// begin inline asm
	dp4a.u32.u32 %r2819, %r2820, %r4101, %r2815;
	// end inline asm
	ld.const.u32 	%r2824, [matrix+2812];
	// begin inline asm
	dp4a.u32.u32 %r2823, %r2824, %r4105, %r2819;
	// end inline asm
	shr.u32 	%r4375, %r2759, 6;
	and.b32  	%r4376, %r4375, 240;
	shr.u32 	%r4377, %r2823, 10;
	or.b32  	%r4378, %r4377, %r4376;
	cvt.u64.u32 	%rd417, %r4378;
	xor.b64  	%rd418, %rd335, %rd417;
	ld.const.u32 	%r2828, [matrix+2816];
	// begin inline asm
	dp4a.u32.u32 %r2827, %r2828, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2832, [matrix+2820];
	// begin inline asm
	dp4a.u32.u32 %r2831, %r2832, %r4049, %r2827;
	// end inline asm
	ld.const.u32 	%r2836, [matrix+2824];
	// begin inline asm
	dp4a.u32.u32 %r2835, %r2836, %r4053, %r2831;
	// end inline asm
	ld.const.u32 	%r2840, [matrix+2828];
	// begin inline asm
	dp4a.u32.u32 %r2839, %r2840, %r4057, %r2835;
	// end inline asm
	ld.const.u32 	%r2844, [matrix+2832];
	// begin inline asm
	dp4a.u32.u32 %r2843, %r2844, %r4061, %r2839;
	// end inline asm
	ld.const.u32 	%r2848, [matrix+2836];
	// begin inline asm
	dp4a.u32.u32 %r2847, %r2848, %r4065, %r2843;
	// end inline asm
	ld.const.u32 	%r2852, [matrix+2840];
	// begin inline asm
	dp4a.u32.u32 %r2851, %r2852, %r4069, %r2847;
	// end inline asm
	ld.const.u32 	%r2856, [matrix+2844];
	// begin inline asm
	dp4a.u32.u32 %r2855, %r2856, %r4073, %r2851;
	// end inline asm
	ld.const.u32 	%r2860, [matrix+2848];
	// begin inline asm
	dp4a.u32.u32 %r2859, %r2860, %r4077, %r2855;
	// end inline asm
	ld.const.u32 	%r2864, [matrix+2852];
	// begin inline asm
	dp4a.u32.u32 %r2863, %r2864, %r4081, %r2859;
	// end inline asm
	ld.const.u32 	%r2868, [matrix+2856];
	// begin inline asm
	dp4a.u32.u32 %r2867, %r2868, %r4085, %r2863;
	// end inline asm
	ld.const.u32 	%r2872, [matrix+2860];
	// begin inline asm
	dp4a.u32.u32 %r2871, %r2872, %r4089, %r2867;
	// end inline asm
	ld.const.u32 	%r2876, [matrix+2864];
	// begin inline asm
	dp4a.u32.u32 %r2875, %r2876, %r4093, %r2871;
	// end inline asm
	ld.const.u32 	%r2880, [matrix+2868];
	// begin inline asm
	dp4a.u32.u32 %r2879, %r2880, %r4097, %r2875;
	// end inline asm
	ld.const.u32 	%r2884, [matrix+2872];
	// begin inline asm
	dp4a.u32.u32 %r2883, %r2884, %r4101, %r2879;
	// end inline asm
	ld.const.u32 	%r2888, [matrix+2876];
	// begin inline asm
	dp4a.u32.u32 %r2887, %r2888, %r4105, %r2883;
	// end inline asm
	ld.const.u32 	%r2892, [matrix+2880];
	// begin inline asm
	dp4a.u32.u32 %r2891, %r2892, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2896, [matrix+2884];
	// begin inline asm
	dp4a.u32.u32 %r2895, %r2896, %r4049, %r2891;
	// end inline asm
	ld.const.u32 	%r2900, [matrix+2888];
	// begin inline asm
	dp4a.u32.u32 %r2899, %r2900, %r4053, %r2895;
	// end inline asm
	ld.const.u32 	%r2904, [matrix+2892];
	// begin inline asm
	dp4a.u32.u32 %r2903, %r2904, %r4057, %r2899;
	// end inline asm
	ld.const.u32 	%r2908, [matrix+2896];
	// begin inline asm
	dp4a.u32.u32 %r2907, %r2908, %r4061, %r2903;
	// end inline asm
	ld.const.u32 	%r2912, [matrix+2900];
	// begin inline asm
	dp4a.u32.u32 %r2911, %r2912, %r4065, %r2907;
	// end inline asm
	ld.const.u32 	%r2916, [matrix+2904];
	// begin inline asm
	dp4a.u32.u32 %r2915, %r2916, %r4069, %r2911;
	// end inline asm
	ld.const.u32 	%r2920, [matrix+2908];
	// begin inline asm
	dp4a.u32.u32 %r2919, %r2920, %r4073, %r2915;
	// end inline asm
	ld.const.u32 	%r2924, [matrix+2912];
	// begin inline asm
	dp4a.u32.u32 %r2923, %r2924, %r4077, %r2919;
	// end inline asm
	ld.const.u32 	%r2928, [matrix+2916];
	// begin inline asm
	dp4a.u32.u32 %r2927, %r2928, %r4081, %r2923;
	// end inline asm
	ld.const.u32 	%r2932, [matrix+2920];
	// begin inline asm
	dp4a.u32.u32 %r2931, %r2932, %r4085, %r2927;
	// end inline asm
	ld.const.u32 	%r2936, [matrix+2924];
	// begin inline asm
	dp4a.u32.u32 %r2935, %r2936, %r4089, %r2931;
	// end inline asm
	ld.const.u32 	%r2940, [matrix+2928];
	// begin inline asm
	dp4a.u32.u32 %r2939, %r2940, %r4093, %r2935;
	// end inline asm
	ld.const.u32 	%r2944, [matrix+2932];
	// begin inline asm
	dp4a.u32.u32 %r2943, %r2944, %r4097, %r2939;
	// end inline asm
	ld.const.u32 	%r2948, [matrix+2936];
	// begin inline asm
	dp4a.u32.u32 %r2947, %r2948, %r4101, %r2943;
	// end inline asm
	ld.const.u32 	%r2952, [matrix+2940];
	// begin inline asm
	dp4a.u32.u32 %r2951, %r2952, %r4105, %r2947;
	// end inline asm
	shr.u32 	%r4379, %r2887, 6;
	and.b32  	%r4380, %r4379, 240;
	shr.u32 	%r4381, %r2951, 10;
	or.b32  	%r4382, %r4381, %r4380;
	cvt.u64.u32 	%rd419, %r4382;
	xor.b64  	%rd420, %rd334, %rd419;
	ld.const.u32 	%r2956, [matrix+2944];
	// begin inline asm
	dp4a.u32.u32 %r2955, %r2956, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r2960, [matrix+2948];
	// begin inline asm
	dp4a.u32.u32 %r2959, %r2960, %r4049, %r2955;
	// end inline asm
	ld.const.u32 	%r2964, [matrix+2952];
	// begin inline asm
	dp4a.u32.u32 %r2963, %r2964, %r4053, %r2959;
	// end inline asm
	ld.const.u32 	%r2968, [matrix+2956];
	// begin inline asm
	dp4a.u32.u32 %r2967, %r2968, %r4057, %r2963;
	// end inline asm
	ld.const.u32 	%r2972, [matrix+2960];
	// begin inline asm
	dp4a.u32.u32 %r2971, %r2972, %r4061, %r2967;
	// end inline asm
	ld.const.u32 	%r2976, [matrix+2964];
	// begin inline asm
	dp4a.u32.u32 %r2975, %r2976, %r4065, %r2971;
	// end inline asm
	ld.const.u32 	%r2980, [matrix+2968];
	// begin inline asm
	dp4a.u32.u32 %r2979, %r2980, %r4069, %r2975;
	// end inline asm
	ld.const.u32 	%r2984, [matrix+2972];
	// begin inline asm
	dp4a.u32.u32 %r2983, %r2984, %r4073, %r2979;
	// end inline asm
	ld.const.u32 	%r2988, [matrix+2976];
	// begin inline asm
	dp4a.u32.u32 %r2987, %r2988, %r4077, %r2983;
	// end inline asm
	ld.const.u32 	%r2992, [matrix+2980];
	// begin inline asm
	dp4a.u32.u32 %r2991, %r2992, %r4081, %r2987;
	// end inline asm
	ld.const.u32 	%r2996, [matrix+2984];
	// begin inline asm
	dp4a.u32.u32 %r2995, %r2996, %r4085, %r2991;
	// end inline asm
	ld.const.u32 	%r3000, [matrix+2988];
	// begin inline asm
	dp4a.u32.u32 %r2999, %r3000, %r4089, %r2995;
	// end inline asm
	ld.const.u32 	%r3004, [matrix+2992];
	// begin inline asm
	dp4a.u32.u32 %r3003, %r3004, %r4093, %r2999;
	// end inline asm
	ld.const.u32 	%r3008, [matrix+2996];
	// begin inline asm
	dp4a.u32.u32 %r3007, %r3008, %r4097, %r3003;
	// end inline asm
	ld.const.u32 	%r3012, [matrix+3000];
	// begin inline asm
	dp4a.u32.u32 %r3011, %r3012, %r4101, %r3007;
	// end inline asm
	ld.const.u32 	%r3016, [matrix+3004];
	// begin inline asm
	dp4a.u32.u32 %r3015, %r3016, %r4105, %r3011;
	// end inline asm
	ld.const.u32 	%r3020, [matrix+3008];
	// begin inline asm
	dp4a.u32.u32 %r3019, %r3020, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3024, [matrix+3012];
	// begin inline asm
	dp4a.u32.u32 %r3023, %r3024, %r4049, %r3019;
	// end inline asm
	ld.const.u32 	%r3028, [matrix+3016];
	// begin inline asm
	dp4a.u32.u32 %r3027, %r3028, %r4053, %r3023;
	// end inline asm
	ld.const.u32 	%r3032, [matrix+3020];
	// begin inline asm
	dp4a.u32.u32 %r3031, %r3032, %r4057, %r3027;
	// end inline asm
	ld.const.u32 	%r3036, [matrix+3024];
	// begin inline asm
	dp4a.u32.u32 %r3035, %r3036, %r4061, %r3031;
	// end inline asm
	ld.const.u32 	%r3040, [matrix+3028];
	// begin inline asm
	dp4a.u32.u32 %r3039, %r3040, %r4065, %r3035;
	// end inline asm
	ld.const.u32 	%r3044, [matrix+3032];
	// begin inline asm
	dp4a.u32.u32 %r3043, %r3044, %r4069, %r3039;
	// end inline asm
	ld.const.u32 	%r3048, [matrix+3036];
	// begin inline asm
	dp4a.u32.u32 %r3047, %r3048, %r4073, %r3043;
	// end inline asm
	ld.const.u32 	%r3052, [matrix+3040];
	// begin inline asm
	dp4a.u32.u32 %r3051, %r3052, %r4077, %r3047;
	// end inline asm
	ld.const.u32 	%r3056, [matrix+3044];
	// begin inline asm
	dp4a.u32.u32 %r3055, %r3056, %r4081, %r3051;
	// end inline asm
	ld.const.u32 	%r3060, [matrix+3048];
	// begin inline asm
	dp4a.u32.u32 %r3059, %r3060, %r4085, %r3055;
	// end inline asm
	ld.const.u32 	%r3064, [matrix+3052];
	// begin inline asm
	dp4a.u32.u32 %r3063, %r3064, %r4089, %r3059;
	// end inline asm
	ld.const.u32 	%r3068, [matrix+3056];
	// begin inline asm
	dp4a.u32.u32 %r3067, %r3068, %r4093, %r3063;
	// end inline asm
	ld.const.u32 	%r3072, [matrix+3060];
	// begin inline asm
	dp4a.u32.u32 %r3071, %r3072, %r4097, %r3067;
	// end inline asm
	ld.const.u32 	%r3076, [matrix+3064];
	// begin inline asm
	dp4a.u32.u32 %r3075, %r3076, %r4101, %r3071;
	// end inline asm
	ld.const.u32 	%r3080, [matrix+3068];
	// begin inline asm
	dp4a.u32.u32 %r3079, %r3080, %r4105, %r3075;
	// end inline asm
	shr.u32 	%r4383, %r3015, 6;
	and.b32  	%r4384, %r4383, 240;
	shr.u32 	%r4385, %r3079, 10;
	or.b32  	%r4386, %r4385, %r4384;
	cvt.u64.u32 	%rd421, %r4386;
	xor.b64  	%rd422, %rd682, %rd421;
	ld.const.u32 	%r3084, [matrix+3072];
	// begin inline asm
	dp4a.u32.u32 %r3083, %r3084, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3088, [matrix+3076];
	// begin inline asm
	dp4a.u32.u32 %r3087, %r3088, %r4049, %r3083;
	// end inline asm
	ld.const.u32 	%r3092, [matrix+3080];
	// begin inline asm
	dp4a.u32.u32 %r3091, %r3092, %r4053, %r3087;
	// end inline asm
	ld.const.u32 	%r3096, [matrix+3084];
	// begin inline asm
	dp4a.u32.u32 %r3095, %r3096, %r4057, %r3091;
	// end inline asm
	ld.const.u32 	%r3100, [matrix+3088];
	// begin inline asm
	dp4a.u32.u32 %r3099, %r3100, %r4061, %r3095;
	// end inline asm
	ld.const.u32 	%r3104, [matrix+3092];
	// begin inline asm
	dp4a.u32.u32 %r3103, %r3104, %r4065, %r3099;
	// end inline asm
	ld.const.u32 	%r3108, [matrix+3096];
	// begin inline asm
	dp4a.u32.u32 %r3107, %r3108, %r4069, %r3103;
	// end inline asm
	ld.const.u32 	%r3112, [matrix+3100];
	// begin inline asm
	dp4a.u32.u32 %r3111, %r3112, %r4073, %r3107;
	// end inline asm
	ld.const.u32 	%r3116, [matrix+3104];
	// begin inline asm
	dp4a.u32.u32 %r3115, %r3116, %r4077, %r3111;
	// end inline asm
	ld.const.u32 	%r3120, [matrix+3108];
	// begin inline asm
	dp4a.u32.u32 %r3119, %r3120, %r4081, %r3115;
	// end inline asm
	ld.const.u32 	%r3124, [matrix+3112];
	// begin inline asm
	dp4a.u32.u32 %r3123, %r3124, %r4085, %r3119;
	// end inline asm
	ld.const.u32 	%r3128, [matrix+3116];
	// begin inline asm
	dp4a.u32.u32 %r3127, %r3128, %r4089, %r3123;
	// end inline asm
	ld.const.u32 	%r3132, [matrix+3120];
	// begin inline asm
	dp4a.u32.u32 %r3131, %r3132, %r4093, %r3127;
	// end inline asm
	ld.const.u32 	%r3136, [matrix+3124];
	// begin inline asm
	dp4a.u32.u32 %r3135, %r3136, %r4097, %r3131;
	// end inline asm
	ld.const.u32 	%r3140, [matrix+3128];
	// begin inline asm
	dp4a.u32.u32 %r3139, %r3140, %r4101, %r3135;
	// end inline asm
	ld.const.u32 	%r3144, [matrix+3132];
	// begin inline asm
	dp4a.u32.u32 %r3143, %r3144, %r4105, %r3139;
	// end inline asm
	ld.const.u32 	%r3148, [matrix+3136];
	// begin inline asm
	dp4a.u32.u32 %r3147, %r3148, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3152, [matrix+3140];
	// begin inline asm
	dp4a.u32.u32 %r3151, %r3152, %r4049, %r3147;
	// end inline asm
	ld.const.u32 	%r3156, [matrix+3144];
	// begin inline asm
	dp4a.u32.u32 %r3155, %r3156, %r4053, %r3151;
	// end inline asm
	ld.const.u32 	%r3160, [matrix+3148];
	// begin inline asm
	dp4a.u32.u32 %r3159, %r3160, %r4057, %r3155;
	// end inline asm
	ld.const.u32 	%r3164, [matrix+3152];
	// begin inline asm
	dp4a.u32.u32 %r3163, %r3164, %r4061, %r3159;
	// end inline asm
	ld.const.u32 	%r3168, [matrix+3156];
	// begin inline asm
	dp4a.u32.u32 %r3167, %r3168, %r4065, %r3163;
	// end inline asm
	ld.const.u32 	%r3172, [matrix+3160];
	// begin inline asm
	dp4a.u32.u32 %r3171, %r3172, %r4069, %r3167;
	// end inline asm
	ld.const.u32 	%r3176, [matrix+3164];
	// begin inline asm
	dp4a.u32.u32 %r3175, %r3176, %r4073, %r3171;
	// end inline asm
	ld.const.u32 	%r3180, [matrix+3168];
	// begin inline asm
	dp4a.u32.u32 %r3179, %r3180, %r4077, %r3175;
	// end inline asm
	ld.const.u32 	%r3184, [matrix+3172];
	// begin inline asm
	dp4a.u32.u32 %r3183, %r3184, %r4081, %r3179;
	// end inline asm
	ld.const.u32 	%r3188, [matrix+3176];
	// begin inline asm
	dp4a.u32.u32 %r3187, %r3188, %r4085, %r3183;
	// end inline asm
	ld.const.u32 	%r3192, [matrix+3180];
	// begin inline asm
	dp4a.u32.u32 %r3191, %r3192, %r4089, %r3187;
	// end inline asm
	ld.const.u32 	%r3196, [matrix+3184];
	// begin inline asm
	dp4a.u32.u32 %r3195, %r3196, %r4093, %r3191;
	// end inline asm
	ld.const.u32 	%r3200, [matrix+3188];
	// begin inline asm
	dp4a.u32.u32 %r3199, %r3200, %r4097, %r3195;
	// end inline asm
	ld.const.u32 	%r3204, [matrix+3192];
	// begin inline asm
	dp4a.u32.u32 %r3203, %r3204, %r4101, %r3199;
	// end inline asm
	ld.const.u32 	%r3208, [matrix+3196];
	// begin inline asm
	dp4a.u32.u32 %r3207, %r3208, %r4105, %r3203;
	// end inline asm
	shr.u32 	%r4387, %r3143, 6;
	and.b32  	%r4388, %r4387, 240;
	shr.u32 	%r4389, %r3207, 10;
	or.b32  	%r4390, %r4389, %r4388;
	cvt.u64.u32 	%rd423, %r4390;
	ld.const.u32 	%r3212, [matrix+3200];
	// begin inline asm
	dp4a.u32.u32 %r3211, %r3212, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3216, [matrix+3204];
	// begin inline asm
	dp4a.u32.u32 %r3215, %r3216, %r4049, %r3211;
	// end inline asm
	ld.const.u32 	%r3220, [matrix+3208];
	// begin inline asm
	dp4a.u32.u32 %r3219, %r3220, %r4053, %r3215;
	// end inline asm
	ld.const.u32 	%r3224, [matrix+3212];
	// begin inline asm
	dp4a.u32.u32 %r3223, %r3224, %r4057, %r3219;
	// end inline asm
	ld.const.u32 	%r3228, [matrix+3216];
	// begin inline asm
	dp4a.u32.u32 %r3227, %r3228, %r4061, %r3223;
	// end inline asm
	ld.const.u32 	%r3232, [matrix+3220];
	// begin inline asm
	dp4a.u32.u32 %r3231, %r3232, %r4065, %r3227;
	// end inline asm
	ld.const.u32 	%r3236, [matrix+3224];
	// begin inline asm
	dp4a.u32.u32 %r3235, %r3236, %r4069, %r3231;
	// end inline asm
	ld.const.u32 	%r3240, [matrix+3228];
	// begin inline asm
	dp4a.u32.u32 %r3239, %r3240, %r4073, %r3235;
	// end inline asm
	ld.const.u32 	%r3244, [matrix+3232];
	// begin inline asm
	dp4a.u32.u32 %r3243, %r3244, %r4077, %r3239;
	// end inline asm
	ld.const.u32 	%r3248, [matrix+3236];
	// begin inline asm
	dp4a.u32.u32 %r3247, %r3248, %r4081, %r3243;
	// end inline asm
	ld.const.u32 	%r3252, [matrix+3240];
	// begin inline asm
	dp4a.u32.u32 %r3251, %r3252, %r4085, %r3247;
	// end inline asm
	ld.const.u32 	%r3256, [matrix+3244];
	// begin inline asm
	dp4a.u32.u32 %r3255, %r3256, %r4089, %r3251;
	// end inline asm
	ld.const.u32 	%r3260, [matrix+3248];
	// begin inline asm
	dp4a.u32.u32 %r3259, %r3260, %r4093, %r3255;
	// end inline asm
	ld.const.u32 	%r3264, [matrix+3252];
	// begin inline asm
	dp4a.u32.u32 %r3263, %r3264, %r4097, %r3259;
	// end inline asm
	ld.const.u32 	%r3268, [matrix+3256];
	// begin inline asm
	dp4a.u32.u32 %r3267, %r3268, %r4101, %r3263;
	// end inline asm
	ld.const.u32 	%r3272, [matrix+3260];
	// begin inline asm
	dp4a.u32.u32 %r3271, %r3272, %r4105, %r3267;
	// end inline asm
	ld.const.u32 	%r3276, [matrix+3264];
	// begin inline asm
	dp4a.u32.u32 %r3275, %r3276, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3280, [matrix+3268];
	// begin inline asm
	dp4a.u32.u32 %r3279, %r3280, %r4049, %r3275;
	// end inline asm
	ld.const.u32 	%r3284, [matrix+3272];
	// begin inline asm
	dp4a.u32.u32 %r3283, %r3284, %r4053, %r3279;
	// end inline asm
	ld.const.u32 	%r3288, [matrix+3276];
	// begin inline asm
	dp4a.u32.u32 %r3287, %r3288, %r4057, %r3283;
	// end inline asm
	ld.const.u32 	%r3292, [matrix+3280];
	// begin inline asm
	dp4a.u32.u32 %r3291, %r3292, %r4061, %r3287;
	// end inline asm
	ld.const.u32 	%r3296, [matrix+3284];
	// begin inline asm
	dp4a.u32.u32 %r3295, %r3296, %r4065, %r3291;
	// end inline asm
	ld.const.u32 	%r3300, [matrix+3288];
	// begin inline asm
	dp4a.u32.u32 %r3299, %r3300, %r4069, %r3295;
	// end inline asm
	ld.const.u32 	%r3304, [matrix+3292];
	// begin inline asm
	dp4a.u32.u32 %r3303, %r3304, %r4073, %r3299;
	// end inline asm
	ld.const.u32 	%r3308, [matrix+3296];
	// begin inline asm
	dp4a.u32.u32 %r3307, %r3308, %r4077, %r3303;
	// end inline asm
	ld.const.u32 	%r3312, [matrix+3300];
	// begin inline asm
	dp4a.u32.u32 %r3311, %r3312, %r4081, %r3307;
	// end inline asm
	ld.const.u32 	%r3316, [matrix+3304];
	// begin inline asm
	dp4a.u32.u32 %r3315, %r3316, %r4085, %r3311;
	// end inline asm
	ld.const.u32 	%r3320, [matrix+3308];
	// begin inline asm
	dp4a.u32.u32 %r3319, %r3320, %r4089, %r3315;
	// end inline asm
	ld.const.u32 	%r3324, [matrix+3312];
	// begin inline asm
	dp4a.u32.u32 %r3323, %r3324, %r4093, %r3319;
	// end inline asm
	ld.const.u32 	%r3328, [matrix+3316];
	// begin inline asm
	dp4a.u32.u32 %r3327, %r3328, %r4097, %r3323;
	// end inline asm
	ld.const.u32 	%r3332, [matrix+3320];
	// begin inline asm
	dp4a.u32.u32 %r3331, %r3332, %r4101, %r3327;
	// end inline asm
	ld.const.u32 	%r3336, [matrix+3324];
	// begin inline asm
	dp4a.u32.u32 %r3335, %r3336, %r4105, %r3331;
	// end inline asm
	shr.u32 	%r4391, %r3271, 6;
	and.b32  	%r4392, %r4391, 240;
	shr.u32 	%r4393, %r3335, 10;
	or.b32  	%r4394, %r4393, %r4392;
	cvt.u64.u32 	%rd424, %r4394;
	xor.b64  	%rd425, %rd368, %rd424;
	xor.b64  	%rd426, %rd367, %rd423;
	ld.const.u32 	%r3340, [matrix+3328];
	// begin inline asm
	dp4a.u32.u32 %r3339, %r3340, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3344, [matrix+3332];
	// begin inline asm
	dp4a.u32.u32 %r3343, %r3344, %r4049, %r3339;
	// end inline asm
	ld.const.u32 	%r3348, [matrix+3336];
	// begin inline asm
	dp4a.u32.u32 %r3347, %r3348, %r4053, %r3343;
	// end inline asm
	ld.const.u32 	%r3352, [matrix+3340];
	// begin inline asm
	dp4a.u32.u32 %r3351, %r3352, %r4057, %r3347;
	// end inline asm
	ld.const.u32 	%r3356, [matrix+3344];
	// begin inline asm
	dp4a.u32.u32 %r3355, %r3356, %r4061, %r3351;
	// end inline asm
	ld.const.u32 	%r3360, [matrix+3348];
	// begin inline asm
	dp4a.u32.u32 %r3359, %r3360, %r4065, %r3355;
	// end inline asm
	ld.const.u32 	%r3364, [matrix+3352];
	// begin inline asm
	dp4a.u32.u32 %r3363, %r3364, %r4069, %r3359;
	// end inline asm
	ld.const.u32 	%r3368, [matrix+3356];
	// begin inline asm
	dp4a.u32.u32 %r3367, %r3368, %r4073, %r3363;
	// end inline asm
	ld.const.u32 	%r3372, [matrix+3360];
	// begin inline asm
	dp4a.u32.u32 %r3371, %r3372, %r4077, %r3367;
	// end inline asm
	ld.const.u32 	%r3376, [matrix+3364];
	// begin inline asm
	dp4a.u32.u32 %r3375, %r3376, %r4081, %r3371;
	// end inline asm
	ld.const.u32 	%r3380, [matrix+3368];
	// begin inline asm
	dp4a.u32.u32 %r3379, %r3380, %r4085, %r3375;
	// end inline asm
	ld.const.u32 	%r3384, [matrix+3372];
	// begin inline asm
	dp4a.u32.u32 %r3383, %r3384, %r4089, %r3379;
	// end inline asm
	ld.const.u32 	%r3388, [matrix+3376];
	// begin inline asm
	dp4a.u32.u32 %r3387, %r3388, %r4093, %r3383;
	// end inline asm
	ld.const.u32 	%r3392, [matrix+3380];
	// begin inline asm
	dp4a.u32.u32 %r3391, %r3392, %r4097, %r3387;
	// end inline asm
	ld.const.u32 	%r3396, [matrix+3384];
	// begin inline asm
	dp4a.u32.u32 %r3395, %r3396, %r4101, %r3391;
	// end inline asm
	ld.const.u32 	%r3400, [matrix+3388];
	// begin inline asm
	dp4a.u32.u32 %r3399, %r3400, %r4105, %r3395;
	// end inline asm
	ld.const.u32 	%r3404, [matrix+3392];
	// begin inline asm
	dp4a.u32.u32 %r3403, %r3404, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3408, [matrix+3396];
	// begin inline asm
	dp4a.u32.u32 %r3407, %r3408, %r4049, %r3403;
	// end inline asm
	ld.const.u32 	%r3412, [matrix+3400];
	// begin inline asm
	dp4a.u32.u32 %r3411, %r3412, %r4053, %r3407;
	// end inline asm
	ld.const.u32 	%r3416, [matrix+3404];
	// begin inline asm
	dp4a.u32.u32 %r3415, %r3416, %r4057, %r3411;
	// end inline asm
	ld.const.u32 	%r3420, [matrix+3408];
	// begin inline asm
	dp4a.u32.u32 %r3419, %r3420, %r4061, %r3415;
	// end inline asm
	ld.const.u32 	%r3424, [matrix+3412];
	// begin inline asm
	dp4a.u32.u32 %r3423, %r3424, %r4065, %r3419;
	// end inline asm
	ld.const.u32 	%r3428, [matrix+3416];
	// begin inline asm
	dp4a.u32.u32 %r3427, %r3428, %r4069, %r3423;
	// end inline asm
	ld.const.u32 	%r3432, [matrix+3420];
	// begin inline asm
	dp4a.u32.u32 %r3431, %r3432, %r4073, %r3427;
	// end inline asm
	ld.const.u32 	%r3436, [matrix+3424];
	// begin inline asm
	dp4a.u32.u32 %r3435, %r3436, %r4077, %r3431;
	// end inline asm
	ld.const.u32 	%r3440, [matrix+3428];
	// begin inline asm
	dp4a.u32.u32 %r3439, %r3440, %r4081, %r3435;
	// end inline asm
	ld.const.u32 	%r3444, [matrix+3432];
	// begin inline asm
	dp4a.u32.u32 %r3443, %r3444, %r4085, %r3439;
	// end inline asm
	ld.const.u32 	%r3448, [matrix+3436];
	// begin inline asm
	dp4a.u32.u32 %r3447, %r3448, %r4089, %r3443;
	// end inline asm
	ld.const.u32 	%r3452, [matrix+3440];
	// begin inline asm
	dp4a.u32.u32 %r3451, %r3452, %r4093, %r3447;
	// end inline asm
	ld.const.u32 	%r3456, [matrix+3444];
	// begin inline asm
	dp4a.u32.u32 %r3455, %r3456, %r4097, %r3451;
	// end inline asm
	ld.const.u32 	%r3460, [matrix+3448];
	// begin inline asm
	dp4a.u32.u32 %r3459, %r3460, %r4101, %r3455;
	// end inline asm
	ld.const.u32 	%r3464, [matrix+3452];
	// begin inline asm
	dp4a.u32.u32 %r3463, %r3464, %r4105, %r3459;
	// end inline asm
	shr.u32 	%r4395, %r3399, 6;
	and.b32  	%r4396, %r4395, 240;
	shr.u32 	%r4397, %r3463, 10;
	or.b32  	%r4398, %r4397, %r4396;
	cvt.u64.u32 	%rd427, %r4398;
	xor.b64  	%rd428, %rd369, %rd427;
	ld.const.u32 	%r3468, [matrix+3456];
	// begin inline asm
	dp4a.u32.u32 %r3467, %r3468, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3472, [matrix+3460];
	// begin inline asm
	dp4a.u32.u32 %r3471, %r3472, %r4049, %r3467;
	// end inline asm
	ld.const.u32 	%r3476, [matrix+3464];
	// begin inline asm
	dp4a.u32.u32 %r3475, %r3476, %r4053, %r3471;
	// end inline asm
	ld.const.u32 	%r3480, [matrix+3468];
	// begin inline asm
	dp4a.u32.u32 %r3479, %r3480, %r4057, %r3475;
	// end inline asm
	ld.const.u32 	%r3484, [matrix+3472];
	// begin inline asm
	dp4a.u32.u32 %r3483, %r3484, %r4061, %r3479;
	// end inline asm
	ld.const.u32 	%r3488, [matrix+3476];
	// begin inline asm
	dp4a.u32.u32 %r3487, %r3488, %r4065, %r3483;
	// end inline asm
	ld.const.u32 	%r3492, [matrix+3480];
	// begin inline asm
	dp4a.u32.u32 %r3491, %r3492, %r4069, %r3487;
	// end inline asm
	ld.const.u32 	%r3496, [matrix+3484];
	// begin inline asm
	dp4a.u32.u32 %r3495, %r3496, %r4073, %r3491;
	// end inline asm
	ld.const.u32 	%r3500, [matrix+3488];
	// begin inline asm
	dp4a.u32.u32 %r3499, %r3500, %r4077, %r3495;
	// end inline asm
	ld.const.u32 	%r3504, [matrix+3492];
	// begin inline asm
	dp4a.u32.u32 %r3503, %r3504, %r4081, %r3499;
	// end inline asm
	ld.const.u32 	%r3508, [matrix+3496];
	// begin inline asm
	dp4a.u32.u32 %r3507, %r3508, %r4085, %r3503;
	// end inline asm
	ld.const.u32 	%r3512, [matrix+3500];
	// begin inline asm
	dp4a.u32.u32 %r3511, %r3512, %r4089, %r3507;
	// end inline asm
	ld.const.u32 	%r3516, [matrix+3504];
	// begin inline asm
	dp4a.u32.u32 %r3515, %r3516, %r4093, %r3511;
	// end inline asm
	ld.const.u32 	%r3520, [matrix+3508];
	// begin inline asm
	dp4a.u32.u32 %r3519, %r3520, %r4097, %r3515;
	// end inline asm
	ld.const.u32 	%r3524, [matrix+3512];
	// begin inline asm
	dp4a.u32.u32 %r3523, %r3524, %r4101, %r3519;
	// end inline asm
	ld.const.u32 	%r3528, [matrix+3516];
	// begin inline asm
	dp4a.u32.u32 %r3527, %r3528, %r4105, %r3523;
	// end inline asm
	ld.const.u32 	%r3532, [matrix+3520];
	// begin inline asm
	dp4a.u32.u32 %r3531, %r3532, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3536, [matrix+3524];
	// begin inline asm
	dp4a.u32.u32 %r3535, %r3536, %r4049, %r3531;
	// end inline asm
	ld.const.u32 	%r3540, [matrix+3528];
	// begin inline asm
	dp4a.u32.u32 %r3539, %r3540, %r4053, %r3535;
	// end inline asm
	ld.const.u32 	%r3544, [matrix+3532];
	// begin inline asm
	dp4a.u32.u32 %r3543, %r3544, %r4057, %r3539;
	// end inline asm
	ld.const.u32 	%r3548, [matrix+3536];
	// begin inline asm
	dp4a.u32.u32 %r3547, %r3548, %r4061, %r3543;
	// end inline asm
	ld.const.u32 	%r3552, [matrix+3540];
	// begin inline asm
	dp4a.u32.u32 %r3551, %r3552, %r4065, %r3547;
	// end inline asm
	ld.const.u32 	%r3556, [matrix+3544];
	// begin inline asm
	dp4a.u32.u32 %r3555, %r3556, %r4069, %r3551;
	// end inline asm
	ld.const.u32 	%r3560, [matrix+3548];
	// begin inline asm
	dp4a.u32.u32 %r3559, %r3560, %r4073, %r3555;
	// end inline asm
	ld.const.u32 	%r3564, [matrix+3552];
	// begin inline asm
	dp4a.u32.u32 %r3563, %r3564, %r4077, %r3559;
	// end inline asm
	ld.const.u32 	%r3568, [matrix+3556];
	// begin inline asm
	dp4a.u32.u32 %r3567, %r3568, %r4081, %r3563;
	// end inline asm
	ld.const.u32 	%r3572, [matrix+3560];
	// begin inline asm
	dp4a.u32.u32 %r3571, %r3572, %r4085, %r3567;
	// end inline asm
	ld.const.u32 	%r3576, [matrix+3564];
	// begin inline asm
	dp4a.u32.u32 %r3575, %r3576, %r4089, %r3571;
	// end inline asm
	ld.const.u32 	%r3580, [matrix+3568];
	// begin inline asm
	dp4a.u32.u32 %r3579, %r3580, %r4093, %r3575;
	// end inline asm
	ld.const.u32 	%r3584, [matrix+3572];
	// begin inline asm
	dp4a.u32.u32 %r3583, %r3584, %r4097, %r3579;
	// end inline asm
	ld.const.u32 	%r3588, [matrix+3576];
	// begin inline asm
	dp4a.u32.u32 %r3587, %r3588, %r4101, %r3583;
	// end inline asm
	ld.const.u32 	%r3592, [matrix+3580];
	// begin inline asm
	dp4a.u32.u32 %r3591, %r3592, %r4105, %r3587;
	// end inline asm
	shr.u32 	%r4399, %r3527, 6;
	and.b32  	%r4400, %r4399, 240;
	shr.u32 	%r4401, %r3591, 10;
	or.b32  	%r4402, %r4401, %r4400;
	cvt.u64.u32 	%rd429, %r4402;
	xor.b64  	%rd430, %rd370, %rd429;
	ld.const.u32 	%r3596, [matrix+3584];
	// begin inline asm
	dp4a.u32.u32 %r3595, %r3596, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3600, [matrix+3588];
	// begin inline asm
	dp4a.u32.u32 %r3599, %r3600, %r4049, %r3595;
	// end inline asm
	ld.const.u32 	%r3604, [matrix+3592];
	// begin inline asm
	dp4a.u32.u32 %r3603, %r3604, %r4053, %r3599;
	// end inline asm
	ld.const.u32 	%r3608, [matrix+3596];
	// begin inline asm
	dp4a.u32.u32 %r3607, %r3608, %r4057, %r3603;
	// end inline asm
	ld.const.u32 	%r3612, [matrix+3600];
	// begin inline asm
	dp4a.u32.u32 %r3611, %r3612, %r4061, %r3607;
	// end inline asm
	ld.const.u32 	%r3616, [matrix+3604];
	// begin inline asm
	dp4a.u32.u32 %r3615, %r3616, %r4065, %r3611;
	// end inline asm
	ld.const.u32 	%r3620, [matrix+3608];
	// begin inline asm
	dp4a.u32.u32 %r3619, %r3620, %r4069, %r3615;
	// end inline asm
	ld.const.u32 	%r3624, [matrix+3612];
	// begin inline asm
	dp4a.u32.u32 %r3623, %r3624, %r4073, %r3619;
	// end inline asm
	ld.const.u32 	%r3628, [matrix+3616];
	// begin inline asm
	dp4a.u32.u32 %r3627, %r3628, %r4077, %r3623;
	// end inline asm
	ld.const.u32 	%r3632, [matrix+3620];
	// begin inline asm
	dp4a.u32.u32 %r3631, %r3632, %r4081, %r3627;
	// end inline asm
	ld.const.u32 	%r3636, [matrix+3624];
	// begin inline asm
	dp4a.u32.u32 %r3635, %r3636, %r4085, %r3631;
	// end inline asm
	ld.const.u32 	%r3640, [matrix+3628];
	// begin inline asm
	dp4a.u32.u32 %r3639, %r3640, %r4089, %r3635;
	// end inline asm
	ld.const.u32 	%r3644, [matrix+3632];
	// begin inline asm
	dp4a.u32.u32 %r3643, %r3644, %r4093, %r3639;
	// end inline asm
	ld.const.u32 	%r3648, [matrix+3636];
	// begin inline asm
	dp4a.u32.u32 %r3647, %r3648, %r4097, %r3643;
	// end inline asm
	ld.const.u32 	%r3652, [matrix+3640];
	// begin inline asm
	dp4a.u32.u32 %r3651, %r3652, %r4101, %r3647;
	// end inline asm
	ld.const.u32 	%r3656, [matrix+3644];
	// begin inline asm
	dp4a.u32.u32 %r3655, %r3656, %r4105, %r3651;
	// end inline asm
	ld.const.u32 	%r3660, [matrix+3648];
	// begin inline asm
	dp4a.u32.u32 %r3659, %r3660, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3664, [matrix+3652];
	// begin inline asm
	dp4a.u32.u32 %r3663, %r3664, %r4049, %r3659;
	// end inline asm
	ld.const.u32 	%r3668, [matrix+3656];
	// begin inline asm
	dp4a.u32.u32 %r3667, %r3668, %r4053, %r3663;
	// end inline asm
	ld.const.u32 	%r3672, [matrix+3660];
	// begin inline asm
	dp4a.u32.u32 %r3671, %r3672, %r4057, %r3667;
	// end inline asm
	ld.const.u32 	%r3676, [matrix+3664];
	// begin inline asm
	dp4a.u32.u32 %r3675, %r3676, %r4061, %r3671;
	// end inline asm
	ld.const.u32 	%r3680, [matrix+3668];
	// begin inline asm
	dp4a.u32.u32 %r3679, %r3680, %r4065, %r3675;
	// end inline asm
	ld.const.u32 	%r3684, [matrix+3672];
	// begin inline asm
	dp4a.u32.u32 %r3683, %r3684, %r4069, %r3679;
	// end inline asm
	ld.const.u32 	%r3688, [matrix+3676];
	// begin inline asm
	dp4a.u32.u32 %r3687, %r3688, %r4073, %r3683;
	// end inline asm
	ld.const.u32 	%r3692, [matrix+3680];
	// begin inline asm
	dp4a.u32.u32 %r3691, %r3692, %r4077, %r3687;
	// end inline asm
	ld.const.u32 	%r3696, [matrix+3684];
	// begin inline asm
	dp4a.u32.u32 %r3695, %r3696, %r4081, %r3691;
	// end inline asm
	ld.const.u32 	%r3700, [matrix+3688];
	// begin inline asm
	dp4a.u32.u32 %r3699, %r3700, %r4085, %r3695;
	// end inline asm
	ld.const.u32 	%r3704, [matrix+3692];
	// begin inline asm
	dp4a.u32.u32 %r3703, %r3704, %r4089, %r3699;
	// end inline asm
	ld.const.u32 	%r3708, [matrix+3696];
	// begin inline asm
	dp4a.u32.u32 %r3707, %r3708, %r4093, %r3703;
	// end inline asm
	ld.const.u32 	%r3712, [matrix+3700];
	// begin inline asm
	dp4a.u32.u32 %r3711, %r3712, %r4097, %r3707;
	// end inline asm
	ld.const.u32 	%r3716, [matrix+3704];
	// begin inline asm
	dp4a.u32.u32 %r3715, %r3716, %r4101, %r3711;
	// end inline asm
	ld.const.u32 	%r3720, [matrix+3708];
	// begin inline asm
	dp4a.u32.u32 %r3719, %r3720, %r4105, %r3715;
	// end inline asm
	shr.u32 	%r4403, %r3655, 6;
	and.b32  	%r4404, %r4403, 240;
	shr.u32 	%r4405, %r3719, 10;
	or.b32  	%r4406, %r4405, %r4404;
	cvt.u64.u32 	%rd431, %r4406;
	xor.b64  	%rd432, %rd371, %rd431;
	ld.const.u32 	%r3724, [matrix+3712];
	// begin inline asm
	dp4a.u32.u32 %r3723, %r3724, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3728, [matrix+3716];
	// begin inline asm
	dp4a.u32.u32 %r3727, %r3728, %r4049, %r3723;
	// end inline asm
	ld.const.u32 	%r3732, [matrix+3720];
	// begin inline asm
	dp4a.u32.u32 %r3731, %r3732, %r4053, %r3727;
	// end inline asm
	ld.const.u32 	%r3736, [matrix+3724];
	// begin inline asm
	dp4a.u32.u32 %r3735, %r3736, %r4057, %r3731;
	// end inline asm
	ld.const.u32 	%r3740, [matrix+3728];
	// begin inline asm
	dp4a.u32.u32 %r3739, %r3740, %r4061, %r3735;
	// end inline asm
	ld.const.u32 	%r3744, [matrix+3732];
	// begin inline asm
	dp4a.u32.u32 %r3743, %r3744, %r4065, %r3739;
	// end inline asm
	ld.const.u32 	%r3748, [matrix+3736];
	// begin inline asm
	dp4a.u32.u32 %r3747, %r3748, %r4069, %r3743;
	// end inline asm
	ld.const.u32 	%r3752, [matrix+3740];
	// begin inline asm
	dp4a.u32.u32 %r3751, %r3752, %r4073, %r3747;
	// end inline asm
	ld.const.u32 	%r3756, [matrix+3744];
	// begin inline asm
	dp4a.u32.u32 %r3755, %r3756, %r4077, %r3751;
	// end inline asm
	ld.const.u32 	%r3760, [matrix+3748];
	// begin inline asm
	dp4a.u32.u32 %r3759, %r3760, %r4081, %r3755;
	// end inline asm
	ld.const.u32 	%r3764, [matrix+3752];
	// begin inline asm
	dp4a.u32.u32 %r3763, %r3764, %r4085, %r3759;
	// end inline asm
	ld.const.u32 	%r3768, [matrix+3756];
	// begin inline asm
	dp4a.u32.u32 %r3767, %r3768, %r4089, %r3763;
	// end inline asm
	ld.const.u32 	%r3772, [matrix+3760];
	// begin inline asm
	dp4a.u32.u32 %r3771, %r3772, %r4093, %r3767;
	// end inline asm
	ld.const.u32 	%r3776, [matrix+3764];
	// begin inline asm
	dp4a.u32.u32 %r3775, %r3776, %r4097, %r3771;
	// end inline asm
	ld.const.u32 	%r3780, [matrix+3768];
	// begin inline asm
	dp4a.u32.u32 %r3779, %r3780, %r4101, %r3775;
	// end inline asm
	ld.const.u32 	%r3784, [matrix+3772];
	// begin inline asm
	dp4a.u32.u32 %r3783, %r3784, %r4105, %r3779;
	// end inline asm
	ld.const.u32 	%r3788, [matrix+3776];
	// begin inline asm
	dp4a.u32.u32 %r3787, %r3788, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3792, [matrix+3780];
	// begin inline asm
	dp4a.u32.u32 %r3791, %r3792, %r4049, %r3787;
	// end inline asm
	ld.const.u32 	%r3796, [matrix+3784];
	// begin inline asm
	dp4a.u32.u32 %r3795, %r3796, %r4053, %r3791;
	// end inline asm
	ld.const.u32 	%r3800, [matrix+3788];
	// begin inline asm
	dp4a.u32.u32 %r3799, %r3800, %r4057, %r3795;
	// end inline asm
	ld.const.u32 	%r3804, [matrix+3792];
	// begin inline asm
	dp4a.u32.u32 %r3803, %r3804, %r4061, %r3799;
	// end inline asm
	ld.const.u32 	%r3808, [matrix+3796];
	// begin inline asm
	dp4a.u32.u32 %r3807, %r3808, %r4065, %r3803;
	// end inline asm
	ld.const.u32 	%r3812, [matrix+3800];
	// begin inline asm
	dp4a.u32.u32 %r3811, %r3812, %r4069, %r3807;
	// end inline asm
	ld.const.u32 	%r3816, [matrix+3804];
	// begin inline asm
	dp4a.u32.u32 %r3815, %r3816, %r4073, %r3811;
	// end inline asm
	ld.const.u32 	%r3820, [matrix+3808];
	// begin inline asm
	dp4a.u32.u32 %r3819, %r3820, %r4077, %r3815;
	// end inline asm
	ld.const.u32 	%r3824, [matrix+3812];
	// begin inline asm
	dp4a.u32.u32 %r3823, %r3824, %r4081, %r3819;
	// end inline asm
	ld.const.u32 	%r3828, [matrix+3816];
	// begin inline asm
	dp4a.u32.u32 %r3827, %r3828, %r4085, %r3823;
	// end inline asm
	ld.const.u32 	%r3832, [matrix+3820];
	// begin inline asm
	dp4a.u32.u32 %r3831, %r3832, %r4089, %r3827;
	// end inline asm
	ld.const.u32 	%r3836, [matrix+3824];
	// begin inline asm
	dp4a.u32.u32 %r3835, %r3836, %r4093, %r3831;
	// end inline asm
	ld.const.u32 	%r3840, [matrix+3828];
	// begin inline asm
	dp4a.u32.u32 %r3839, %r3840, %r4097, %r3835;
	// end inline asm
	ld.const.u32 	%r3844, [matrix+3832];
	// begin inline asm
	dp4a.u32.u32 %r3843, %r3844, %r4101, %r3839;
	// end inline asm
	ld.const.u32 	%r3848, [matrix+3836];
	// begin inline asm
	dp4a.u32.u32 %r3847, %r3848, %r4105, %r3843;
	// end inline asm
	shr.u32 	%r4407, %r3783, 6;
	and.b32  	%r4408, %r4407, 240;
	shr.u32 	%r4409, %r3847, 10;
	or.b32  	%r4410, %r4409, %r4408;
	cvt.u64.u32 	%rd433, %r4410;
	xor.b64  	%rd434, %rd373, %rd433;
	ld.const.u32 	%r3852, [matrix+3840];
	// begin inline asm
	dp4a.u32.u32 %r3851, %r3852, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3856, [matrix+3844];
	// begin inline asm
	dp4a.u32.u32 %r3855, %r3856, %r4049, %r3851;
	// end inline asm
	ld.const.u32 	%r3860, [matrix+3848];
	// begin inline asm
	dp4a.u32.u32 %r3859, %r3860, %r4053, %r3855;
	// end inline asm
	ld.const.u32 	%r3864, [matrix+3852];
	// begin inline asm
	dp4a.u32.u32 %r3863, %r3864, %r4057, %r3859;
	// end inline asm
	ld.const.u32 	%r3868, [matrix+3856];
	// begin inline asm
	dp4a.u32.u32 %r3867, %r3868, %r4061, %r3863;
	// end inline asm
	ld.const.u32 	%r3872, [matrix+3860];
	// begin inline asm
	dp4a.u32.u32 %r3871, %r3872, %r4065, %r3867;
	// end inline asm
	ld.const.u32 	%r3876, [matrix+3864];
	// begin inline asm
	dp4a.u32.u32 %r3875, %r3876, %r4069, %r3871;
	// end inline asm
	ld.const.u32 	%r3880, [matrix+3868];
	// begin inline asm
	dp4a.u32.u32 %r3879, %r3880, %r4073, %r3875;
	// end inline asm
	ld.const.u32 	%r3884, [matrix+3872];
	// begin inline asm
	dp4a.u32.u32 %r3883, %r3884, %r4077, %r3879;
	// end inline asm
	ld.const.u32 	%r3888, [matrix+3876];
	// begin inline asm
	dp4a.u32.u32 %r3887, %r3888, %r4081, %r3883;
	// end inline asm
	ld.const.u32 	%r3892, [matrix+3880];
	// begin inline asm
	dp4a.u32.u32 %r3891, %r3892, %r4085, %r3887;
	// end inline asm
	ld.const.u32 	%r3896, [matrix+3884];
	// begin inline asm
	dp4a.u32.u32 %r3895, %r3896, %r4089, %r3891;
	// end inline asm
	ld.const.u32 	%r3900, [matrix+3888];
	// begin inline asm
	dp4a.u32.u32 %r3899, %r3900, %r4093, %r3895;
	// end inline asm
	ld.const.u32 	%r3904, [matrix+3892];
	// begin inline asm
	dp4a.u32.u32 %r3903, %r3904, %r4097, %r3899;
	// end inline asm
	ld.const.u32 	%r3908, [matrix+3896];
	// begin inline asm
	dp4a.u32.u32 %r3907, %r3908, %r4101, %r3903;
	// end inline asm
	ld.const.u32 	%r3912, [matrix+3900];
	// begin inline asm
	dp4a.u32.u32 %r3911, %r3912, %r4105, %r3907;
	// end inline asm
	ld.const.u32 	%r3916, [matrix+3904];
	// begin inline asm
	dp4a.u32.u32 %r3915, %r3916, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3920, [matrix+3908];
	// begin inline asm
	dp4a.u32.u32 %r3919, %r3920, %r4049, %r3915;
	// end inline asm
	ld.const.u32 	%r3924, [matrix+3912];
	// begin inline asm
	dp4a.u32.u32 %r3923, %r3924, %r4053, %r3919;
	// end inline asm
	ld.const.u32 	%r3928, [matrix+3916];
	// begin inline asm
	dp4a.u32.u32 %r3927, %r3928, %r4057, %r3923;
	// end inline asm
	ld.const.u32 	%r3932, [matrix+3920];
	// begin inline asm
	dp4a.u32.u32 %r3931, %r3932, %r4061, %r3927;
	// end inline asm
	ld.const.u32 	%r3936, [matrix+3924];
	// begin inline asm
	dp4a.u32.u32 %r3935, %r3936, %r4065, %r3931;
	// end inline asm
	ld.const.u32 	%r3940, [matrix+3928];
	// begin inline asm
	dp4a.u32.u32 %r3939, %r3940, %r4069, %r3935;
	// end inline asm
	ld.const.u32 	%r3944, [matrix+3932];
	// begin inline asm
	dp4a.u32.u32 %r3943, %r3944, %r4073, %r3939;
	// end inline asm
	ld.const.u32 	%r3948, [matrix+3936];
	// begin inline asm
	dp4a.u32.u32 %r3947, %r3948, %r4077, %r3943;
	// end inline asm
	ld.const.u32 	%r3952, [matrix+3940];
	// begin inline asm
	dp4a.u32.u32 %r3951, %r3952, %r4081, %r3947;
	// end inline asm
	ld.const.u32 	%r3956, [matrix+3944];
	// begin inline asm
	dp4a.u32.u32 %r3955, %r3956, %r4085, %r3951;
	// end inline asm
	ld.const.u32 	%r3960, [matrix+3948];
	// begin inline asm
	dp4a.u32.u32 %r3959, %r3960, %r4089, %r3955;
	// end inline asm
	ld.const.u32 	%r3964, [matrix+3952];
	// begin inline asm
	dp4a.u32.u32 %r3963, %r3964, %r4093, %r3959;
	// end inline asm
	ld.const.u32 	%r3968, [matrix+3956];
	// begin inline asm
	dp4a.u32.u32 %r3967, %r3968, %r4097, %r3963;
	// end inline asm
	ld.const.u32 	%r3972, [matrix+3960];
	// begin inline asm
	dp4a.u32.u32 %r3971, %r3972, %r4101, %r3967;
	// end inline asm
	ld.const.u32 	%r3976, [matrix+3964];
	// begin inline asm
	dp4a.u32.u32 %r3975, %r3976, %r4105, %r3971;
	// end inline asm
	shr.u32 	%r4411, %r3911, 6;
	and.b32  	%r4412, %r4411, 240;
	shr.u32 	%r4413, %r3975, 10;
	or.b32  	%r4414, %r4413, %r4412;
	cvt.u64.u32 	%rd435, %r4414;
	xor.b64  	%rd436, %rd375, %rd435;
	ld.const.u32 	%r3980, [matrix+3968];
	// begin inline asm
	dp4a.u32.u32 %r3979, %r3980, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r3984, [matrix+3972];
	// begin inline asm
	dp4a.u32.u32 %r3983, %r3984, %r4049, %r3979;
	// end inline asm
	ld.const.u32 	%r3988, [matrix+3976];
	// begin inline asm
	dp4a.u32.u32 %r3987, %r3988, %r4053, %r3983;
	// end inline asm
	ld.const.u32 	%r3992, [matrix+3980];
	// begin inline asm
	dp4a.u32.u32 %r3991, %r3992, %r4057, %r3987;
	// end inline asm
	ld.const.u32 	%r3996, [matrix+3984];
	// begin inline asm
	dp4a.u32.u32 %r3995, %r3996, %r4061, %r3991;
	// end inline asm
	ld.const.u32 	%r4000, [matrix+3988];
	// begin inline asm
	dp4a.u32.u32 %r3999, %r4000, %r4065, %r3995;
	// end inline asm
	ld.const.u32 	%r4004, [matrix+3992];
	// begin inline asm
	dp4a.u32.u32 %r4003, %r4004, %r4069, %r3999;
	// end inline asm
	ld.const.u32 	%r4008, [matrix+3996];
	// begin inline asm
	dp4a.u32.u32 %r4007, %r4008, %r4073, %r4003;
	// end inline asm
	ld.const.u32 	%r4012, [matrix+4000];
	// begin inline asm
	dp4a.u32.u32 %r4011, %r4012, %r4077, %r4007;
	// end inline asm
	ld.const.u32 	%r4016, [matrix+4004];
	// begin inline asm
	dp4a.u32.u32 %r4015, %r4016, %r4081, %r4011;
	// end inline asm
	ld.const.u32 	%r4020, [matrix+4008];
	// begin inline asm
	dp4a.u32.u32 %r4019, %r4020, %r4085, %r4015;
	// end inline asm
	ld.const.u32 	%r4024, [matrix+4012];
	// begin inline asm
	dp4a.u32.u32 %r4023, %r4024, %r4089, %r4019;
	// end inline asm
	ld.const.u32 	%r4028, [matrix+4016];
	// begin inline asm
	dp4a.u32.u32 %r4027, %r4028, %r4093, %r4023;
	// end inline asm
	ld.const.u32 	%r4032, [matrix+4020];
	// begin inline asm
	dp4a.u32.u32 %r4031, %r4032, %r4097, %r4027;
	// end inline asm
	ld.const.u32 	%r4036, [matrix+4024];
	// begin inline asm
	dp4a.u32.u32 %r4035, %r4036, %r4101, %r4031;
	// end inline asm
	ld.const.u32 	%r4040, [matrix+4028];
	// begin inline asm
	dp4a.u32.u32 %r4039, %r4040, %r4105, %r4035;
	// end inline asm
	ld.const.u32 	%r4044, [matrix+4032];
	// begin inline asm
	dp4a.u32.u32 %r4043, %r4044, %r4045, %r4420;
	// end inline asm
	ld.const.u32 	%r4048, [matrix+4036];
	// begin inline asm
	dp4a.u32.u32 %r4047, %r4048, %r4049, %r4043;
	// end inline asm
	ld.const.u32 	%r4052, [matrix+4040];
	// begin inline asm
	dp4a.u32.u32 %r4051, %r4052, %r4053, %r4047;
	// end inline asm
	ld.const.u32 	%r4056, [matrix+4044];
	// begin inline asm
	dp4a.u32.u32 %r4055, %r4056, %r4057, %r4051;
	// end inline asm
	ld.const.u32 	%r4060, [matrix+4048];
	// begin inline asm
	dp4a.u32.u32 %r4059, %r4060, %r4061, %r4055;
	// end inline asm
	ld.const.u32 	%r4064, [matrix+4052];
	// begin inline asm
	dp4a.u32.u32 %r4063, %r4064, %r4065, %r4059;
	// end inline asm
	ld.const.u32 	%r4068, [matrix+4056];
	// begin inline asm
	dp4a.u32.u32 %r4067, %r4068, %r4069, %r4063;
	// end inline asm
	ld.const.u32 	%r4072, [matrix+4060];
	// begin inline asm
	dp4a.u32.u32 %r4071, %r4072, %r4073, %r4067;
	// end inline asm
	ld.const.u32 	%r4076, [matrix+4064];
	// begin inline asm
	dp4a.u32.u32 %r4075, %r4076, %r4077, %r4071;
	// end inline asm
	ld.const.u32 	%r4080, [matrix+4068];
	// begin inline asm
	dp4a.u32.u32 %r4079, %r4080, %r4081, %r4075;
	// end inline asm
	ld.const.u32 	%r4084, [matrix+4072];
	// begin inline asm
	dp4a.u32.u32 %r4083, %r4084, %r4085, %r4079;
	// end inline asm
	ld.const.u32 	%r4088, [matrix+4076];
	// begin inline asm
	dp4a.u32.u32 %r4087, %r4088, %r4089, %r4083;
	// end inline asm
	ld.const.u32 	%r4092, [matrix+4080];
	// begin inline asm
	dp4a.u32.u32 %r4091, %r4092, %r4093, %r4087;
	// end inline asm
	ld.const.u32 	%r4096, [matrix+4084];
	// begin inline asm
	dp4a.u32.u32 %r4095, %r4096, %r4097, %r4091;
	// end inline asm
	ld.const.u32 	%r4100, [matrix+4088];
	// begin inline asm
	dp4a.u32.u32 %r4099, %r4100, %r4101, %r4095;
	// end inline asm
	ld.const.u32 	%r4104, [matrix+4092];
	// begin inline asm
	dp4a.u32.u32 %r4103, %r4104, %r4105, %r4099;
	// end inline asm
	shr.u32 	%r4415, %r4039, 6;
	and.b32  	%r4416, %r4415, 240;
	shr.u32 	%r4417, %r4103, 10;
	or.b32  	%r4418, %r4417, %r4416;
	cvt.u64.u32 	%rd437, %r4418;
	shl.b64 	%rd438, %rd437, 56;
	xor.b64  	%rd439, %rd367, %rd438;
	shr.u64 	%rd440, %rd439, 56;
	xor.b64  	%rd441, %rd348, %rd378;
	shl.b64 	%rd442, %rd386, 24;
	and.b64  	%rd443, %rd442, 4278190080;
	shl.b64 	%rd444, %rd388, 16;
	and.b64  	%rd445, %rd444, 16711680;
	shl.b64 	%rd446, %rd390, 8;
	and.b64  	%rd447, %rd446, 65280;
	shl.b64 	%rd448, %rd432, 24;
	and.b64  	%rd449, %rd448, 4278190080;
	shl.b64 	%rd450, %rd434, 16;
	and.b64  	%rd451, %rd450, 16711680;
	shl.b64 	%rd452, %rd436, 8;
	xor.b64  	%rd453, %rd340, %rd408;
	shl.b64 	%rd454, %rd416, 24;
	and.b64  	%rd455, %rd454, 4278190080;
	shl.b64 	%rd456, %rd418, 16;
	and.b64  	%rd457, %rd456, 16711680;
	shl.b64 	%rd458, %rd420, 8;
	and.b64  	%rd459, %rd458, 65280;
	xor.b64  	%rd460, %rd347, %rd393;
	shl.b64 	%rd461, %rd401, 24;
	and.b64  	%rd462, %rd461, 4278190080;
	shl.b64 	%rd463, %rd403, 16;
	and.b64  	%rd464, %rd463, 16711680;
	shl.b64 	%rd465, %rd405, 8;
	and.b64  	%rd466, %rd465, 65280;
	shl.b64 	%rd467, %rd426, 56;
	shl.b64 	%rd468, %rd425, 48;
	and.b64  	%rd469, %rd468, 71776119061217280;
	or.b64  	%rd470, %rd467, %rd469;
	shl.b64 	%rd471, %rd428, 40;
	and.b64  	%rd472, %rd471, 280375465082880;
	or.b64  	%rd473, %rd470, %rd472;
	shl.b64 	%rd474, %rd430, 32;
	and.b64  	%rd475, %rd474, 1095216660480;
	or.b64  	%rd476, %rd473, %rd475;
	or.b64  	%rd477, %rd476, %rd449;
	and.b64  	%rd478, %rd452, 65280;
	or.b64  	%rd479, %rd477, %rd451;
	or.b64  	%rd480, %rd479, %rd478;
	or.b64  	%rd481, %rd480, %rd440;
	xor.b64  	%rd124, %rd481, 4239941492252378377;
	shl.b64 	%rd482, %rd453, 56;
	shl.b64 	%rd483, %rd410, 48;
	and.b64  	%rd484, %rd483, 71776119061217280;
	or.b64  	%rd485, %rd482, %rd484;
	shl.b64 	%rd486, %rd412, 40;
	and.b64  	%rd487, %rd486, 280375465082880;
	or.b64  	%rd488, %rd485, %rd487;
	shl.b64 	%rd489, %rd414, 32;
	and.b64  	%rd490, %rd489, 1095216660480;
	or.b64  	%rd491, %rd488, %rd490;
	or.b64  	%rd492, %rd491, %rd455;
	or.b64  	%rd493, %rd492, %rd457;
	and.b64  	%rd494, %rd422, 255;
	or.b64  	%rd495, %rd493, %rd459;
	or.b64  	%rd496, %rd495, %rd494;
	xor.b64  	%rd708, %rd496, 8746723911537738262;
	shl.b64 	%rd497, %rd460, 56;
	shl.b64 	%rd498, %rd395, 48;
	and.b64  	%rd499, %rd498, 71776119061217280;
	or.b64  	%rd500, %rd497, %rd499;
	shl.b64 	%rd501, %rd397, 40;
	and.b64  	%rd502, %rd501, 280375465082880;
	or.b64  	%rd503, %rd500, %rd502;
	shl.b64 	%rd504, %rd399, 32;
	and.b64  	%rd505, %rd504, 1095216660480;
	or.b64  	%rd506, %rd503, %rd505;
	or.b64  	%rd507, %rd506, %rd462;
	or.b64  	%rd508, %rd507, %rd464;
	and.b64  	%rd509, %rd407, 255;
	or.b64  	%rd510, %rd508, %rd466;
	or.b64  	%rd511, %rd510, %rd509;
	xor.b64  	%rd703, %rd511, 8796936657246353646;
	shl.b64 	%rd512, %rd441, 56;
	shl.b64 	%rd513, %rd380, 48;
	and.b64  	%rd514, %rd513, 71776119061217280;
	or.b64  	%rd515, %rd512, %rd514;
	shl.b64 	%rd516, %rd382, 40;
	and.b64  	%rd517, %rd516, 280375465082880;
	or.b64  	%rd518, %rd515, %rd517;
	shl.b64 	%rd519, %rd384, 32;
	and.b64  	%rd520, %rd519, 1095216660480;
	or.b64  	%rd521, %rd518, %rd520;
	or.b64  	%rd522, %rd521, %rd443;
	or.b64  	%rd523, %rd522, %rd445;
	and.b64  	%rd524, %rd392, 255;
	or.b64  	%rd525, %rd523, %rd447;
	or.b64  	%rd526, %rd525, %rd524;
	xor.b64  	%rd698, %rd526, 1272090201925444760;
	mov.u64 	%rd712, 8270816933120786537;
	mov.u64 	%rd711, -850687345431043546;
	mov.u64 	%rd710, 8596393687355028144;
	mov.u64 	%rd709, -4073852189716399785;
	mov.u64 	%rd707, -4539347866060507718;
	mov.u64 	%rd706, -3233781605604422593;
	mov.u64 	%rd705, 570094237299545110;
	mov.u64 	%rd704, 5171152063242093102;
	mov.u64 	%rd702, 6782861118970774626;
	mov.u64 	%rd701, 7812475424661425213;
	mov.u64 	%rd700, 9119540418498120711;
	mov.u64 	%rd699, -7873636174015165430;
	mov.u64 	%rd697, -9207053471590684088;
	mov.u64 	%rd696, 3370482334374859748;
	mov.u64 	%rd695, -1544774801229058759;
	mov.u64 	%rd694, 6096431547456407061;
	mov.u64 	%rd693, -1792185402154627366;
	mov.u64 	%rd692, -6864424130110145268;
	mov.u64 	%rd691, 5690099369266491460;
	mov.u64 	%rd690, -5074726839974049192;
	mov.u64 	%rd689, 1592359455985097269;
	mov.u64 	%rd688, RC;

$L__BB0_9:
	xor.b64  	%rd527, %rd712, %rd124;
	xor.b64  	%rd528, %rd527, %rd711;
	xor.b64  	%rd529, %rd528, %rd710;
	xor.b64  	%rd530, %rd529, %rd709;
	xor.b64  	%rd531, %rd707, %rd708;
	xor.b64  	%rd532, %rd531, %rd706;
	xor.b64  	%rd533, %rd532, %rd705;
	xor.b64  	%rd534, %rd533, %rd704;
	xor.b64  	%rd535, %rd702, %rd703;
	xor.b64  	%rd536, %rd535, %rd701;
	xor.b64  	%rd537, %rd536, %rd700;
	xor.b64  	%rd538, %rd537, %rd699;
	xor.b64  	%rd539, %rd697, %rd698;
	xor.b64  	%rd540, %rd539, %rd696;
	xor.b64  	%rd541, %rd540, %rd695;
	xor.b64  	%rd542, %rd541, %rd694;
	xor.b64  	%rd543, %rd692, %rd693;
	xor.b64  	%rd544, %rd543, %rd691;
	xor.b64  	%rd545, %rd544, %rd690;
	xor.b64  	%rd546, %rd545, %rd689;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd534, 1;
	shr.b64 	%rhs, %rd534, 63;
	add.u64 	%rd547, %lhs, %rhs;
	}
	xor.b64  	%rd548, %rd546, %rd547;
	xor.b64  	%rd549, %rd548, %rd124;
	xor.b64  	%rd550, %rd712, %rd548;
	xor.b64  	%rd551, %rd711, %rd548;
	xor.b64  	%rd552, %rd710, %rd548;
	xor.b64  	%rd553, %rd709, %rd548;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd538, 1;
	shr.b64 	%rhs, %rd538, 63;
	add.u64 	%rd554, %lhs, %rhs;
	}
	xor.b64  	%rd555, %rd554, %rd530;
	xor.b64  	%rd556, %rd708, %rd555;
	xor.b64  	%rd557, %rd707, %rd555;
	xor.b64  	%rd558, %rd706, %rd555;
	xor.b64  	%rd559, %rd705, %rd555;
	xor.b64  	%rd560, %rd704, %rd555;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd542, 1;
	shr.b64 	%rhs, %rd542, 63;
	add.u64 	%rd561, %lhs, %rhs;
	}
	xor.b64  	%rd562, %rd561, %rd534;
	xor.b64  	%rd563, %rd703, %rd562;
	xor.b64  	%rd564, %rd702, %rd562;
	xor.b64  	%rd565, %rd701, %rd562;
	xor.b64  	%rd566, %rd700, %rd562;
	xor.b64  	%rd567, %rd699, %rd562;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd546, 1;
	shr.b64 	%rhs, %rd546, 63;
	add.u64 	%rd568, %lhs, %rhs;
	}
	xor.b64  	%rd569, %rd568, %rd538;
	xor.b64  	%rd570, %rd698, %rd569;
	xor.b64  	%rd571, %rd697, %rd569;
	xor.b64  	%rd572, %rd696, %rd569;
	xor.b64  	%rd573, %rd695, %rd569;
	xor.b64  	%rd574, %rd694, %rd569;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd530, 1;
	shr.b64 	%rhs, %rd530, 63;
	add.u64 	%rd575, %lhs, %rhs;
	}
	xor.b64  	%rd576, %rd542, %rd575;
	xor.b64  	%rd577, %rd693, %rd576;
	xor.b64  	%rd578, %rd692, %rd576;
	xor.b64  	%rd579, %rd691, %rd576;
	xor.b64  	%rd580, %rd690, %rd576;
	xor.b64  	%rd581, %rd689, %rd576;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd556, 1;
	shr.b64 	%rhs, %rd556, 63;
	add.u64 	%rd582, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd551, 3;
	shr.b64 	%rhs, %rd551, 61;
	add.u64 	%rd583, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd564, 6;
	shr.b64 	%rhs, %rd564, 58;
	add.u64 	%rd584, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd558, 10;
	shr.b64 	%rhs, %rd558, 54;
	add.u64 	%rd585, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd566, 15;
	shr.b64 	%rhs, %rd566, 49;
	add.u64 	%rd586, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd573, 21;
	shr.b64 	%rhs, %rd573, 43;
	add.u64 	%rd587, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd570, 28;
	shr.b64 	%rhs, %rd570, 36;
	add.u64 	%rd588, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd550, 36;
	shr.b64 	%rhs, %rd550, 28;
	add.u64 	%rd589, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd559, 45;
	shr.b64 	%rhs, %rd559, 19;
	add.u64 	%rd590, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd571, 55;
	shr.b64 	%rhs, %rd571, 9;
	add.u64 	%rd591, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd560, 2;
	shr.b64 	%rhs, %rd560, 62;
	add.u64 	%rd592, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd581, 14;
	shr.b64 	%rhs, %rd581, 50;
	add.u64 	%rd593, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd577, 27;
	shr.b64 	%rhs, %rd577, 37;
	add.u64 	%rd594, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd552, 41;
	shr.b64 	%rhs, %rd552, 23;
	add.u64 	%rd595, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd574, 56;
	shr.b64 	%rhs, %rd574, 8;
	add.u64 	%rd596, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd580, 8;
	shr.b64 	%rhs, %rd580, 56;
	add.u64 	%rd597, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd572, 25;
	shr.b64 	%rhs, %rd572, 39;
	add.u64 	%rd598, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd565, 43;
	shr.b64 	%rhs, %rd565, 21;
	add.u64 	%rd599, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd563, 62;
	shr.b64 	%rhs, %rd563, 2;
	add.u64 	%rd600, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd553, 18;
	shr.b64 	%rhs, %rd553, 46;
	add.u64 	%rd601, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd579, 39;
	shr.b64 	%rhs, %rd579, 25;
	add.u64 	%rd602, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd567, 61;
	shr.b64 	%rhs, %rd567, 3;
	add.u64 	%rd603, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd578, 20;
	shr.b64 	%rhs, %rd578, 44;
	add.u64 	%rd604, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd557, 44;
	shr.b64 	%rhs, %rd557, 20;
	add.u64 	%rd605, %lhs, %rhs;
	}
	not.b64 	%rd606, %rd605;
	and.b64  	%rd607, %rd599, %rd606;
	xor.b64  	%rd608, %rd607, %rd549;
	not.b64 	%rd609, %rd599;
	and.b64  	%rd610, %rd587, %rd609;
	xor.b64  	%rd708, %rd610, %rd605;
	not.b64 	%rd611, %rd587;
	and.b64  	%rd612, %rd593, %rd611;
	xor.b64  	%rd703, %rd612, %rd599;
	not.b64 	%rd613, %rd593;
	and.b64  	%rd614, %rd549, %rd613;
	xor.b64  	%rd698, %rd614, %rd587;
	not.b64 	%rd615, %rd549;
	and.b64  	%rd616, %rd605, %rd615;
	xor.b64  	%rd693, %rd593, %rd616;
	not.b64 	%rd617, %rd604;
	and.b64  	%rd618, %rd583, %rd617;
	xor.b64  	%rd712, %rd618, %rd588;
	not.b64 	%rd619, %rd583;
	and.b64  	%rd620, %rd590, %rd619;
	xor.b64  	%rd707, %rd620, %rd604;
	not.b64 	%rd621, %rd590;
	and.b64  	%rd622, %rd603, %rd621;
	xor.b64  	%rd702, %rd622, %rd583;
	not.b64 	%rd623, %rd603;
	and.b64  	%rd624, %rd588, %rd623;
	xor.b64  	%rd697, %rd624, %rd590;
	not.b64 	%rd625, %rd588;
	and.b64  	%rd626, %rd604, %rd625;
	xor.b64  	%rd692, %rd603, %rd626;
	not.b64 	%rd627, %rd584;
	and.b64  	%rd628, %rd598, %rd627;
	xor.b64  	%rd711, %rd628, %rd582;
	not.b64 	%rd629, %rd598;
	and.b64  	%rd630, %rd597, %rd629;
	xor.b64  	%rd706, %rd630, %rd584;
	not.b64 	%rd631, %rd597;
	and.b64  	%rd632, %rd601, %rd631;
	xor.b64  	%rd701, %rd632, %rd598;
	not.b64 	%rd633, %rd601;
	and.b64  	%rd634, %rd582, %rd633;
	xor.b64  	%rd696, %rd634, %rd597;
	not.b64 	%rd635, %rd582;
	and.b64  	%rd636, %rd584, %rd635;
	xor.b64  	%rd691, %rd601, %rd636;
	not.b64 	%rd637, %rd589;
	and.b64  	%rd638, %rd585, %rd637;
	xor.b64  	%rd710, %rd638, %rd594;
	not.b64 	%rd639, %rd585;
	and.b64  	%rd640, %rd586, %rd639;
	xor.b64  	%rd705, %rd640, %rd589;
	not.b64 	%rd641, %rd586;
	and.b64  	%rd642, %rd596, %rd641;
	xor.b64  	%rd700, %rd642, %rd585;
	not.b64 	%rd643, %rd596;
	and.b64  	%rd644, %rd594, %rd643;
	xor.b64  	%rd695, %rd644, %rd586;
	not.b64 	%rd645, %rd594;
	and.b64  	%rd646, %rd589, %rd645;
	xor.b64  	%rd690, %rd596, %rd646;
	not.b64 	%rd647, %rd591;
	and.b64  	%rd648, %rd602, %rd647;
	xor.b64  	%rd709, %rd648, %rd600;
	not.b64 	%rd649, %rd602;
	and.b64  	%rd650, %rd595, %rd649;
	xor.b64  	%rd704, %rd650, %rd591;
	not.b64 	%rd651, %rd595;
	and.b64  	%rd652, %rd592, %rd651;
	xor.b64  	%rd699, %rd652, %rd602;
	not.b64 	%rd653, %rd592;
	and.b64  	%rd654, %rd600, %rd653;
	xor.b64  	%rd694, %rd654, %rd595;
	not.b64 	%rd655, %rd600;
	and.b64  	%rd656, %rd591, %rd655;
	xor.b64  	%rd689, %rd592, %rd656;
	ld.global.nc.u64 	%rd657, [%rd688];
	xor.b64  	%rd124, %rd608, %rd657;
	add.s64 	%rd688, %rd688, 8;
	add.s32 	%r4420, %r4420, 1;
	setp.ne.s32 	%p5, %r4420, 24;
	@%p5 bra 	$L__BB0_9;

	ld.const.u64 	%rd126, [target+24];
	setp.eq.s64 	%p6, %rd698, %rd126;
	@%p6 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	ld.const.u64 	%rd127, [target+16];
	setp.eq.s64 	%p8, %rd703, %rd127;
	@%p8 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_13;

$L__BB0_14:
	ld.const.u64 	%rd128, [target+8];
	setp.eq.s64 	%p10, %rd708, %rd128;
	@%p10 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_15;

$L__BB0_16:
	ld.const.u64 	%rd658, [target];
	setp.ge.u64 	%p12, %rd124, %rd658;
	@%p12 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_17;

$L__BB0_11:
	setp.lt.u64 	%p7, %rd698, %rd126;
	@%p7 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_18;

$L__BB0_17:
	mov.u64 	%rd659, 0;
	atom.global.cas.b64 	%rd660, [%rd2], %rd659, %rd7;

$L__BB0_18:
	ret;

$L__BB0_13:
	setp.lt.u64 	%p9, %rd703, %rd127;
	@%p9 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_18;

$L__BB0_15:
	setp.lt.u64 	%p11, %rd708, %rd128;
	@%p11 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_18;

}

